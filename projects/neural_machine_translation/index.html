<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Neural machine translation - Paddy - Paddy&#039;s Log Book</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Paddy - Paddy&#039;s Log Book"><meta name="msapplication-TileImage" content="/images/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Paddy - Paddy&#039;s Log Book"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Neural machine translation with basic Seq-to-Seq Transformer Architecture and Keras"><meta property="og:type" content="blog"><meta property="og:title" content="Neural machine translation"><meta property="og:url" content="http://paddyzz.github.io/Projects/neural_machine_translation/"><meta property="og:site_name" content="Paddy - Paddy&#039;s Log Book"><meta property="og:description" content="Neural machine translation with basic Seq-to-Seq Transformer Architecture and Keras"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image%201.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image%202.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image%203.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image%204.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image%205.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image%206.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image%207.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image%208.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image%209.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image%2010.png"><meta property="article:published_time" content="2024-05-30T16:00:00.000Z"><meta property="article:modified_time" content="2024-10-23T16:00:00.000Z"><meta property="article:author" content="Paddy"><meta property="article:tag" content="DL"><meta property="article:tag" content="NLP"><meta property="article:tag" content="ML"><meta property="article:tag" content="PROJECTS"><meta property="article:tag" content="Python"><meta property="article:tag" content="Seq-to-Seq"><meta property="article:tag" content="Tensorflow"><meta property="article:tag" content="Keras"><meta property="article:tag" content="transformer"><meta property="article:tag" content="tokenizer"><meta property="article:tag" content="self-attention"><meta property="article:tag" content="translation"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://paddyzz.github.io/images/assets/neural_machine_translation/image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://paddyzz.github.io/Projects/neural_machine_translation/"},"headline":"Neural machine translation","image":["http://paddyzz.github.io/images/assets/neural_machine_translation/image.png","http://paddyzz.github.io/images/assets/neural_machine_translation/image%201.png","http://paddyzz.github.io/images/assets/neural_machine_translation/image%202.png","http://paddyzz.github.io/images/assets/neural_machine_translation/image%203.png","http://paddyzz.github.io/images/assets/neural_machine_translation/image%204.png","http://paddyzz.github.io/images/assets/neural_machine_translation/image%205.png","http://paddyzz.github.io/images/assets/neural_machine_translation/image%206.png","http://paddyzz.github.io/images/assets/neural_machine_translation/image%207.png","http://paddyzz.github.io/images/assets/neural_machine_translation/image%208.png","http://paddyzz.github.io/images/assets/neural_machine_translation/image%209.png","http://paddyzz.github.io/images/assets/neural_machine_translation/image%2010.png"],"datePublished":"2024-05-30T16:00:00.000Z","dateModified":"2024-10-23T16:00:00.000Z","author":{"@type":"Person","name":"Paddy"},"publisher":{"@type":"Organization","name":"Paddy - Paddy's Log Book","logo":{"@type":"ImageObject","url":"http://paddyzz.github.io/images/favicon.png"}},"description":"Neural machine translation with basic Seq-to-Seq Transformer Architecture and Keras"}</script><link rel="canonical" href="http://paddyzz.github.io/Projects/neural_machine_translation/"><link rel="icon" href="/images/favicon.png"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.2/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="follow.it-verification-code" content="SdbKP9l6XayZRBYCuvDS"><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><script type="text/javascript" src="/js/svg-inject.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/gsap@3.3.4/dist/gsap.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/gsap@3.3.4/dist/ScrollTrigger.js"></script><progress max="100" value="0"></progress><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/favicon.png" alt="Paddy - Paddy&#039;s Log Book" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item navbar-item-home" href="/">PADDY&#039;S LOG BOOK</a><a class="navbar-item" href="/curriculum/">CURRICULUM</a><a class="navbar-item" href="/certificates/">CERTIFICATES</a><a class="navbar-item" href="/blogs/">BLOGS</a><a class="navbar-item" href="/projects/">PROJECTS</a><a class="navbar-item" href="/life/">LIFE</a><a class="navbar-item" href="/archives/">ARCHIVES</a><a class="navbar-item" href="/categories/">CATEGORIES</a><a class="navbar-item" href="/tags/">TAGS</a><a class="navbar-item" href="/faqs/">FAQS</a></div><div class="navbar-end"><a class="navbar-item navbar-item-logo" id="star-nav" title="Nox Tenebratio!" style="opacity:0;display:none;userSelect:none;" href="javascript:;"><i class="fa fa-star-and-crescent" id="star-icon" style="font-size:17.75px"></i></a><a class="navbar-item navbar-item-logo night" id="night-nav" title="Nox!" href="javascript:;"><i class="fas fa-moon" id="night-icon" style="font-size:16.75px"></i></a><a class="navbar-item navbar-item-logo" id="night-nav" title="Email" href="mailto:jiahe.zhao@uq.net.au?body=Hello%2C%0A%0AIt%20would%20be%20greatly%20appreciated%20if%20you%20could%20send%20me%20an%20email%20using%20your%20personal%20email%20client%20rather%20than%20the%20current%20HTML%20popup%20one%2C%20as%20I%20may%20not%20receive%20your%20message.%0A%0AThank%20you."><i class="fas fa-envelope" style="font-size:16.75px"></i></a><a class="navbar-item navbar-item-logo" title="Gitter" target="_blank" rel="noopener" href="https://app.gitter.im/#/room/#Paddy/Community:gitter.im"><i class="fab fa-gitter" style="font-size:16.75px"></i></a><a class="navbar-item navbar-item-logo" title="Element" target="_blank" rel="noopener" href="https://app.element.io/#/room/#Paddy/Community:gitter.im"><svg version="1.0" id="svg-element" xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 225 225"><g fill="#4a4a4a"><path d="M91 1c-11 3-13 19-3 24l11 2c32 3 56 27 59 59 0 9 2 12 6 15 7 4 15 2 19-5l1-13c-1-11-3-19-9-31A87 87 0 0 0 91 1zM73 43a90 90 0 0 0-72 91c3 11 19 13 24 3l2-11c3-32 27-56 59-59 9 0 12-2 15-6 4-7 2-15-5-19H73zM208 82c-7 2-9 6-10 17-3 32-27 56-59 59-9 0-12 2-15 6-4 7-1 15 5 19l13 1c12-1 20-3 33-9a86 86 0 0 0 49-84c-1-4-6-9-8-9h-8zM47 124c-5 3-6 7-6 18 1 12 3 20 10 33 13 28 39 46 71 49 10 1 14 0 18-3 6-6 4-17-3-21l-11-2c-32-3-56-27-59-59l-2-10c-2-4-7-7-11-7l-7 2z"></path></g></svg></a><a class="navbar-item navbar-item-logo" title="GitHub" target="_blank" rel="noopener" href="https://github.com/paddyzz"><i class="fab fa-github" style="font-size:16.75px"></i></a><a class="navbar-item navbar-item-logo" title="Linkedin" target="_blank" rel="noopener" href="https://www.linkedin.com/in/jiahe-paddy-zhao-213b24300"><i class="fab fa-linkedin" style="font-size:19.75px"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item navbar-item-logo search" title="Search For It !" href="javascript:;"><i class="fa-brands fa-searchengin" style="font-size:19.75px"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-3 is-size-4-mobile title-font-style">Neural machine translation</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item author-capitalize"> Paddy </span><span class="level-item"><i class="far fa-calendar-alt"></i>&nbsp;<time dateTime="2024-05-30T16:00:00.000Z" title="31/05/2024, 12:00:00 am">31-05-2024</time></span><span class="level-item"><i class="far fa-calendar-check"></i>&nbsp;<time dateTime="2024-10-23T16:00:00.000Z" title="24/10/2024, 12:00:00 am">24-10-2024</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i><span> </span><a class="link-muted" href="/projects/">projects</a></span><span class="level-item"> <i class="far fa-clock"></i> <span> </span> 25 minutes read<span> </span>( About 3795 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><article class="message is-info" style="margin-top:1.5rem;font-style:oblique"><div class="message-body">Neural machine translation with basic Seq-to-Seq Transformer Architecture and Keras</div></article><div class="content card-content-font-style" style="margin-top:1.5rem;margin-bottom:1rem"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In this blog, we will create and train a <a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary#sequence-to-sequence-task">sequence-to-sequence</a> <a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary#Transformer">Transformer</a> model to translate <a target="_blank" rel="noopener" href="https://www.google.com/url?q=https://www.tensorflow.org/datasets/catalog/ted_hrlr_translate%23ted_hrlr_translatept_to_en">Portuguese into English</a>.</p>
<p>Transformers are deep neural networks that replace CNNs and RNNs with <a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary#self-attention">self-attention</a>. Self-attention allows Transformers to easily transmit information across the input sequences.</p>
<p>As suggested in the <a target="_blank" rel="noopener" href="https://www.google.com/url?q=https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">Google AI Blog post</a>:</p>
<blockquote>
<p>Neural networks for machine translation typically contain an encoder reading the input sentence and generating a representation of it. A decoder then generates the output sentence word by word while consulting the representation generated by the encoder. The Transformer starts by generating initial representations, or embeddings, for each word… Then, using self-attention, it aggregates information from all of the other words, generating a new representation per word informed by the entire context, represented by the filled balls. This step is then repeated multiple times in parallel for all words, successively generating new representations.</p>
</blockquote>
<p>let’s dive into it!</p>
<h2 id="Set-up"><a href="#Set-up" class="headerlink" title="Set up"></a>Set up</h2><p>Begin by installing <a target="_blank" rel="noopener" href="https://tensorflow.org/datasets">TensorFlow Datasets</a> for loading the dataset and <a target="_blank" rel="noopener" href="https://www.google.com/url?q=https://www.tensorflow.org/text">TensorFlow Text</a> for text preprocessing:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># google colab</span><br><span class="line"># Install the most re version of TensorFlow to use the improved</span><br><span class="line"># masking support for `tf.keras.layers.MultiHeadAttention`.</span><br><span class="line">!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2</span><br><span class="line">!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text</span><br><span class="line">!pip install protobuf~=3.20.3</span><br><span class="line">!pip install -q tensorflow_datasets</span><br><span class="line">!pip install -q -U tensorflow-text tensorflow</span><br><span class="line">import logging</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">import tensorflow_datasets as tfds</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">import tensorflow_text</span><br><span class="line">!pip install datasets</span><br></pre></td></tr></table></figure>

<h2 id="Data-handling"><a href="#Data-handling" class="headerlink" title="Data handling"></a>Data handling</h2><h3 id="Download-the-dataset"><a href="#Download-the-dataset" class="headerlink" title="Download the dataset"></a>Download the dataset</h3><p>Use TensorFlow Datasets to load the <a target="_blank" rel="noopener" href="https://www.google.com/url?q=https://www.tensorflow.org/datasets/catalog/ted_hrlr_translate%23ted_hrlr_translatept_to_en">Portuguese-English translation dataset</a>D Talks Open Translation Project. This dataset contains approximately 52,000 training, 1,200 validation and 1,800 test examples.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">examples, metadata = tfds.load(&#x27;ted_hrlr_translate/pt_to_en&#x27;,</span><br><span class="line">                               with_info=True,</span><br><span class="line">                               as_supervised=True)</span><br><span class="line"></span><br><span class="line">train_examples, val_examples = examples[&#x27;train&#x27;], examples[&#x27;validation&#x27;]</span><br></pre></td></tr></table></figure>

<p>after we have loaded the dataset, we will tokenize the text, so that each element is represented as a <a target="_blank" rel="noopener" href="https://developers.google.com/machine-learning/glossary#token">token</a> or token ID (a numeric representation).</p>
<h3 id="Set-up-the-tokenizer"><a href="#Set-up-the-tokenizer" class="headerlink" title="Set up the tokenizer"></a>Set up the tokenizer</h3><p>ownload, extract, and import the <code>saved_model</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model_name = &#x27;ted_hrlr_translate_pt_en_converter&#x27;</span><br><span class="line">tf.keras.utils.get_file(</span><br><span class="line">    f&#x27;&#123;model_name&#125;.zip&#x27;,</span><br><span class="line">    f&#x27;https://storage.googleapis.com/download.tensorflow.org/models/&#123;model_name&#125;.zip&#x27;,</span><br><span class="line">    cache_dir=&#x27;.&#x27;, cache_subdir=&#x27;&#x27;, extract=True</span><br><span class="line">)</span><br><span class="line">tokenizers = tf.saved_model.load(f&#x27;&#123;model_name&#125;_extracted/&#123;model_name&#125;&#x27;)</span><br></pre></td></tr></table></figure>

<h3 id="Set-up-a-data-pipeline-with-tf-data"><a href="#Set-up-a-data-pipeline-with-tf-data" class="headerlink" title="Set up a data pipeline with tf.data"></a><strong>Set up a data pipeline with <code>tf.data</code></strong></h3><p>The following function takes batches of text as input, and converts them to a format suitable for training.</p>
<ol>
<li>It tokenizes them into ragged batches.</li>
<li>It trims each to be no longer than <code>MAX_TOKENS</code>.</li>
<li>It splits the target (English) tokens into inputs and labels. These are shifted by one step so that at each input location the <code>label</code> is the id of the next token.</li>
<li>It converts the <code>RaggedTensor</code>s to padded dense <code>Tensor</code>s.</li>
<li>It returns an <code>(inputs, labels)</code> pair.</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">MAX_TOKENS=128</span><br><span class="line">def prepare_batch(pt, en):</span><br><span class="line">    pt = tokenizers.pt.tokenize(pt)      # Output is ragged.</span><br><span class="line">    pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.</span><br><span class="line">    pt = pt.to_tensor()  # Convert to 0-padded dense Tensor</span><br><span class="line"></span><br><span class="line">    en = tokenizers.en.tokenize(en)</span><br><span class="line">    en = en[:, :(MAX_TOKENS+1)]</span><br><span class="line">    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens</span><br><span class="line">    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens</span><br><span class="line"></span><br><span class="line">    return (pt, en_inputs), en_labels</span><br></pre></td></tr></table></figure>

<p>The function below converts a dataset of text examples into data of batches for training.</p>
<ol>
<li>It tokenizes the text, and filters out the sequences that are too long. (The <code>batch</code>&#x2F;<code>unbatch</code> is included because the tokenizer is much more efficient on large batches).</li>
<li>The <code>cache</code> method ensures that that work is only executed once.</li>
<li>Then <code>shuffle</code> and, <code>dense_to_ragged_batch</code> randomize the order and assemble batches of examples.</li>
<li>Finally <code>prefetch</code> runs the dataset in parallel with the model to ensure that data is available when needed.</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">BUFFER_SIZE = 20000</span><br><span class="line">BATCH_SIZE = 64</span><br><span class="line">def make_batches(ds):</span><br><span class="line">  return (</span><br><span class="line">      ds</span><br><span class="line">      .shuffle(BUFFER_SIZE)</span><br><span class="line">      .batch(BATCH_SIZE)</span><br><span class="line">      .map(prepare_batch, tf.data.AUTOTUNE)</span><br><span class="line">      .prefetch(buffer_size=tf.data.AUTOTUNE))</span><br><span class="line"></span><br><span class="line"># Create training and validation set batches.</span><br><span class="line">train_batches = make_batches(train_examples)</span><br><span class="line">val_batches = make_batches(val_examples)     </span><br></pre></td></tr></table></figure>

<h2 id="Define-the-components"><a href="#Define-the-components" class="headerlink" title="Define the components"></a>Define the components</h2><p>we will start to implement the components of a Transformer as a standard sequence-to-sequence model with an encoder and a decoder.</p>
<figcaption align="center">
  <img src="../../images/assets/neural_machine_translation/image.png" >
  <figcaption>Figure 1. The original transformer diagram.</figcaption>
</figcaption>

<h3 id="The-embedding-and-positional-encoding-layer"><a href="#The-embedding-and-positional-encoding-layer" class="headerlink" title="The embedding and positional encoding layer"></a><strong>The embedding and positional encoding layer</strong></h3><p>The inputs to both the encoder and decoder use the same embedding and positional encoding logic.</p>
<figcaption align="center">
  <img src="../../images/assets/neural_machine_translation/image 1.png" >
</figcaption>

<p>A Transformer adds a “Positional Encoding” to the embedding vectors. It uses a set of sines and cosines at different frequencies (across the sequence). By definition nearby elements will have similar position encodings.</p>
<p>Using the following formula for calculating the positional encoding:</p>
<p>$\Large{PE_{(pos, 2i)} &#x3D; \sin(pos &#x2F; 10000^{2i &#x2F; d_{model}})}$$\Large{PE_{(pos, 2i+1)} &#x3D; \cos(pos &#x2F; 10000^{2i &#x2F; d_{model}})}$</p>
<p>The function using the vectors of sines and cosines  concatenated simply to implement it</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def positional_encoding(length, depth):</span><br><span class="line">  depth = depth/2</span><br><span class="line"></span><br><span class="line">  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)</span><br><span class="line">  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)</span><br><span class="line"></span><br><span class="line">  angle_rates = 1 / (10000**depths)         # (1, depth)</span><br><span class="line">  angle_rads = positions * angle_rates      # (pos, depth)</span><br><span class="line"></span><br><span class="line">  pos_encoding = np.concatenate(</span><br><span class="line">      [np.sin(angle_rads), np.cos(angle_rads)],</span><br><span class="line">      axis=-1)</span><br><span class="line"></span><br><span class="line">  return tf.cast(pos_encoding, dtype=tf.float32)</span><br></pre></td></tr></table></figure>

<p>The position encoding function is a stack of sines and cosines that vibrate at different frequencies depending on their location along the depth of the embedding vector. They vibrate across the position axis.</p>
<p>Creating a <code>PositionEmbedding</code> layer that looks-up a token’s embedding vector and adds the position vector:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">class PositionalEmbedding(tf.keras.layers.Layer):</span><br><span class="line">  def __init__(self, vocab_size, d_model):</span><br><span class="line">    super().__init__()</span><br><span class="line">    self.d_model = d_model</span><br><span class="line">    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)</span><br><span class="line">    self.pos_encoding = positional_encoding(length=2048, depth=d_model)</span><br><span class="line"></span><br><span class="line">  def compute_mask(self, *args, **kwargs):</span><br><span class="line">    return self.embedding.compute_mask(*args, **kwargs)</span><br><span class="line"></span><br><span class="line">  def call(self, x):</span><br><span class="line">    length = tf.shape(x)[1]</span><br><span class="line">    x = self.embedding(x)</span><br><span class="line">    # This factor sets the relative scale of the embedding and positonal_encoding.</span><br><span class="line">    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))</span><br><span class="line">    x = x + self.pos_encoding[tf.newaxis, :length, :]</span><br><span class="line">    return x</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Add-and-normalise"><a href="#Add-and-normalise" class="headerlink" title="Add and normalise"></a><strong>Add and normalise</strong></h3><figcaption align="center">
  <img src="../../images/assets/neural_machine_translation/image 2.png" >
</figcaption>

<p>These “Add &amp; Norm” blocks are scattered throughout the model. Each one joins a residual connection and runs the result through a <code>LayerNormalization</code> layer.</p>
<h3 id="The-base-attention-layer"><a href="#The-base-attention-layer" class="headerlink" title="The base attention layer"></a><strong>The base attention layer</strong></h3><p>Attention layers are used throughout the model. These are all identical except for how the attention is configured. Each one contains a <code>layers.MultiHeadAttention</code>, a <code>layers.LayerNormalization</code> and a <code>layers.Add</code></p>
<p>. And we will get started from a simple base class that just contains the component layers</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class BaseAttention(tf.keras.layers.Layer):</span><br><span class="line">  def __init__(self, **kwargs):</span><br><span class="line">    super().__init__()</span><br><span class="line">    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)</span><br><span class="line">    self.layernorm = tf.keras.layers.LayerNormalization()</span><br><span class="line">    self.add = tf.keras.layers.Add()</span><br></pre></td></tr></table></figure>

<h3 id="The-cross-attention-layer"><a href="#The-cross-attention-layer" class="headerlink" title="The cross attention layer"></a><strong>The cross attention layer</strong></h3><p>At the literal center of the Transformer is the cross-attention layer. This layer connects the encoder and decoder. This layer is the most straight-forward use of attention in the model, it performs the same task as the attention block</p>
<figcaption align="center">
  <img src="../../images/assets/neural_machine_translation/image 3.png" >
</figcaption>

<p>To implement this, we pass the target sequence <code>x</code> as the <code>query</code> and the <code>context</code> sequence as the <code>key/value</code> when calling the <code>mha</code> layer:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class CrossAttention(BaseAttention):</span><br><span class="line">  def call(self, x, context):</span><br><span class="line">    attn_output, attn_scores = self.mha(</span><br><span class="line">        query=x,</span><br><span class="line">        key=context,</span><br><span class="line">        value=context,</span><br><span class="line">        return_attention_scores=True)</span><br><span class="line"></span><br><span class="line">    # Cache the attention scores for plotting later.</span><br><span class="line">    self.last_attn_scores = attn_scores</span><br><span class="line"></span><br><span class="line">    x = self.add([x, attn_output])</span><br><span class="line">    x = self.layernorm(x)</span><br><span class="line"></span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test out the layer</span></span><br><span class="line">sample_ca = CrossAttention(num_heads=<span class="number">2</span>, key_dim=<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pt_emb.shape)</span><br><span class="line"><span class="built_in">print</span>(en_emb.shape)</span><br><span class="line"><span class="built_in">print</span>(sample_ca(en_emb, pt_emb).shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># result </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(64, 75, 512)</span></span><br><span class="line"><span class="string">(64, 53, 512)</span></span><br><span class="line"><span class="string">(64, 53, 512)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="The-global-self-attention-layer"><a href="#The-global-self-attention-layer" class="headerlink" title="The global self-attention layer"></a><strong>The global self-attention layer</strong></h3><p>This layer is responsible for processing the context sequence, and propagating information along its length:</p>
<figcaption align="center">
  <img src="../../images/assets/neural_machine_translation/image 4.png" >
</figcaption>

<p>To implement this layer we just need to pass the target sequence, <code>x</code>, as both the <code>query</code>, and <code>value</code> arguments to the <code>mha</code> layer:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class GlobalSelfAttention(BaseAttention):</span><br><span class="line">  def call(self, x):</span><br><span class="line">    attn_output = self.mha(</span><br><span class="line">        query=x,</span><br><span class="line">        value=x,</span><br><span class="line">        key=x)</span><br><span class="line">    x = self.add([x, attn_output])</span><br><span class="line">    x = self.layernorm(x)</span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test out the layer</span></span><br><span class="line">sample_gsa = GlobalSelfAttention(num_heads=<span class="number">2</span>, key_dim=<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pt_emb.shape)</span><br><span class="line"><span class="built_in">print</span>(sample_gsa(pt_emb).shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># result </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(64, 75, 512)</span></span><br><span class="line"><span class="string">(64, 75, 512)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="The-causal-self-attention-layer"><a href="#The-causal-self-attention-layer" class="headerlink" title="The causal self-attention layer"></a><strong>The causal self-attention layer</strong></h3><p>This layer does a similar job as the global self-attention layer, for the output sequence:</p>
<figcaption align="center">
  <img src="../../images/assets/neural_machine_translation/image 5.png" >
</figcaption>

<p>To build a causal self-attention layer, we need to use an appropriate mask when computing the attention scores and summing the attention <code>value</code>s. And we can solve this pass <code>use_causal_mask = True</code> to the <code>MultiHeadAttention</code> layer </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">class CausalSelfAttention(BaseAttention):</span><br><span class="line">  def call(self, x):</span><br><span class="line">    attn_output = self.mha(</span><br><span class="line">        query=x,</span><br><span class="line">        value=x,</span><br><span class="line">        key=x,</span><br><span class="line">        use_causal_mask = True)</span><br><span class="line">    x = self.add([x, attn_output])</span><br><span class="line">    x = self.layernorm(x)</span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test out the layer</span></span><br><span class="line">sample_csa = CausalSelfAttention(num_heads=<span class="number">2</span>, key_dim=<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(en_emb.shape)</span><br><span class="line"><span class="built_in">print</span>(sample_csa(en_emb).shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># result </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(64, 53, 512)</span></span><br><span class="line"><span class="string">(64, 53, 512)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="The-feed-forward-network"><a href="#The-feed-forward-network" class="headerlink" title="The feed forward network"></a><strong>The feed forward network</strong></h3><p>The transformer also includes this point-wise feed-forward network in both the encoder and decoder:</p>
<p>The network consists of two linear layers (<code>tf.keras.layers.Dense</code>) with a ReLU activation in-between, and a dropout layer. As with the attention layers the code here also includes the residual connection and normalization:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class FeedForward(tf.keras.layers.Layer):</span><br><span class="line">  def __init__(self, d_model, dff, dropout_rate=0.1):</span><br><span class="line">    super().__init__()</span><br><span class="line">    self.seq = tf.keras.Sequential([</span><br><span class="line">      tf.keras.layers.Dense(dff, activation=&#x27;relu&#x27;),</span><br><span class="line">      tf.keras.layers.Dense(d_model),</span><br><span class="line">      tf.keras.layers.Dropout(dropout_rate)</span><br><span class="line">    ])</span><br><span class="line">    self.add = tf.keras.layers.Add()</span><br><span class="line">    self.layer_norm = tf.keras.layers.LayerNormalization()</span><br><span class="line"></span><br><span class="line">  def call(self, x):</span><br><span class="line">    x = self.add([x, self.seq(x)])</span><br><span class="line">    x = self.layer_norm(x)</span><br><span class="line">    return x</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test out the layer</span></span><br><span class="line">sample_ffn = FeedForward(<span class="number">512</span>, <span class="number">2048</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(en_emb.shape)</span><br><span class="line"><span class="built_in">print</span>(sample_ffn(en_emb).shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># result </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(64, 53, 512)</span></span><br><span class="line"><span class="string">(64, 53, 512)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="The-encoder-layer"><a href="#The-encoder-layer" class="headerlink" title="The encoder layer"></a><strong>The encoder layer</strong></h3><p>The encoder contains a stack of <code>N</code> encoder layers. Where each <code>EncoderLayer</code> contains a <code>GlobalSelfAttention</code> and <code>FeedForward</code> layer:</p>
<figcaption align="center">
  <img src="../../images/assets/neural_machine_translation/image 6.png" >
</figcaption>

<p>Here is the definition of the <code>EncoderLayer</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class EncoderLayer(tf.keras.layers.Layer):</span><br><span class="line">  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):</span><br><span class="line">    super().__init__()</span><br><span class="line"></span><br><span class="line">    self.self_attention = GlobalSelfAttention(</span><br><span class="line">        num_heads=num_heads,</span><br><span class="line">        key_dim=d_model,</span><br><span class="line">        dropout=dropout_rate)</span><br><span class="line"></span><br><span class="line">    self.ffn = FeedForward(d_model, dff)</span><br><span class="line"></span><br><span class="line">  def call(self, x):</span><br><span class="line">    x = self.self_attention(x)</span><br><span class="line">    x = self.ffn(x)</span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>

<p>And a quick test again, the output will have the same shape as the input</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test out the layer</span></span><br><span class="line">sample_encoder_layer = EncoderLayer(d_model=<span class="number">512</span>, num_heads=<span class="number">8</span>, dff=<span class="number">2048</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pt_emb.shape)</span><br><span class="line"><span class="built_in">print</span>(sample_encoder_layer(pt_emb).shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># result </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(64, 75, 512)</span></span><br><span class="line"><span class="string">(64, 75, 512)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="The-encoder"><a href="#The-encoder" class="headerlink" title="The encoder"></a><strong>The encoder</strong></h3><figcaption align="center">
  <img src="../../images/assets/neural_machine_translation/image 7.png" >
</figcaption>

<p>The encoder consists of:</p>
<ul>
<li>A <code>PositionalEmbedding</code> layer at the input.</li>
<li>A stack of <code>EncoderLayer</code> layers.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">class Encoder(tf.keras.layers.Layer):</span><br><span class="line">  def __init__(self, *, num_layers, d_model, num_heads,</span><br><span class="line">               dff, vocab_size, dropout_rate=0.1):</span><br><span class="line">    super().__init__()</span><br><span class="line"></span><br><span class="line">    self.d_model = d_model</span><br><span class="line">    self.num_layers = num_layers</span><br><span class="line"></span><br><span class="line">    self.pos_embedding = PositionalEmbedding(</span><br><span class="line">        vocab_size=vocab_size, d_model=d_model)</span><br><span class="line"></span><br><span class="line">    self.enc_layers = [</span><br><span class="line">        EncoderLayer(d_model=d_model,</span><br><span class="line">                     num_heads=num_heads,</span><br><span class="line">                     dff=dff,</span><br><span class="line">                     dropout_rate=dropout_rate)</span><br><span class="line">        for _ in range(num_layers)]</span><br><span class="line">    self.dropout = tf.keras.layers.Dropout(dropout_rate)</span><br><span class="line"></span><br><span class="line">  def call(self, x):</span><br><span class="line">    # `x` is token-IDs shape: (batch, seq_len)</span><br><span class="line">    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.</span><br><span class="line"></span><br><span class="line">    # Add dropout.</span><br><span class="line">    x = self.dropout(x)</span><br><span class="line"></span><br><span class="line">    for i in range(self.num_layers):</span><br><span class="line">      x = self.enc_layers[i](x)</span><br><span class="line"></span><br><span class="line">    return x  # Shape `(batch_size, seq_len, d_model)`.</span><br></pre></td></tr></table></figure>

<p>And test the encoder:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test out the layer</span></span><br><span class="line"><span class="comment"># Instantiate the encoder.</span></span><br><span class="line">sample_encoder = Encoder(num_layers=<span class="number">4</span>,</span><br><span class="line">                         d_model=<span class="number">512</span>,</span><br><span class="line">                         num_heads=<span class="number">8</span>,</span><br><span class="line">                         dff=<span class="number">2048</span>,</span><br><span class="line">                         vocab_size=<span class="number">8500</span>)</span><br><span class="line"></span><br><span class="line">sample_encoder_output = sample_encoder(pt, training=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(pt.shape)</span><br><span class="line"><span class="built_in">print</span>(sample_encoder_output.shape)  <span class="comment"># Shape `(batch_size, input_seq_len, d_model)`.</span></span><br><span class="line"><span class="comment"># result </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(64, 75)</span></span><br><span class="line"><span class="string">(64, 75, 512)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="The-decoder-layer"><a href="#The-decoder-layer" class="headerlink" title="The decoder layer"></a><strong>The decoder layer</strong></h3><p>The decoder’s stack is slightly more complex, with each <code>DecoderLayer</code> containing a <code>CausalSelfAttention</code>, a <code>CrossAttention</code>, and a <code>FeedForward</code> layer:</p>
<figcaption align="center">
  <img src="../../images/assets/neural_machine_translation/image 8.png" >
</figcaption>

<p>Implement it:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">class DecoderLayer(tf.keras.layers.Layer):</span><br><span class="line">  def __init__(self,</span><br><span class="line">               *,</span><br><span class="line">               d_model,</span><br><span class="line">               num_heads,</span><br><span class="line">               dff,</span><br><span class="line">               dropout_rate=0.1):</span><br><span class="line">    super(DecoderLayer, self).__init__()</span><br><span class="line"></span><br><span class="line">    self.causal_self_attention = CausalSelfAttention(</span><br><span class="line">        num_heads=num_heads,</span><br><span class="line">        key_dim=d_model,</span><br><span class="line">        dropout=dropout_rate)</span><br><span class="line"></span><br><span class="line">    self.cross_attention = CrossAttention(</span><br><span class="line">        num_heads=num_heads,</span><br><span class="line">        key_dim=d_model,</span><br><span class="line">        dropout=dropout_rate)</span><br><span class="line"></span><br><span class="line">    self.ffn = FeedForward(d_model, dff)</span><br><span class="line"></span><br><span class="line">  def call(self, x, context):</span><br><span class="line">    x = self.causal_self_attention(x=x)</span><br><span class="line">    x = self.cross_attention(x=x, context=context)</span><br><span class="line"></span><br><span class="line">    # Cache the last attention scores for plotting later</span><br><span class="line">    self.last_attn_scores = self.cross_attention.last_attn_scores</span><br><span class="line"></span><br><span class="line">    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.</span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>

<p>Test the layer:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">sample_decoder_layer = DecoderLayer(d_model=<span class="number">512</span>, num_heads=<span class="number">8</span>, dff=<span class="number">2048</span>)</span><br><span class="line"></span><br><span class="line">sample_decoder_layer_output = sample_decoder_layer(</span><br><span class="line">    x=en_emb, context=pt_emb)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(en_emb.shape)</span><br><span class="line"><span class="built_in">print</span>(pt_emb.shape)</span><br><span class="line"><span class="built_in">print</span>(sample_decoder_layer_output.shape)  <span class="comment"># `(batch_size, seq_len, d_model)`</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># result</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(64, 53, 512)</span></span><br><span class="line"><span class="string">(64, 75, 512)</span></span><br><span class="line"><span class="string">(64, 53, 512)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="The-decoder"><a href="#The-decoder" class="headerlink" title="The decoder"></a><strong>The decoder</strong></h3><p>Similar to the <code>Encoder</code>, the <code>Decoder</code> consists of a <code>PositionalEmbedding</code>, and a stack of <code>DecoderLayer</code></p>
<figcaption align="center">
  <img src="../../images/assets/neural_machine_translation/image 9.png" >
</figcaption>

<p>Define the decoder by extending <code>tf.keras.layers.Layer</code>:  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">class Decoder(tf.keras.layers.Layer):</span><br><span class="line">  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,</span><br><span class="line">               dropout_rate=0.1):</span><br><span class="line">    super(Decoder, self).__init__()</span><br><span class="line"></span><br><span class="line">    self.d_model = d_model</span><br><span class="line">    self.num_layers = num_layers</span><br><span class="line"></span><br><span class="line">    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,</span><br><span class="line">                                             d_model=d_model)</span><br><span class="line">    self.dropout = tf.keras.layers.Dropout(dropout_rate)</span><br><span class="line">    self.dec_layers = [</span><br><span class="line">        DecoderLayer(d_model=d_model, num_heads=num_heads,</span><br><span class="line">                     dff=dff, dropout_rate=dropout_rate)</span><br><span class="line">        for _ in range(num_layers)]</span><br><span class="line"></span><br><span class="line">    self.last_attn_scores = None</span><br><span class="line"></span><br><span class="line">  def call(self, x, context):</span><br><span class="line">    # `x` is token-IDs shape (batch, target_seq_len)</span><br><span class="line">    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)</span><br><span class="line"></span><br><span class="line">    x = self.dropout(x)</span><br><span class="line"></span><br><span class="line">    for i in range(self.num_layers):</span><br><span class="line">      x  = self.dec_layers[i](x, context)</span><br><span class="line"></span><br><span class="line">    self.last_attn_scores = self.dec_layers[-1].last_attn_scores</span><br><span class="line"></span><br><span class="line">    # The shape of x is (batch_size, target_seq_len, d_model).</span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>

<p>Test the decoder:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Instantiate the decoder.</span></span><br><span class="line">sample_decoder = Decoder(num_layers=<span class="number">4</span>,</span><br><span class="line">                         d_model=<span class="number">512</span>,</span><br><span class="line">                         num_heads=<span class="number">8</span>,</span><br><span class="line">                         dff=<span class="number">2048</span>,</span><br><span class="line">                         vocab_size=<span class="number">8000</span>)</span><br><span class="line"></span><br><span class="line">output = sample_decoder(</span><br><span class="line">    x=en,</span><br><span class="line">    context=pt_emb)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the shapes.</span></span><br><span class="line"><span class="built_in">print</span>(en.shape)</span><br><span class="line"><span class="built_in">print</span>(pt_emb.shape)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># result</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(64, 53)</span></span><br><span class="line"><span class="string">(64, 75, 512)</span></span><br><span class="line"><span class="string">(64, 53, 512)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="The-Transformer"><a href="#The-Transformer" class="headerlink" title="The Transformer"></a><strong>The Transformer</strong></h3><p>Now we need to put  <code>Encoder</code> and <code>Decoder</code> together and add a final linear (<code>Dense</code>) layer which converts the resulting vector at each location into output token probabilities to finish the transformer model to be created.</p>
<figcaption align="center">
  <img src="../../images/assets/neural_machine_translation/image 10.png" >
</figcaption>

<p>Create the <code>Transformer</code> by extending <code>tf.keras.Model</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">class Transformer(tf.keras.Model):</span><br><span class="line">  def __init__(self, *, num_layers, d_model, num_heads, dff,</span><br><span class="line">               input_vocab_size, target_vocab_size, dropout_rate=0.1):</span><br><span class="line">    super().__init__()</span><br><span class="line">    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,</span><br><span class="line">                           num_heads=num_heads, dff=dff,</span><br><span class="line">                           vocab_size=input_vocab_size,</span><br><span class="line">                           dropout_rate=dropout_rate)</span><br><span class="line"></span><br><span class="line">    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,</span><br><span class="line">                           num_heads=num_heads, dff=dff,</span><br><span class="line">                           vocab_size=target_vocab_size,</span><br><span class="line">                           dropout_rate=dropout_rate)</span><br><span class="line"></span><br><span class="line">    self.final_layer = tf.keras.layers.Dense(target_vocab_size)</span><br><span class="line"></span><br><span class="line">  def call(self, inputs):</span><br><span class="line">    # To use a Keras model with `.fit` you must pass all your inputs in the</span><br><span class="line">    # first argument.</span><br><span class="line">    context, x  = inputs</span><br><span class="line"></span><br><span class="line">    context = self.encoder(context)  # (batch_size, context_len, d_model)</span><br><span class="line"></span><br><span class="line">    x = self.decoder(x, context)  # (batch_size, target_len, d_model)</span><br><span class="line"></span><br><span class="line">    # Final linear layer output.</span><br><span class="line">    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">      # Drop the keras mask, so it doesn&#x27;t scale the losses/metrics.</span><br><span class="line">      # b/250038731</span><br><span class="line">      del logits._keras_mask</span><br><span class="line">    except AttributeError:</span><br><span class="line">      pass</span><br><span class="line"></span><br><span class="line">    # Return the final output and the attention weights.</span><br><span class="line">    return logits</span><br></pre></td></tr></table></figure>

<p>define the hyperparameters, instantiate the model and test it out:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">num_layers = 4</span><br><span class="line">d_model = 128</span><br><span class="line">dff = 512</span><br><span class="line">num_heads = 8</span><br><span class="line">dropout_rate = 0.1</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  instantiate the model</span></span><br><span class="line">transformer = Transformer(</span><br><span class="line">    num_layers=num_layers,</span><br><span class="line">    d_model=d_model,</span><br><span class="line">    num_heads=num_heads,</span><br><span class="line">    dff=dff,</span><br><span class="line">    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),</span><br><span class="line">    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),</span><br><span class="line">    dropout_rate=dropout_rate)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># test</span></span><br><span class="line">output = transformer((pt, en))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(en.shape)</span><br><span class="line"><span class="built_in">print</span>(pt.shape)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># result</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(64, 53)</span></span><br><span class="line"><span class="string">(64, 75)</span></span><br><span class="line"><span class="string">(64, 53, 7010)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span> </span><br></pre></td></tr></table></figure>

<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><h3 id="Set-up-the-optimiser"><a href="#Set-up-the-optimiser" class="headerlink" title="Set up the optimiser"></a><strong>Set up the optimiser</strong></h3><p>Use the Adam optimiser with a custom learning rate scheduler according to the formula in the original Transformer <a target="_blank" rel="noopener" href="https://www.google.com/url?q=https://arxiv.org/abs/1706.03762">paper</a>.</p>
<p>$\Large{lrate &#x3D; d_{model}^{-0.5} * \min(step{_}num^{-0.5}, step{_}num \cdot warmup{_}steps^{-1.5})}$</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):</span><br><span class="line">  def __init__(self, d_model, warmup_steps=4000):</span><br><span class="line">    super().__init__()</span><br><span class="line"></span><br><span class="line">    self.d_model = d_model</span><br><span class="line">    self.d_model = tf.cast(self.d_model, tf.float32)</span><br><span class="line"></span><br><span class="line">    self.warmup_steps = warmup_steps</span><br><span class="line"></span><br><span class="line">  def __call__(self, step):</span><br><span class="line">    step = tf.cast(step, dtype=tf.float32)</span><br><span class="line">    arg1 = tf.math.rsqrt(step)</span><br><span class="line">    arg2 = step * (self.warmup_steps ** -1.5)</span><br><span class="line"></span><br><span class="line">    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)</span><br></pre></td></tr></table></figure>

<h3 id="Set-up-the-loss-and-metrics"><a href="#Set-up-the-loss-and-metrics" class="headerlink" title="Set up the loss and metrics"></a><strong>Set up the loss and metrics</strong></h3><p>We will use the cross-entropy loss function (<code>tf.keras.losses.SparseCategoricalCrossentropy</code>)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">def masked_loss(label, pred):</span><br><span class="line">  mask = label != 0</span><br><span class="line">  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(</span><br><span class="line">    from_logits=True, reduction=&#x27;none&#x27;)</span><br><span class="line">  loss = loss_object(label, pred)</span><br><span class="line"></span><br><span class="line">  mask = tf.cast(mask, dtype=loss.dtype)</span><br><span class="line">  loss *= mask</span><br><span class="line"></span><br><span class="line">  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)</span><br><span class="line">  return loss</span><br><span class="line"></span><br><span class="line">def masked_accuracy(label, pred):</span><br><span class="line">  pred = tf.argmax(pred, axis=2)</span><br><span class="line">  label = tf.cast(label, pred.dtype)</span><br><span class="line">  match = label == pred</span><br><span class="line"></span><br><span class="line">  mask = label != 0</span><br><span class="line"></span><br><span class="line">  match = match &amp; mask</span><br><span class="line"></span><br><span class="line">  match = tf.cast(match, dtype=tf.float32)</span><br><span class="line">  mask = tf.cast(mask, dtype=tf.float32)</span><br><span class="line">  return tf.reduce_sum(match)/tf.reduce_sum(mask)</span><br></pre></td></tr></table></figure>

<h3 id="Training-the-model"><a href="#Training-the-model" class="headerlink" title="Training the model"></a>Training the model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># compile and fit</span></span><br><span class="line">transformer.<span class="built_in">compile</span>(</span><br><span class="line">    loss=masked_loss,</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    metrics=[masked_accuracy])</span><br><span class="line">    </span><br><span class="line">transformer.fit(train_batches,</span><br><span class="line">                epochs=<span class="number">20</span>,</span><br><span class="line">                validation_data=val_batches)    </span><br></pre></td></tr></table></figure>

<h2 id="Run-inference"><a href="#Run-inference" class="headerlink" title="Run inference"></a><strong>Run inference</strong></h2><p>Define the <code>Translator</code> class by subclassing <code>tf.Module</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Translator</span>(tf.Module):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tokenizers, transformer</span>):</span><br><span class="line">    self.tokenizers = tokenizers</span><br><span class="line">    self.transformer = transformer</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, sentence, max_length=MAX_TOKENS</span>):</span><br><span class="line">    <span class="comment"># The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(sentence, tf.Tensor)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sentence.shape) == <span class="number">0</span>:</span><br><span class="line">      sentence = sentence[tf.newaxis]</span><br><span class="line"></span><br><span class="line">    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()</span><br><span class="line"></span><br><span class="line">    encoder_input = sentence</span><br><span class="line"></span><br><span class="line">    <span class="comment"># As the output language is English, initialize the output with the</span></span><br><span class="line">    <span class="comment"># English `[START]` token.</span></span><br><span class="line">    start_end = self.tokenizers.en.tokenize([<span class="string">&#x27;&#x27;</span>])[<span class="number">0</span>]</span><br><span class="line">    start = start_end[<span class="number">0</span>][tf.newaxis]</span><br><span class="line">    end = start_end[<span class="number">1</span>][tf.newaxis]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># `tf.TensorArray` is required here (instead of a Python list), so that the</span></span><br><span class="line">    <span class="comment"># dynamic-loop can be traced by `tf.function`.</span></span><br><span class="line">    output_array = tf.TensorArray(dtype=tf.int64, size=<span class="number">0</span>, dynamic_size=<span class="literal">True</span>)</span><br><span class="line">    output_array = output_array.write(<span class="number">0</span>, start)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tf.<span class="built_in">range</span>(max_length):</span><br><span class="line">      output = tf.transpose(output_array.stack())</span><br><span class="line">      predictions = self.transformer([encoder_input, output], training=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Select the last token from the `seq_len` dimension.</span></span><br><span class="line">      predictions = predictions[:, -<span class="number">1</span>:, :]  <span class="comment"># Shape `(batch_size, 1, vocab_size)`.</span></span><br><span class="line"></span><br><span class="line">      predicted_id = tf.argmax(predictions, axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Concatenate the `predicted_id` to the output which is given to the</span></span><br><span class="line">      <span class="comment"># decoder as its input.</span></span><br><span class="line">      output_array = output_array.write(i+<span class="number">1</span>, predicted_id[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> predicted_id == end:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    output = tf.transpose(output_array.stack())</span><br><span class="line">    <span class="comment"># The output shape is `(1, tokens)`.</span></span><br><span class="line">    text = tokenizers.en.detokenize(output)[<span class="number">0</span>]  <span class="comment"># Shape: `()`.</span></span><br><span class="line"></span><br><span class="line">    tokens = tokenizers.en.lookup(output)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># `tf.function` prevents us from using the attention_weights that were</span></span><br><span class="line">    <span class="comment"># calculated on the last iteration of the loop.</span></span><br><span class="line">    <span class="comment"># So, recalculate them outside the loop.</span></span><br><span class="line">    self.transformer([encoder_input, output[:,:-<span class="number">1</span>]], training=<span class="literal">False</span>)</span><br><span class="line">    attention_weights = self.transformer.decoder.last_attn_scores</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> text, tokens, attention_weights</span><br></pre></td></tr></table></figure>

<p>Create an instance of this <code>Translator</code> class, and try it out a few times:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">translator = Translator(tokenizers, transformer)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_translation</span>(<span class="params">sentence, tokens, ground_truth</span>):</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;<span class="string">&quot;Input:&quot;</span>:15s&#125;</span>: <span class="subst">&#123;sentence&#125;</span>&#x27;</span>)</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;<span class="string">&quot;Prediction&quot;</span>:15s&#125;</span>: <span class="subst">&#123;tokens.numpy().decode(<span class="string">&quot;utf-8&quot;</span>)&#125;</span>&#x27;</span>)</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;<span class="string">&quot;Ground truth&quot;</span>:15s&#125;</span>: <span class="subst">&#123;ground_truth&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example one</span></span><br><span class="line">sentence = <span class="string">&#x27;este é um problema que temos que resolver.&#x27;</span></span><br><span class="line">ground_truth = <span class="string">&#x27;this is a problem we have to solve .&#x27;</span></span><br><span class="line"></span><br><span class="line">translated_text, translated_tokens, attention_weights = translator(</span><br><span class="line">    tf.constant(sentence))</span><br><span class="line">print_translation(sentence, translated_text, ground_truth)</span><br><span class="line"></span><br><span class="line"><span class="comment">#result</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Input:        : este é um problema que temos que resolver.</span></span><br><span class="line"><span class="string">Prediction    : this is a problem we have to solve .</span></span><br><span class="line"><span class="string">Ground truth  : this is a problem we have to solve .</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example two</span></span><br><span class="line">sentence = <span class="string">&#x27;os meus vizinhos ouviram sobre esta ideia.&#x27;</span></span><br><span class="line">ground_truth = <span class="string">&#x27;and my neighboring homes heard about this idea .&#x27;</span></span><br><span class="line"></span><br><span class="line">translated_text, translated_tokens, attention_weights = translator(</span><br><span class="line">    tf.constant(sentence))</span><br><span class="line">print_translation(sentence, translated_text, ground_truth)</span><br><span class="line"></span><br><span class="line"><span class="comment">#result</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Input:        : os meus vizinhos ouviram sobre esta ideia .</span></span><br><span class="line"><span class="string">Prediction    : and my neighboring homes heard about this idea .</span></span><br><span class="line"><span class="string">Ground truth  : and my neighboring homes heard about this idea .</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example three</span></span><br><span class="line">sentence = <span class="string">&#x27;vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.&#x27;</span></span><br><span class="line">ground_truth = <span class="string">&quot;so i&#x27;ll just share with you some stories very quickly of some magical things that have happened.&quot;</span></span><br><span class="line"></span><br><span class="line">translated_text, translated_tokens, attention_weights = translator(</span><br><span class="line">    tf.constant(sentence))</span><br><span class="line">print_translation(sentence, translated_text, ground_truth)</span><br><span class="line"></span><br><span class="line"><span class="comment">#result</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Input:        : vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram .</span></span><br><span class="line"><span class="string">Prediction    : so i&#x27;ll just share with you some stories very quickly of some magical things that have happened .</span></span><br><span class="line"><span class="string">Ground truth  : so i&#x27;ll just share with you some stories very quickly of some magical things that have happened .</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="Export-the-model"><a href="#Export-the-model" class="headerlink" title="Export the model"></a>Export the model</h2><p>Create a class called <code>ExportTranslator</code> by subclassing the <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/Module"><code>tf.Module</code></a> subclass with a <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/function"><code>tf.function</code></a> on the <code>__call__</code> method:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class ExportTranslator(tf.Module):</span><br><span class="line">  def __init__(self, translator):</span><br><span class="line">    self.translator = translator</span><br><span class="line"></span><br><span class="line">  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])</span><br><span class="line">  def __call__(self, sentence):</span><br><span class="line">    (result,</span><br><span class="line">     tokens,</span><br><span class="line">     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)</span><br><span class="line"></span><br><span class="line">    return result</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">translator = ExportTranslator(translator)</span><br><span class="line">tf.saved_model.save(translator, export_dir=<span class="string">&#x27;translator&#x27;</span>)</span><br><span class="line">reloaded = tf.saved_model.load(<span class="string">&#x27;translator&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(reloaded(tf.constant(<span class="string">&#x27;este é o primeiro livro que eu fiz.&#x27;</span>)).numpy().decode(<span class="string">&quot;utf-8&quot;</span>))</span><br><span class="line"><span class="comment"># result: this is the first book I made.</span></span><br></pre></td></tr></table></figure>

<h2 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h2><p><a target="_blank" rel="noopener" href="https://github.com/PaddyZz/neural_machine_translation">https://github.com/PaddyZz/neural_machine_translation</a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>We have finised:</p>
<p>• Enviroment and Dependencies set up<br>• Data Handling (Datasets, Tokenizer, Data Pipeline)<br>• Define the components (encoder,decoder, attention layers and etc)<br>• Train the Model<br>• Run the inference<br>• Export the model</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">paper</a></p>
<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/datasets/catalog/ted_hrlr_translate#ted_hrlr_translatept_to_en">ted_hrlr_translate</a></p>
<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/text/tutorials/nmt_with_attention">Neural machine learning with attention</a></p>
<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/text/tutorials/transformer">Neural machine translation with a Transformer and Keras</a></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Neural machine translation</p><p><a class="link-muted" href="http://paddyzz.github.io/Projects/neural_machine_translation/">http://paddyzz.github.io/Projects/neural_machine_translation/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Paddy</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>31-05-2024</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>24-10-2024</p></div></div><div class="level-item is-narrow"><div><h6>Categories</h6><a class="link-muted is-uppercase is-size-7 article_license_category" href="/projects/">projects</a></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons article_license_logo" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons article_license_logo" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons article_license_logo" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1.5px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 mb-4" style="line-height:21px;height:0"><i class="fas fa-tags has-text-grey"></i><span> </span><a class="link-muted  tag-uppercase" rel="tag" href="/tags/DL/">DL<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/NLP/">NLP<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/ML/">ML<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/PROJECTS/">PROJECTS<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Python/">Python<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Seq-to-Seq/">Seq-to-Seq<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Tensorflow/">Tensorflow<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Keras/">Keras<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/transformer/">transformer<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/tokenizer/">tokenizer<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/self-attention/">self-attention<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/translation/">translation</a></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=665ef533f75dab0019ade953&amp;&amp;product=inline-share-buttons" defer></script></article></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/curriculum/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">curriculum</span></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://paddyzz.github.io/Projects/neural_machine_translation/';
            this.page.identifier = '/Projects/neural_machine_translation/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'paddys-disqus' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div> </div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://assets-global.website-files.com/653dcbdd718cbd5c51c4dbed/653f5e8549a0fbf7dc295818_IMG_20190205_193746-p-500.jpg" alt="Jiahe(Paddy) ZHAO"></figure><p class="title is-size-4 is-block" style="line-height:inherit;margin-bottom:0.5rem;">Jiahe(Paddy) ZHAO</p><p class="is-block" style="font-style:Italic;font-size:0.8rem;">Artificial Intelligence</p><p class="is-block" style="font-style:Italic;font-size:0.8rem;">Machine Learning</p><p class="is-block" style="font-style:Italic;font-size:0.8rem;">Deep Learning</p><p class="is-block" style="font-style:Italic;font-size:0.8rem;">Computer Science</p><p class="is-block" style="font-style:Italic;font-size:0.8rem;">Information Technology</p><p class="is-size-6 is-flex justify-content-center" style="margin-top:0.5rem;"><i class="fas fa-map-marker-alt mr-1"></i><span>Hebei, CHINA</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading widget-profile-article-fontsize-style title-font-style">Posts</p><a href="/archives"><p class="title widget-profile-number-style">14</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading widget-profile-article-fontsize-style title-font-style">Categories</p><a href="/categories"><p class="title widget-profile-number-style">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading widget-profile-article-fontsize-style title-font-style">Tags</p><a href="/tags"><p class="title widget-profile-number-style">61</p></a></div></div></nav><div class="level"><a class="level-item fake-button-style is-rounded widget-profile-follow-button-style title-font-style" href="mailto:jiahe.zhao@uq.net.au?body=Hello%2C%0A%0AIt%20would%20be%20greatly%20appreciated%20if%20you%20could%20send%20me%20an%20email%20using%20your%20personal%20email%20client%20rather%20than%20the%20current%20HTML%20popup%20one%2C%20as%20I%20may%20not%20receive%20your%20message.%0A%0AThank%20you." target="_blank" rel="noopener"> <i class="fa fa-envelope" style="font-size:16.75px;margin-right:0.6rem;"></i>Email Me</a><span>  </span><a class="level-item fake-button-style is-rounded widget-profile-follow-button-style title-font-style" href="https://www.linkedin.com/in/jiahe-paddy-zhao-213b24300" target="_blank" rel="noopener"> <i class="fa-brands fa-linkedin color-linkedin" style="font-size:16.75px;margin-right:0.6rem;"></i>LinkedIn</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless widget-profile-logo-style" target="_blank" rel="noopener" title="Github" href="https://github.com/paddyzz"><i class="fa-brands fa-github color-github"></i></a><a class="level-item button is-transparent is-marginless widget-profile-logo-style" target="_blank" rel="noopener" title="Kaggle" href="https://www.kaggle.com/paddyzhao/"><i class="fa-brands fa-kaggle color-kaggle"></i></a><a class="level-item button is-transparent is-marginless widget-profile-logo-style" target="_blank" rel="noopener" title="Facebook" href="https://www.facebook.com/profile.php?id=100087961621533"><i class="fa-brands fa-facebook-f color-facebook"></i></a><a class="level-item button is-transparent is-marginless widget-profile-logo-style" target="_blank" rel="noopener" title="X" href="https://x.com/paddyzhao150568"><i class="fa-brands fa-x-twitter color-X"></i></a><a class="level-item button is-transparent is-marginless widget-profile-logo-style" target="_blank" rel="noopener" title="Discord" href="https://discord.com/users/1001308889062576139"><i class="fa-brands fa-discord color-discord"></i></a></div></div></div><div class="card widget is-sticky" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#Set-up"><span class="level-left"><span class="level-item">2</span><span class="level-item">Set up</span></span></a></li><li><a class="level is-mobile" href="#Data-handling"><span class="level-left"><span class="level-item">3</span><span class="level-item">Data handling</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Download-the-dataset"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Download the dataset</span></span></a></li><li><a class="level is-mobile" href="#Set-up-the-tokenizer"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">Set up the tokenizer</span></span></a></li><li><a class="level is-mobile" href="#Set-up-a-data-pipeline-with-tf-data"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">Set up a data pipeline with tf.data</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Define-the-components"><span class="level-left"><span class="level-item">4</span><span class="level-item">Define the components</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#The-embedding-and-positional-encoding-layer"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">The embedding and positional encoding layer</span></span></a></li><li><a class="level is-mobile" href="#Add-and-normalise"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">Add and normalise</span></span></a></li><li><a class="level is-mobile" href="#The-base-attention-layer"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">The base attention layer</span></span></a></li><li><a class="level is-mobile" href="#The-cross-attention-layer"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">The cross attention layer</span></span></a></li><li><a class="level is-mobile" href="#The-global-self-attention-layer"><span class="level-left"><span class="level-item">4.5</span><span class="level-item">The global self-attention layer</span></span></a></li><li><a class="level is-mobile" href="#The-causal-self-attention-layer"><span class="level-left"><span class="level-item">4.6</span><span class="level-item">The causal self-attention layer</span></span></a></li><li><a class="level is-mobile" href="#The-feed-forward-network"><span class="level-left"><span class="level-item">4.7</span><span class="level-item">The feed forward network</span></span></a></li><li><a class="level is-mobile" href="#The-encoder-layer"><span class="level-left"><span class="level-item">4.8</span><span class="level-item">The encoder layer</span></span></a></li><li><a class="level is-mobile" href="#The-encoder"><span class="level-left"><span class="level-item">4.9</span><span class="level-item">The encoder</span></span></a></li><li><a class="level is-mobile" href="#The-decoder-layer"><span class="level-left"><span class="level-item">4.10</span><span class="level-item">The decoder layer</span></span></a></li><li><a class="level is-mobile" href="#The-decoder"><span class="level-left"><span class="level-item">4.11</span><span class="level-item">The decoder</span></span></a></li><li><a class="level is-mobile" href="#The-Transformer"><span class="level-left"><span class="level-item">4.12</span><span class="level-item">The Transformer</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Training"><span class="level-left"><span class="level-item">5</span><span class="level-item">Training</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Set-up-the-optimiser"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">Set up the optimiser</span></span></a></li><li><a class="level is-mobile" href="#Set-up-the-loss-and-metrics"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">Set up the loss and metrics</span></span></a></li><li><a class="level is-mobile" href="#Training-the-model"><span class="level-left"><span class="level-item">5.3</span><span class="level-item">Training the model</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Run-inference"><span class="level-left"><span class="level-item">6</span><span class="level-item">Run inference</span></span></a></li><li><a class="level is-mobile" href="#Export-the-model"><span class="level-left"><span class="level-item">7</span><span class="level-item">Export the model</span></span></a></li><li><a class="level is-mobile" href="#GitHub"><span class="level-left"><span class="level-item">8</span><span class="level-item">GitHub</span></span></a></li><li><a class="level is-mobile" href="#Conclusion"><span class="level-left"><span class="level-item">9</span><span class="level-item">Conclusion</span></span></a></li><li><a class="level is-mobile" href="#References"><span class="level-left"><span class="level-item">10</span><span class="level-item">References</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><!--!--><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div></div></div></section><footer class="footer" style="padding:2rem 0.75rem 2rem;"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/favicon.png" alt="Paddy - Paddy&#039;s Log Book" height="28"></a><p class="is-size-7"><span>&copy; 2023-2024 Paddy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a> &amp; <a href="/" target="_blank" rel="noopener">Paddy&#039;s FE Tech</a><br><span id="busuanzi_container_page_uv">Visited by <span id="busuanzi_value_page_uv">88</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent article_license_logo is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent article_license_logo is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent article_license_logo is-large" target="_blank" rel="noopener" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/universe.js"></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script type="text/javascript" src="/js/gsap_progressbar.js"></script><script type="text/javascript" src="/js/night.js"></script></body></html>