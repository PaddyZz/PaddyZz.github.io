<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Configure and deploy models on Kubeflow - Paddy - Paddy&#039;s Log Book</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Paddy - Paddy&#039;s Log Book"><meta name="msapplication-TileImage" content="/images/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Paddy - Paddy&#039;s Log Book"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="How to Configure Kubeflow on AWS EC2 and Deploy a Complete Model Inference Service on KServe in 2024 [Step-by-Step Guide]"><meta property="og:type" content="blog"><meta property="og:title" content="Configure and deploy models on Kubeflow"><meta property="og:url" content="http://paddyzz.github.io/projects/Config_Kubeflow/"><meta property="og:site_name" content="Paddy - Paddy&#039;s Log Book"><meta property="og:description" content="How to Configure Kubeflow on AWS EC2 and Deploy a Complete Model Inference Service on KServe in 2024 [Step-by-Step Guide]"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://paddyzz.github.io/images/assets/config_kubeflow/image%202.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/config_kubeflow/image.png"><meta property="og:image" content="http://paddyzz.github.io/images/assets/config_kubeflow/image%201.png"><meta property="article:published_time" content="2024-10-01T16:00:00.000Z"><meta property="article:modified_time" content="2024-10-24T00:00:00.000Z"><meta property="article:author" content="Paddy"><meta property="article:tag" content="DL"><meta property="article:tag" content="ML"><meta property="article:tag" content="PROJECTS"><meta property="article:tag" content="Conda"><meta property="article:tag" content="CICD"><meta property="article:tag" content="AWS"><meta property="article:tag" content="EC2"><meta property="article:tag" content="EKS"><meta property="article:tag" content="Docker"><meta property="article:tag" content="K8s"><meta property="article:tag" content="End-to-End"><meta property="article:tag" content="MLOps"><meta property="article:tag" content="Kubeflow"><meta property="article:tag" content="Bash"><meta property="article:tag" content="Python"><meta property="article:tag" content="Git"><meta property="article:tag" content="MinIO"><meta property="article:tag" content="Kserve"><meta property="article:tag" content="kfp"><meta property="article:tag" content="argo"><meta property="article:tag" content="Tekton"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://paddyzz.github.io/images/assets/config_kubeflow/image%202.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://paddyzz.github.io/projects/Config_Kubeflow/"},"headline":"Configure and deploy models on Kubeflow","image":["http://paddyzz.github.io/images/assets/config_kubeflow/image%202.png","http://paddyzz.github.io/images/assets/config_kubeflow/image.png","http://paddyzz.github.io/images/assets/config_kubeflow/image%201.png"],"datePublished":"2024-10-01T16:00:00.000Z","dateModified":"2024-10-24T00:00:00.000Z","author":{"@type":"Person","name":"Paddy"},"publisher":{"@type":"Organization","name":"Paddy - Paddy's Log Book","logo":{"@type":"ImageObject","url":"http://paddyzz.github.io/images/favicon.png"}},"description":"How to Configure Kubeflow on AWS EC2 and Deploy a Complete Model Inference Service on KServe in 2024 [Step-by-Step Guide]"}</script><link rel="canonical" href="http://paddyzz.github.io/projects/Config_Kubeflow/"><link rel="icon" href="/images/favicon.png"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.2/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="follow.it-verification-code" content="SdbKP9l6XayZRBYCuvDS"><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><script type="text/javascript" src="/js/svg-inject.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/gsap@3.3.4/dist/gsap.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/gsap@3.3.4/dist/ScrollTrigger.js"></script><progress max="100" value="0"></progress><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/favicon.png" alt="Paddy - Paddy&#039;s Log Book" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item navbar-item-home" href="/">PADDY&#039;S LOG BOOK</a><a class="navbar-item" href="/curriculum/">CURRICULUM</a><a class="navbar-item" href="/Certificates/">CERTIFICATES</a><a class="navbar-item" href="/blogs/">BLOGS</a><a class="navbar-item" href="/projects/">PROJECTS</a><a class="navbar-item" href="/life/">LIFE</a><a class="navbar-item" href="/archives/">ARCHIVES</a><a class="navbar-item" href="/categories/">CATEGORIES</a><a class="navbar-item" href="/tags/">TAGS</a><a class="navbar-item" href="/faqs/">FAQS</a></div><div class="navbar-end"><a class="navbar-item navbar-item-logo" id="star-nav" title="Nox Tenebratio!" style="opacity:0;display:none;userSelect:none;" href="javascript:;"><i class="fa fa-star-and-crescent" id="star-icon" style="font-size:17.75px"></i></a><a class="navbar-item navbar-item-logo night" id="night-nav" title="Nox!" href="javascript:;"><i class="fas fa-moon" id="night-icon" style="font-size:16.75px"></i></a><a class="navbar-item navbar-item-logo" id="night-nav" title="Email" href="mailto:jiahe.zhao@uq.net.au?body=Hello%2C%0A%0AIt%20would%20be%20greatly%20appreciated%20if%20you%20could%20send%20me%20an%20email%20using%20your%20personal%20email%20client%20rather%20than%20the%20current%20HTML%20popup%20one%2C%20as%20I%20may%20not%20receive%20your%20message.%0A%0AThank%20you."><i class="fas fa-envelope" style="font-size:16.75px"></i></a><a class="navbar-item navbar-item-logo" title="Gitter" target="_blank" rel="noopener" href="https://app.gitter.im/#/room/#Paddy/Community:gitter.im"><i class="fab fa-gitter" style="font-size:16.75px"></i></a><a class="navbar-item navbar-item-logo" title="Element" target="_blank" rel="noopener" href="https://app.element.io/#/room/#Paddy/Community:gitter.im"><svg version="1.0" id="svg-element" xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 225 225"><g fill="#4a4a4a"><path d="M91 1c-11 3-13 19-3 24l11 2c32 3 56 27 59 59 0 9 2 12 6 15 7 4 15 2 19-5l1-13c-1-11-3-19-9-31A87 87 0 0 0 91 1zM73 43a90 90 0 0 0-72 91c3 11 19 13 24 3l2-11c3-32 27-56 59-59 9 0 12-2 15-6 4-7 2-15-5-19H73zM208 82c-7 2-9 6-10 17-3 32-27 56-59 59-9 0-12 2-15 6-4 7-1 15 5 19l13 1c12-1 20-3 33-9a86 86 0 0 0 49-84c-1-4-6-9-8-9h-8zM47 124c-5 3-6 7-6 18 1 12 3 20 10 33 13 28 39 46 71 49 10 1 14 0 18-3 6-6 4-17-3-21l-11-2c-32-3-56-27-59-59l-2-10c-2-4-7-7-11-7l-7 2z"></path></g></svg></a><a class="navbar-item navbar-item-logo" title="GitHub" target="_blank" rel="noopener" href="https://github.com/paddyzz"><i class="fab fa-github" style="font-size:16.75px"></i></a><a class="navbar-item navbar-item-logo" title="Linkedin" target="_blank" rel="noopener" href="https://www.linkedin.com/in/jiahe-paddy-zhao-213b24300"><i class="fab fa-linkedin" style="font-size:19.75px"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item navbar-item-logo search" title="Search For It !" href="javascript:;"><i class="fa-brands fa-searchengin" style="font-size:19.75px"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-3 is-size-4-mobile title-font-style">Configure and deploy models on Kubeflow</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item author-capitalize"> Paddy </span><span class="level-item"><i class="far fa-calendar-alt"></i>&nbsp;<time dateTime="2024-10-01T16:00:00.000Z" title="02/10/2024, 12:00:00 am">02-10-2024</time></span><span class="level-item"><i class="far fa-calendar-check"></i>&nbsp;<time dateTime="2024-10-24T00:00:00.000Z" title="24/10/2024, 8:00:00 am">24-10-2024</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i><span> </span><a class="link-muted" href="/projects/">projects</a></span><span class="level-item"> <i class="far fa-clock"></i> <span> </span> an hour read<span> </span>( About 9678 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><article class="message is-info" style="margin-top:1.5rem;font-style:oblique"><div class="message-body">How to Configure Kubeflow on AWS EC2 and Deploy a Complete Model Inference Service on KServe in 2024 [Step-by-Step Guide]</div></article><div class="content card-content-font-style" style="margin-top:1.5rem;margin-bottom:1rem"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>This blog is mainly on how to deploy Kubeflow on AWS EC2 and create model inference services in Kubeflow. Since some of the tutorials available online seem to be outdated, and it’s common to encounter unexpected and challenging bugs during implementation. This blog will also share some of the pitfalls I’ve encountered, along with solutions for future reviewing and reference.</p>
<h2 id="Create-and-Configure-EC2-instance-in-AWS-console-dashboard"><a href="#Create-and-Configure-EC2-instance-in-AWS-console-dashboard" class="headerlink" title="Create and Configure EC2 instance in AWS console dashboard"></a>Create and Configure EC2 instance in AWS console dashboard</h2><p>We’ll using an EC2 instance to install awscli, eksctl, and other support tools needed to create the EKS Cluster and Install Kubeflow.</p>
<p>Login to the AWS Managment Console go to the AWS EC2 Dashboard</p>
<p>Click on “Launch Instance”</p>
<p>Name and tags Name:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeflow-cloud-shell</span><br></pre></td></tr></table></figure>

<p>OS Image (Ubuntu preferably, for following apt and other command needed installing):</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Ubuntu:latest</span><br></pre></td></tr></table></figure>

<p>create your EC2 instance pair-key for following connection and accessing after the instance created</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pair-key</span><br></pre></td></tr></table></figure>

<p>Instance type</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2.micro</span><br></pre></td></tr></table></figure>

<p>Network settings (You could use the default security group if you’ve already added ssh as an inbound rule)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Select <span class="string">&quot;Create Security Group&quot;</span></span><br><span class="line">Select <span class="string">&quot;Allow SSH traffic from&quot;</span></span><br><span class="line">Select <span class="string">&quot;Anywhere&quot;</span></span><br></pre></td></tr></table></figure>

<p>Storage （Bigger SSD storage set-up are better for avoiding unexpected and difficult debugging bugs on the following process of creating EKS cluster and its nodes-group）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SSD:30GB, EBS:gp3 volumes</span><br></pre></td></tr></table></figure>

<p>After setting up, review and launch your EC2 instance!</p>
<h2 id="Connect-and-access-your-EC2-instance"><a href="#Connect-and-access-your-EC2-instance" class="headerlink" title="Connect and access your EC2 instance!"></a>Connect and access your EC2 instance!</h2><p>There are three different ways to do that</p>
<ol>
<li><p>The first one is pretty simple and easy.<br>Just press the <code>connect</code> button on the EC2 dashboard, after navigate to launch page, press the <code>launch</code> button directly if you are fine with the default setting.</p>
</li>
<li><p>Using ssh command (if you save the pair-key format as .pem, or you could use PuTTYgen to convert your pair-key from .ppk to .pem format. And there also is a <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/connect-linux-inst-from-windows.html#:~:text=(Optional)-,Convert%20your%20private%20key%20using%20PuTTYgen,-PuTTY%20does%20not">tutorial</a> about how to implement it! )</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># open your Linux env bash terminal </span></span><br><span class="line"><span class="comment"># assume pwd is the directory you run ssh command from</span></span><br><span class="line">ssh -i &lt;pair-key.pem&gt; ubuntu@ec2-&lt;your-ec2-public-ipv4-DNS&gt; </span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Using PuTTY</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># open your PuTTy dashboard</span></span><br><span class="line">├── Session/</span><br><span class="line">	│   └── Logging/ <span class="comment"># fill out &lt;hostname(ip-address): ubuntu@ec2-&lt;public-ipv4-DNS&gt; &lt;port:22&gt; &lt;connection-type: SSH&gt;</span></span><br><span class="line">...</span><br><span class="line">└── Connection/</span><br><span class="line">    └── SSH/</span><br><span class="line">        └── Auth/ <span class="comment"># press &#x27;browse&#x27; button to add and configure your private key file with .ppk format for auth</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h2 id="Install-basic-tools-apt-conda-kubeflow-manifests-repo-etc"><a href="#Install-basic-tools-apt-conda-kubeflow-manifests-repo-etc" class="headerlink" title="Install basic tools (apt, conda, kubeflow-manifests repo etc)"></a>Install basic tools (apt, conda, kubeflow-manifests repo etc)</h2><p>Firstly, we need to stay the installation and other basic cmd updated</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install git curl unzip tar make sudo vim wget -y</span><br></pre></td></tr></table></figure>

<p>It would be better to install Conda for the following package needed installation efficiency, running-environment isolation and the reduction of dependency packages potential conflicts</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># We choose miniconda for lightweight installation and efficiency (Anaconda is also a good choice for flexibility</span></span><br><span class="line"><span class="built_in">mkdir</span> -p ~/miniconda3</span><br><span class="line">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh</span><br><span class="line">bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3</span><br><span class="line"><span class="built_in">rm</span> ~/miniconda3/miniconda.sh</span><br></pre></td></tr></table></figure>

<p>And we also need to change the system file ~&#x2F;.bashrc </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># edit the ~/.bashrc file using vim, nano etc</span></span><br><span class="line"><span class="comment"># adding the command below and save </span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;<span class="variable">$HOME</span>/miniconda3/bin:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Back to the terminal, run the cmd below, and restart the terminal to make it work</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>

<p>It now should be able to make the MiniConda work and stay in the ‘base’ mode</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># your temninal be like:</span></span><br><span class="line">(base) [ubuntu:&lt;Your private Ipv4 DNS&gt; ~]$</span><br></pre></td></tr></table></figure>

<p>We Could create and activate an env to set up the following packages needed</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># assume env-name is kubeflow_v1 or you could pick a name you happy with</span></span><br><span class="line"><span class="comment"># python version 3.8 or above are both acceptable </span></span><br><span class="line">conda create --name kubeflow_v1 python=3.8</span><br></pre></td></tr></table></figure>

<p>And the terminal should be like that after running</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(kubeflow_v1) [ubuntu:&lt;Your private Ipv4 DNS&gt; ~]$</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>and we use these commands ‘<code>$python3.8$</code>’, ‘<code>which pip3</code>’ and ‘<code>which pip</code>’ to check if they work simply</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$python3</span>.8</span><br><span class="line"><span class="comment"># and it should be like that</span></span><br><span class="line"><span class="comment"># input &#x27;exit()&#x27; to exit python terminal</span></span><br><span class="line">python3.8.x ......</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&gt;&gt;&gt; <span class="built_in">exit</span>()</span><br><span class="line">$</span><br><span class="line"><span class="variable">$which</span> pip</span><br><span class="line">/usr/bin/pip</span><br><span class="line"><span class="variable">$which</span> pip3</span><br><span class="line">/user/bin/pip3</span><br></pre></td></tr></table></figure>

<p>Alright, time for installing the main part of kubeflow: the latest and compatible Kubeflow and AWS release versions are showed below, you could also replace the tag <em><strong>KUBEFLOW_RELEASE_VERSION</strong></em> and <em><strong>AWS_RELEASE_VERSION</strong></em> with one you happy with. There is also an instruction about how to choose the <a target="_blank" rel="noopener" href="https://awslabs.github.io/kubeflow-manifests/docs/about/releases/">releases and versions</a> </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> KUBEFLOW_RELEASE_VERSION=v1.7.0</span><br><span class="line"><span class="built_in">export</span> AWS_RELEASE_VERSION=v1.7.0-aws-b1.0.3</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/awslabs/kubeflow-manifests.git &amp;&amp; <span class="built_in">cd</span> kubeflow-manifests</span><br><span class="line">git checkout <span class="variable">$&#123;AWS_RELEASE_VERSION&#125;</span></span><br><span class="line">git <span class="built_in">clone</span> --branch <span class="variable">$&#123;KUBEFLOW_RELEASE_VERSION&#125;</span> https://github.com/kubeflow/manifests.git upstream</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Make sure the terminal stay in the kubeflow-manifests directory and install tools needed from Makefile</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># it should be like:</span></span><br><span class="line">(kubeflow_v1) [ubuntu:&lt;Your private Ipv4 DNS&gt; kubeflow-manifests]$</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$make</span> install-tools</span><br></pre></td></tr></table></figure>

<p>After that, it might throw an exception about fail to install python3.8, but we could ignore it safely since we have get the python3.8 env configured and run the following command to continue to install the ones to be installed </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ make install-python-packages</span><br></pre></td></tr></table></figure>

<p>For more info about why the error happened, we could dive into the Makefile to check it out</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Makefile part of code snippets:</span></span><br><span class="line">...</span><br><span class="line">install-python:</span><br><span class="line">	sudo apt install -q python3.8 -y </span><br><span class="line">	sudo apt install -q python3-pip -y</span><br><span class="line">	python3.8 -m pip install --upgrade pip</span><br><span class="line"></span><br><span class="line">install-tools: ...... install-python ......</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>Since it seems to be showing exception apt:<code>python3.8 package not found</code> sometimes, we have configured env python3.8 and pip package so could feel free to ignore it.</p>
<p>Finally, ensure the packages below installed completely after run ‘<code>make install-tools</code>’</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html">AWS CLI</a> - A command line tool for interacting with AWS services.</li>
<li><a target="_blank" rel="noopener" href="https://eksctl.io/introduction/#installation">eksctl</a> - A command line tool for working with EKS clusters.</li>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/tools">kubectl</a> - A command line tool for working with Kubernetes clusters.</li>
<li><a target="_blank" rel="noopener" href="https://mikefarah.gitbook.io/yq">yq</a> - A command line tool for YAML processing. (For Linux environments, use the <a target="_blank" rel="noopener" href="https://github.com/mikefarah/yq/#install">wget plain binary installation</a>)</li>
<li><a target="_blank" rel="noopener" href="https://stedolan.github.io/jq/download/">jq</a> - A command line tool for processing JSON.</li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes-sigs/kustomize/releases/tag/kustomize%2Fv5.0.1">kustomize version 5.0.1</a> - A command line tool to customize Kubernetes objects through a kustomization file.</li>
<li><a target="_blank" rel="noopener" href="https://www.python.org/downloads/">python 3.8+</a> - A programming language used for automated installation scripts.</li>
<li><a target="_blank" rel="noopener" href="https://pip.pypa.io/en/stable/installation/">pip</a> - A package installer for python.</li>
<li><a target="_blank" rel="noopener" href="https://learn.hashicorp.com/tutorials/terraform/install-cli">terraform</a> - An infrastructure as code tool that lets you develop cloud and on-prem resources.</li>
<li><a target="_blank" rel="noopener" href="https://helm.sh/docs/intro/install/">helm</a> - A package manager for Kubernetes</li>
</ul>
<p>(referenced from <a target="_blank" rel="noopener" href="https://awslabs.github.io/kubeflow-manifests/docs/deployment/prerequisites/#:~:text=AWS%20CLI%20%2D%20A,manager%20for%20Kubernetes">awslabs</a>)</p>
<h2 id="Configure-AWS-credentials-regions-and-deploy-AWS-EKS-cluster-node-group"><a href="#Configure-AWS-credentials-regions-and-deploy-AWS-EKS-cluster-node-group" class="headerlink" title="Configure AWS credentials, regions and deploy AWS EKS cluster, node-group"></a>Configure AWS credentials, regions and deploy AWS EKS cluster, node-group</h2><p>For aws credentials config, you might need set up IAM credential to get your AWS account access key and secret key. Follow <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html">AWS CLI Configure Quickstart documentation</a> to setup your IAM credentials.</p>
<p>After getting the two keys, configure the AWS creds and regions for further EKS deployments</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">aws configure --profile=kubeflow</span><br><span class="line"><span class="comment"># AWS Access Key ID [None]: &lt;enter access key id&gt;</span></span><br><span class="line"><span class="comment"># AWS Secret Access Key [None]: &lt;enter secret access key&gt;</span></span><br><span class="line"><span class="comment"># Default region name [None]: &lt;AWS region&gt;</span></span><br><span class="line"><span class="comment"># Default output format [None]: json</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the AWS_PROFILE variable with the profile above</span></span><br><span class="line"><span class="built_in">export</span> AWS_PROFILE=kubeflow</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Once your configuration is complete, run ’<code>aws sts get-caller-identity</code>’ to verify that AWS CLI has access to your IAM credentials. And it should be fine if nothing error happened even though there is nothing print-out.</p>
<p>Configure your EKS cluster_name, region:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cluster_name &#x27;kubeflow&#x27; is just used for example</span></span><br><span class="line"><span class="built_in">export</span> CLUSTER_NAME=kuebflow</span><br><span class="line"><span class="comment"># us-east-1 is just used for example, please change that if it is not according to your account region</span></span><br><span class="line"><span class="built_in">export</span> CLUSTER_REGION=us-east-1</span><br></pre></td></tr></table></figure>

<p>Then we create EKS cluster and its node-group for kubeflow deployment.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make create-eks-cluster</span><br></pre></td></tr></table></figure>

<p>If you want to set up your own EKS cluster and node-group (EKS version,Nodes_number etc), please use the eksctl command to finish the set-up for reference.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">eksctl create cluster \</span><br><span class="line">	--name $(CLUSTER_NAME) \</span><br><span class="line">	--version 1.25 \</span><br><span class="line">	--region $(CLUSTER_REGION) \</span><br><span class="line">	--nodegroup-name linux-nodes \</span><br><span class="line">	--node-type m5.xlarge \</span><br><span class="line">	--nodes 5 \</span><br><span class="line">	--nodes-min 5 \</span><br><span class="line">	--nodes-max 10 \</span><br><span class="line">	--managed \</span><br><span class="line">	--with-oidc</span><br></pre></td></tr></table></figure>

<p>Generally, it may take just a few minutes to finish up.</p>
<p>But sometimes,unexpectedly,you might encounter the issue like <code>still waiting for AWS ***cloudFormation*** creating cluser &lt;cluster_name&gt;</code> <code>still waiting for ***cloudFormation*** creating node-group &lt;node_group_name&gt;</code> after waiting for a long time and even throw an TimeOut error sometimes. And the related blocks in AWS cloudFormation might show ROLL_BACK_Failed in status. One of the possible and simplest solutions is just accessing <em><strong>cloudFormation</strong></em>, deleting the block with the same name, and try it again.</p>
<p>Lastly,after it finish up, we use awscli and kubectl to check if the cluster and its node-group status is active and all fine(And in fact, it is likely to be working normally once the installation done)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">aws eks describe-cluster --region &lt;your-region&gt; --name &lt;your-cluster-name&gt; -query <span class="string">&quot;cluster.status&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>

<h2 id="Install-Kubeflow-Pods-required"><a href="#Install-Kubeflow-Pods-required" class="headerlink" title="Install Kubeflow Pods required"></a>Install Kubeflow Pods required</h2><h3 id="preparation"><a href="#preparation" class="headerlink" title="preparation"></a>preparation</h3><p>There are two preparation work we need to do</p>
<ol>
<li>replace the old image file with new one in the <a target="_blank" rel="noopener" href="https://github.com/awslabs/kubeflow-manifests/blob/db95e829cd21ad63315a7ef44110666c25c09570/charts/common/oidc-authservice/templates/StatefulSet/authservice-istio-system-StatefulSet.yaml#L25">**kubeflow-manifests&#x2F;charts&#x2F;common&#x2F;oidc-authservice&#x2F;templates&#x2F;StatefulSet&#x2F;authservice-istio-system-StatefulSet.yaml</a> file**</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># locate the following line in the file</span></span><br><span class="line">docker pull gcr.io/arrikto/kubeflow/oidc-authservice:e236439</span><br><span class="line"><span class="comment"># and replace it with the new docker file addr</span></span><br><span class="line">docker pull docker.io/kubeflowmanifestswg/oidc-authservice:e236439</span><br></pre></td></tr></table></figure>

<p>Otherwise it will result in oidc-authservice pod installation failed.</p>
<ol start="2">
<li>We need to install AWS EBS CSI driver for the EKS cluster created from accessing the AWS EKS dashboard add-ons. Otherwise it will result in the following pods installation failed like my-sql,minio pods etc with kubeflow-pipeline namespaces. Please reference the <a target="_blank" rel="noopener" href="https://docs.aws.amazon.com/eks/latest/userguide/ebs-csi.html">tutorial</a> to configure it.</li>
</ol>
<p>After that, let us go back to the kubeflow-manifests directory and install the Kubeflow Pods needed.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make deploy-kubeflow INSTALLATION_OPTION=helm DEPLOYMENT_OPTION=vanilla</span><br></pre></td></tr></table></figure>

<p>It should take up just a few mins. If the installation process get stuck in some pods deployment like oidc-authservice, kubeflow-pipeline etc from observing the print-out for a long time (like 5mins or above) and throw the timeout error constantly, please use CTRL+C to interrupt the installation, go back and check if the preparation work is all-set above and try again.</p>
<p>Finally, use the kubectl cmd below to check if all pods are all-set</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -n cert-manager</span><br><span class="line">kubectl get pods -n istio-system</span><br><span class="line">kubectl get pods -n auth</span><br><span class="line">kubectl get pods -n knative-eventing</span><br><span class="line">kubectl get pods -n knative-serving</span><br><span class="line">kubectl get pods -n kubeflow</span><br><span class="line">kubectl get pods -n kubeflow-user-example-com</span><br></pre></td></tr></table></figure>

<p>And there also are some useful commands to help debug and config the pods fail to work</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get all pods info, especially getting their names for debugging</span></span><br><span class="line">kubectl get pods --all-namespaces</span><br><span class="line"><span class="comment"># check the pod info</span></span><br><span class="line">kubectl describe pod &lt;pod_name&gt; -n &lt;namespace&gt;</span><br><span class="line"><span class="comment"># check the pod logs</span></span><br><span class="line">kubectl logs &lt;pod_name&gt; -n &lt;namespace&gt;</span><br><span class="line"><span class="comment"># once your figure the bug out, change the StatefulSet(pod controller used) set-up yaml of the pod</span></span><br><span class="line"><span class="comment"># and use the cmd below to get the StatefulSet name of the pod</span></span><br><span class="line">kubectl get pod &lt;pod_name&gt; -n &lt;namespace&gt; -o jsonpath=<span class="string">&#x27;&#123;.metadata.ownerReferences[*].name&#125;&#x27;</span></span><br><span class="line"><span class="comment"># then edit (it&#x27;ll open the vim ediot automatically if installed)</span></span><br><span class="line">kubectl edit statefulset &lt;statefulset_name&gt; -n &lt;namespace&gt;</span><br><span class="line"><span class="comment"># after editing and saving, exit the vim editor, it&#x27;ll apply the change automatically</span></span><br></pre></td></tr></table></figure>

<p>If it’s all going well,it’s time to connect the Kubeflow dashboard</p>
<h2 id="Connect-the-Kubeflow-Dashboard"><a href="#Connect-the-Kubeflow-Dashboard" class="headerlink" title="Connect the Kubeflow Dashboard"></a>Connect the Kubeflow Dashboard</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">make port-forward</span><br><span class="line"></span><br><span class="line"><span class="comment"># or you could change the port number if port：8080 in your local machine get occupied by other services</span></span><br><span class="line">$(<span class="built_in">eval</span> IP_ADDRESS:=127.0.0.1)</span><br><span class="line">$(<span class="built_in">eval</span> PORT:=8080)</span><br><span class="line">kubectl port-forward svc/istio-ingressgateway --address $(IP_ADDRESS) -n istio-system $(PORT):80</span><br></pre></td></tr></table></figure>

<p>and open another terminal to establish the connection</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#assume pwd is the directory you run ssh command from</span></span><br><span class="line">ssh -i &lt;pair-key.pem&gt; -L 8080:localhost:8080 -N ubuntu@ec2-&lt;your-ec2-public-ipv4-DNS&gt; </span><br></pre></td></tr></table></figure>

<p>go to the browser and input username: <a href="mailto:user@example.com">user@example.com</a> and password: 12341234</p>
<p>It’s advised that change the plain text password as hash one for security</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#this command will convert your plain text password input to hash formation by using bcrypt packages</span></span><br><span class="line">python3 -c <span class="string">&#x27;from passlib.hash import bcrypt; import getpass; print(bcrypt.using(rounds=12, ident=&quot;2y&quot;).hash(getpass.getpass()))&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>then edit <code>upstream/common/dex/base/config-map.yaml</code> and fill the relevant field with the hash one you chose:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  staticPasswords:</span><br><span class="line">  - email: user@example.com</span><br><span class="line">    <span class="built_in">hash</span>: &lt;enter the generated <span class="built_in">hash</span> here&gt;</span><br></pre></td></tr></table></figure>

<p>Congrats!!!, You should be able to see the Kubeflow dashboard now! And we have finished the Kubeflow Config on AWS EC2</p>
<figcaption align="center">
  <img src="../../images/assets/config_kubeflow/image 2.png" >
</figcaption>

<h2 id="Connect-the-Kubeflow-Notebooks-Server"><a href="#Connect-the-Kubeflow-Notebooks-Server" class="headerlink" title="Connect the Kubeflow Notebooks Server"></a>Connect the Kubeflow Notebooks Server</h2><p>Firstly, we need to apply the yaml file below to access Kubeflow pipeline service from notebooks server</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># access-kfp-from-notebooks.yaml</span></span><br><span class="line">apiVersion: kubeflow.org/v1alpha1  <span class="comment"># Specify the API version to interact with Kubeflow</span></span><br><span class="line">kind: PodDefault  <span class="comment"># This is a PodDefault object used to define default settings</span></span><br><span class="line">metadata:</span><br><span class="line">  name: access-ml-pipeline  <span class="comment"># Give this PodDefault a friendly name</span></span><br><span class="line">  namespace: kubeflow-user-example-com  <span class="comment"># kubeflow defalut namespace</span></span><br><span class="line">spec:</span><br><span class="line">  desc: Allow access to Kubeflow Pipelines  <span class="comment"># Describe the purpose of this PodDefault</span></span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      access-ml-pipeline: <span class="string">&quot;true&quot;</span>  <span class="comment"># Select Pods with this label to apply these default settings</span></span><br><span class="line">  volumes:</span><br><span class="line">    - name: volume-kf-pipeline-token  <span class="comment"># Define a name for the volume</span></span><br><span class="line">      projected:  <span class="comment"># Use a projected volume to include content from multiple sources</span></span><br><span class="line">        sources:</span><br><span class="line">          - serviceAccountToken:  <span class="comment"># Obtain a token from the service account</span></span><br><span class="line">              path: token  <span class="comment"># Path where the token will be stored in the volume</span></span><br><span class="line">              expirationSeconds: 7200  <span class="comment"># Set the token&#x27;s validity period to 2 hours, change that for longer period if u want</span></span><br><span class="line">              audience: pipelines.kubeflow.org  <span class="comment"># Specify the audience for the token as Kubeflow Pipelines</span></span><br><span class="line">  volumeMounts:</span><br><span class="line">    - mountPath: /var/run/secrets/kubeflow/pipelines  <span class="comment"># Specify the path where the volume will be mounted in the Pod</span></span><br><span class="line">      name: volume-kf-pipeline-token  <span class="comment"># Name of the volume being mounted</span></span><br><span class="line">      readOnly: <span class="literal">true</span>  <span class="comment"># Set the volume to read-only to protect the data</span></span><br><span class="line">  <span class="built_in">env</span>:</span><br><span class="line">    - name: KF_PIPELINES_SA_TOKEN_PATH  <span class="comment"># Set an environment variable to point to the token path</span></span><br><span class="line">      value: /var/run/secrets/kubeflow/pipelines/token  <span class="comment"># The value of this environment variable</span></span><br></pre></td></tr></table></figure>

<p>and apply the change by using kubectl cmd</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f access-kfp-from-notebooks.yaml</span><br></pre></td></tr></table></figure>

<p>then go to Kubeflow Notebooks dashboard and spin up a new notebook server for deploying our models on Kserve</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># config</span></span><br><span class="line"><span class="comment"># or change them witgh set-ups you happy with</span></span><br><span class="line">Name=kubeflow_v1</span><br><span class="line"><span class="comment"># configure the docker_image you happy with for env and package dependencies</span></span><br><span class="line">Docker_image=public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0 </span><br><span class="line">CPU=2, RAM=4GiB</span><br><span class="line">GPU=1， GPU Vendor=NVIDIA</span><br><span class="line">Workspace_volume=default</span><br><span class="line"></span><br><span class="line"><span class="comment"># please set up this config</span></span><br><span class="line">Configurations=allow access to Kfp Pipelines</span><br></pre></td></tr></table></figure>

<p>after creating, we need to set up MinIO to manage our working data</p>
<h2 id="Setup-MinIO-for-Object-Storage"><a href="#Setup-MinIO-for-Object-Storage" class="headerlink" title="Setup MinIO for Object Storage"></a>Setup MinIO for Object Storage</h2><p>we need another two terminal to deal with that, one for forwarding the MinIO pod’s port to the local port and the other one for making connection with the local port on local machine to access MinIO service</p>
<p>In the first one, using kubectl cmd to forward the port</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># you can also change the &lt;local-port: 9000&gt; as you want if it is occupied</span></span><br><span class="line">kubectl port-forward -n kubeflow svc/minio-service &lt;local-port&gt;:&lt;pod-port&gt;</span><br><span class="line">kubectl port-forward -n kubeflow svc/minio-service 9000:9000</span><br></pre></td></tr></table></figure>

<p>considering We need MinIO username and password to access MinIO dashboard for more info, which are <em><strong>minio</strong></em> and <em><strong>minio123</strong></em> separately，and just for sure, We can also access them by using kubctl cmd:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get accesskey (username)</span></span><br><span class="line">kubectl get secret mlpipeline-minio-artifact -n kubeflow -o jsonpath=<span class="string">&quot;&#123;.data.accesskey&#125;&quot;</span> | <span class="built_in">base64</span> --decode</span><br><span class="line"><span class="comment"># get secretkey (password)</span></span><br><span class="line">kubectl get secret mlpipeline-minio-artifact -n kubeflow -o jsonpath=<span class="string">&quot;&#123;.data.secretkey&#125;&quot;</span> | <span class="built_in">base64</span> --decode</span><br></pre></td></tr></table></figure>

<p>and it’s advised to change the default username and password for security. One <a target="_blank" rel="noopener" href="https://min.io/docs/minio/linux/administration/identity-access-management/minio-user-management.html#id3:~:text=Delete%20a%20User-,User%20Management,-Overview">Tutorial</a> for reference.</p>
<p>Alright in the second one, using ssh cmd to connect</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -i &lt;pair-key.pem&gt; -L 9000:localhost:9000 -N ubuntu@ec2-&lt;your-ipv4-DNS&gt;</span><br></pre></td></tr></table></figure>

<p>access <a target="_blank" rel="noopener" href="http://localhost/">***localhost</a>:9000*** in your local machine browser, enter the username and password. Now you should be able to see the MinIO dashboard like that:</p>
<figcaption align="center">
  <img src="../../images/assets/config_kubeflow/image.png" >
</figcaption>

<p>And then, we go ahead and start to deploy the kserve for inference service </p>
<h2 id="Setting-up-MinIO-secret-for-Kserve-for-inference-service"><a href="#Setting-up-MinIO-secret-for-Kserve-for-inference-service" class="headerlink" title="Setting up MinIO secret for Kserve for inference service"></a>Setting up MinIO secret for Kserve for inference service</h2><p>We need to apply this yaml file below so that the working data(train_dataset, models etc) which will be saved on minIO can be accessed by Kserve. Kserve could copy the model to be saved in the newly created inference container.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># apply-minio-secret-to-kserve.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: minio-kserve-secret  <span class="comment"># Name of the secret for accessing MinIO.</span></span><br><span class="line">  namespace: kubeflow-user-example-com  <span class="comment"># Namespace where this secret is located.</span></span><br><span class="line">  annotations:</span><br><span class="line">     serving.kserve.io/s3-endpoint: <span class="string">&quot;minio-service.kubeflow:9000&quot;</span>  <span class="comment"># Specifies the S3 endpoint for MinIO service.</span></span><br><span class="line">     serving.kserve.io/s3-usehttps: <span class="string">&quot;0&quot;</span>  <span class="comment"># Indicates that HTTPS is not used (0 means false).</span></span><br><span class="line">     serving.kserve.io/s3-useanoncredential: <span class="string">&quot;false&quot;</span>  <span class="comment"># Denotes that anonymous credentials are not used (false means credentials are required).</span></span><br><span class="line"><span class="built_in">type</span>: Opaque  <span class="comment"># Type of the secret, indicating it&#x27;s in plain text format.</span></span><br><span class="line">stringData:</span><br><span class="line">  AWS_ACCESS_KEY_ID: <span class="string">&quot;minio&quot;</span>  <span class="comment"># AWS access key ID for authentication.</span></span><br><span class="line">  AWS_SECRET_ACCESS_KEY: <span class="string">&quot;minio123&quot;</span>  <span class="comment"># AWS secret access key for authentication.</span></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: sa-minio-kserve  <span class="comment"># Name of the service account for MinIO access.</span></span><br><span class="line">  namespace: kubeflow-user-example-com  <span class="comment"># Namespace where this service account is created.</span></span><br><span class="line">secrets:</span><br><span class="line">- name: minio-kserve-secret  <span class="comment"># Associates the service account with the MinIO secret created earlier.</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>then we apply the yaml file for changes</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f apply-minio-secret-to-kserve.yaml</span><br></pre></td></tr></table></figure>

<p>After that, we start to deploy our models to Kserve from MinIO to check if the changes above work and get the inference service started.</p>
<h2 id="Deploy-models-on-Kserve-inference-services"><a href="#Deploy-models-on-Kserve-inference-services" class="headerlink" title="Deploy models on Kserve inference services"></a>Deploy models on Kserve inference services</h2><p>There are five ways to deal with that, first and second one would be a good choice for quick-start, and the third one have enough advantages on developing and debugging by using the most common component of Kubeflow, which is Kubeflow pipelines(Kfp). The fourth and fifth one are using argo workflow and tekton separately. Argo workflow is famous by its DAG, flexible execution flow and task reusability. Tekton is known by its structured pipeline and strong CI&#x2F;CD integration. And We will use one of my LSTM models for the demo. For more info about the model, please access the project:<a href="https://paddyzz.github.io/Projects/time_series_forecasting/">Time Series Forecasting(LSTM)</a></p>
<h3 id="Using-GitHub"><a href="#Using-GitHub" class="headerlink" title="Using GitHub"></a>Using GitHub</h3><ol>
<li>In the first method, We will be using the model uploaded on GitHub mainly and a few funcs from kfp components packages to deploy kserve inference services</li>
</ol>
<p>Since we have configured the connection to Kubeflow Jupyter notebooks server before, let’s create one new ipynb file with python kernel. </p>
<p>In the new file, clone the repo and take the model directory </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">!git <span class="built_in">clone</span> https://github.com/PaddyZz/Time_Series_Forecasting.git</span><br><span class="line">!<span class="built_in">mkdir</span> lstm_model_dir &amp;&amp; <span class="built_in">cp</span> .../repo_dir/models/* lstm_model_dir</span><br><span class="line"><span class="built_in">rm</span> -rf repo_dir</span><br></pre></td></tr></table></figure>

<p>then upload the model directory to MinIO bucket for kserve inference service. </p>
<p>Before that, we need to get the MinIO pod cluster IP</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get exact minio service name</span></span><br><span class="line">kubectl get svc -n kubeflow</span><br><span class="line"><span class="comment"># check out the cluster IP</span></span><br><span class="line">kubectl describe svc &lt;svc-name&gt; -n kubeflow</span><br></pre></td></tr></table></figure>

<p>after that, upload the model directory with the model</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">from minio import Minio</span><br><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line"></span><br><span class="line">minio_client = Minio(</span><br><span class="line">        <span class="string">&quot;&lt;MinIO clsuter-IP&gt;:9000&quot;</span>,</span><br><span class="line">        access_key=<span class="string">&quot;minio&quot;</span>,</span><br><span class="line">        secret_key=<span class="string">&quot;minio123&quot;</span>,</span><br><span class="line">        secure=False</span><br><span class="line">    )</span><br><span class="line">minio_bucket = <span class="string">&quot;mlpipeline&quot;</span> <span class="comment"># default bucket name</span></span><br><span class="line"></span><br><span class="line">def upload_local_directory_to_minio(local_path, bucket_name, minio_path):</span><br><span class="line">    assert os.path.isdir(local_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> local_file <span class="keyword">in</span> glob.glob(local_path + <span class="string">&#x27;/**&#x27;</span>):</span><br><span class="line">        local_file = local_file.replace(os.sep, <span class="string">&quot;/&quot;</span>) <span class="comment"># Replace \ with / on Windows</span></span><br><span class="line">        <span class="keyword">if</span> not os.path.isfile(local_file):</span><br><span class="line">            upload_local_directory_to_minio(</span><br><span class="line">                local_file, bucket_name, minio_path + <span class="string">&quot;/&quot;</span> + os.path.basename(local_file))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            remote_path = os.path.join(</span><br><span class="line">                minio_path, local_file[1 + len(local_path):])</span><br><span class="line">            remote_path = remote_path.replace(</span><br><span class="line">                os.sep, <span class="string">&quot;/&quot;</span>)  <span class="comment"># Replace \ with / on Windows</span></span><br><span class="line">            minio_client.fput_object(bucket_name, remote_path, local_file)</span><br><span class="line">            </span><br><span class="line">upload_local_directory_to_minio(<span class="string">&quot;/lstm_model_dir/&quot;</span>,minio_bucket,<span class="string">&quot;/models/lstm_model_dir/&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>you could have a look to see if there is the model directory in the MinIO bucket from the browser</p>
<p>After observing if there is no problem, deploy the inference service!</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import kfp</span><br><span class="line">import kfp.components as components</span><br><span class="line"></span><br><span class="line">def model_serving():</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    Create kserve instance</span></span><br><span class="line"><span class="string">    &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">    from kubernetes import client </span><br><span class="line">    from kserve import KServeClient</span><br><span class="line">    from kserve import constants</span><br><span class="line">    from kserve import utils</span><br><span class="line">    from kserve import V1beta1InferenceService</span><br><span class="line">    from kserve import V1beta1InferenceServiceSpec</span><br><span class="line">    from kserve import V1beta1PredictorSpec</span><br><span class="line">    from kserve import V1beta1TFServingSpec</span><br><span class="line"></span><br><span class="line">    namespace = utils.get_default_target_namespace()</span><br><span class="line"></span><br><span class="line">    name=<span class="string">&#x27;weather-prediction-kserve-inference-service-v1&#x27;</span></span><br><span class="line">    kserve_version=<span class="string">&#x27;v1beta1&#x27;</span></span><br><span class="line">    api_version = constants.KSERVE_GROUP + <span class="string">&#x27;/&#x27;</span> + kserve_version</span><br><span class="line"></span><br><span class="line">    isvc = V1beta1InferenceService(api_version=api_version,</span><br><span class="line">                                   kind=constants.KSERVE_KIND,</span><br><span class="line">                                   metadata=client.V1ObjectMeta(</span><br><span class="line">                                       name=name, namespace=namespace, annotations=&#123;<span class="string">&#x27;sidecar.istio.io/inject&#x27;</span>:<span class="string">&#x27;false&#x27;</span>&#125;),</span><br><span class="line">                                   spec=V1beta1InferenceServiceSpec(</span><br><span class="line">                                   predictor=V1beta1PredictorSpec(</span><br><span class="line">                                       service_account_name=<span class="string">&quot;sa-minio-kserve&quot;</span>, <span class="comment">#see apply-minio-secret-to-kserve.yaml</span></span><br><span class="line">                                       tensorflow=(V1beta1TFServingSpec(</span><br><span class="line">                                           storage_uri=<span class="string">&quot;s3://mlpipeline/models/lstm_model_dir&quot;</span>))))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    KServe = KServeClient()</span><br><span class="line">    KServe.create(isvc)</span><br><span class="line">    </span><br><span class="line">comp_model_serving = components.create_component_from_func(model_serving,base_image=<span class="string">&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;</span>,</span><br><span class="line">                                                           packages_to_install=[<span class="string">&#x27;kserve==0.8.0.1&#x27;</span>])   </span><br><span class="line"><span class="comment">#define the pipeline</span></span><br><span class="line">from kfp import dsl</span><br><span class="line">@dsl.pipeline(</span><br><span class="line">    name=<span class="string">&#x27;weather-pred-pipeline&#x27;</span>,</span><br><span class="line">    description=<span class="string">&#x27;weather-prediction&#x27;</span></span><br><span class="line">)</span><br><span class="line">def weather_pred():</span><br><span class="line">	comp_model_serving()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">		<span class="comment">#connect to kfp client</span></span><br><span class="line">		import requests</span><br><span class="line">    </span><br><span class="line">		USERNAME=<span class="string">&quot;user@example.com&quot;</span></span><br><span class="line">		PASSWORD=<span class="string">&quot;12341234&quot;</span></span><br><span class="line">		NAMESPACE=<span class="string">&quot;kubeflow-user-example-com&quot;</span></span><br><span class="line">		HOST=<span class="string">&#x27;http://istio-ingressgateway.istio-system.svc.cluster.local:80&#x27;</span></span><br><span class="line">		session=requests.Session()</span><br><span class="line">		response=session.get(HOST)</span><br><span class="line">		headers=&#123;<span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/x-www-form-urlencoded&quot;</span>,&#125;</span><br><span class="line">		data=&#123;<span class="string">&quot;login&quot;</span>: USERNAME, <span class="string">&quot;password&quot;</span>: PASSWORD&#125;</span><br><span class="line">		session.post(response.url, headers=headers, data=data)</span><br><span class="line">		session_cookie=session.cookies.get_dict()[<span class="string">&quot;authservice_session&quot;</span>]</span><br><span class="line">		client=kfp.Client(host=f<span class="string">&quot;&#123;HOST&#125;/pipeline&quot;</span>, cookies=f<span class="string">&quot;authservice_session=&#123;session_cookie&#125;&quot;</span>,)</span><br><span class="line">    client.create_run_from_pipeline_func(weather_pred,arguments=None,experiment_name=<span class="string">&quot;weather-prediction-v1-exp&quot;</span>)                                                            </span><br></pre></td></tr></table></figure>

<p>(access <code>Run</code> in Kubeflow central board menu panel and checkout the logs if the inference endpoint have not been set up correctly or there are other bugs) </p>
<p>then make a request to test the inference service.</p>
<p>Before that, We need some functions from my model project to get the inputs in tf.tensor for the inference input</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import pandas as pd</span><br><span class="line">import zipfile</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">def getDataset():</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    Downloads and extracts a CSV dataset from a remote ZIP file, processes the data, and returns a DataFrame and a Series.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The function performs the following steps:</span></span><br><span class="line"><span class="string">    1. Downloads a ZIP file containing the dataset from a specified URL.</span></span><br><span class="line"><span class="string">    2. Extracts the ZIP file into the current working directory.</span></span><br><span class="line"><span class="string">    3. Reads the CSV file from the extracted contents into a DataFrame.</span></span><br><span class="line"><span class="string">    4. Processes the DataFrame by slicing it to include every 6th row starting from the 5th row and converting the &#x27;Date Time&#x27; column to datetime objects.</span></span><br><span class="line"><span class="string">    5. Cleans up by removing the ZIP file and extracted CSV file.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        df (pd.DataFrame): Processed DataFrame containing the dataset with every 6th row.</span></span><br><span class="line"><span class="string">        date_time (pd.Series): Series containing datetime objects converted from the &#x27;Date Time&#x27; column.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Raises:</span></span><br><span class="line"><span class="string">        KeyError: If the &#x27;Date Time&#x27; column is not found in the CSV file.</span></span><br><span class="line"><span class="string">    &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    zip_path = tf.keras.utils.get_file(</span><br><span class="line">        origin=<span class="string">&#x27;https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip&#x27;</span>,</span><br><span class="line">        fname=<span class="string">&#x27;jena_climate_2009_2016.csv.zip&#x27;</span>,</span><br><span class="line">        extract=False)  </span><br><span class="line"></span><br><span class="line">    extract_dir = os.path.dirname(zip_path)</span><br><span class="line"></span><br><span class="line">    with zipfile.ZipFile(zip_path, <span class="string">&#x27;r&#x27;</span>) as zip_ref:</span><br><span class="line">        zip_ref.extractall(extract_dir)</span><br><span class="line">        extracted_files = zip_ref.namelist()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    csv_files = [f <span class="keyword">for</span> f <span class="keyword">in</span> extracted_files <span class="keyword">if</span> f.endswith(<span class="string">&#x27;.csv&#x27;</span>)]</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> csv_files:</span><br><span class="line">        csv_path = os.path.join(extract_dir, csv_files[0])</span><br><span class="line">        <span class="built_in">df</span> = pd.read_csv(csv_path)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;Date Time&#x27;</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">            <span class="comment"># sliceData</span></span><br><span class="line">            <span class="built_in">df</span> = <span class="built_in">df</span>[5::6]</span><br><span class="line">            date_time = pd.to_datetime(df.pop(<span class="string">&#x27;Date Time&#x27;</span>), format=<span class="string">&#x27;%d.%m.%Y %H:%M:%S&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            raise KeyError(<span class="string">&quot;&#x27;Date Time&#x27; column not found in the CSV file.&quot;</span>)</span><br><span class="line">            </span><br><span class="line">def splitDataAndNormalization(<span class="built_in">df</span>):</span><br><span class="line">    </span><br><span class="line">    n = len(<span class="built_in">df</span>)</span><br><span class="line">    train_df = <span class="built_in">df</span>[0:int(n*0.7)]</span><br><span class="line">    val_df = <span class="built_in">df</span>[int(n*0.7):int(n*0.9)]</span><br><span class="line">    test_df = <span class="built_in">df</span>[int(n*0.9):]</span><br><span class="line">    num_features = df.shape[1]</span><br><span class="line">    train_mean = train_df.mean()</span><br><span class="line">    train_std = train_df.std()</span><br><span class="line"></span><br><span class="line">    train_df = (train_df - train_mean) / train_std</span><br><span class="line">    val_df = (val_df - train_mean) / train_std <span class="comment">#validation_df</span></span><br><span class="line">    test_df = (test_df - train_mean) / train_std</span><br><span class="line">    <span class="built_in">return</span> train_df,val_df,test_df,num_features</span><br><span class="line"></span><br><span class="line">def cleanUpOutlier(<span class="built_in">df</span>):</span><br><span class="line">    wv = <span class="built_in">df</span>[<span class="string">&#x27;wv (m/s)&#x27;</span>]</span><br><span class="line">    bad_wv = wv == -9999.0</span><br><span class="line">    wv[bad_wv] = 0.0</span><br><span class="line"></span><br><span class="line">    max_wv = <span class="built_in">df</span>[<span class="string">&#x27;max. wv (m/s)&#x27;</span>]</span><br><span class="line">    bad_max_wv = max_wv == -9999.0</span><br><span class="line">    max_wv[bad_max_wv] = 0.0   </span><br><span class="line">            </span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">class WindowGenerator():</span><br><span class="line">  def __init__(self, input_width, label_width, <span class="built_in">shift</span>,</span><br><span class="line">               train_df, val_df, test_df,</span><br><span class="line">               label_columns=None):</span><br><span class="line">    <span class="comment"># Store the raw data.</span></span><br><span class="line">    self.train_df = train_df</span><br><span class="line">    self.val_df = val_df</span><br><span class="line">    self.test_df = test_df</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Work out the label column indices.</span></span><br><span class="line">    self.label_columns = label_columns</span><br><span class="line">    <span class="keyword">if</span> label_columns is not None:</span><br><span class="line">      self.label_columns_indices = &#123;name: i <span class="keyword">for</span> i, name <span class="keyword">in</span></span><br><span class="line">                                    enumerate(label_columns)&#125;</span><br><span class="line">    self.column_indices = &#123;name: i <span class="keyword">for</span> i, name <span class="keyword">in</span></span><br><span class="line">                           enumerate(train_df.columns)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Work out the window parameters.</span></span><br><span class="line">    self.input_width = input_width</span><br><span class="line">    self.label_width = label_width</span><br><span class="line">    self.shift = <span class="built_in">shift</span></span><br><span class="line"></span><br><span class="line">    self.total_window_size = input_width + <span class="built_in">shift</span></span><br><span class="line"></span><br><span class="line">    self.input_slice = slice(0, input_width)</span><br><span class="line">    self.input_indices = np.arange(self.total_window_size)[self.input_slice]</span><br><span class="line"></span><br><span class="line">    self.label_start = self.total_window_size - self.label_width</span><br><span class="line">    self.labels_slice = slice(self.label_start, None)</span><br><span class="line">    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]</span><br><span class="line"></span><br><span class="line">  def __repr__(self):</span><br><span class="line">    <span class="built_in">return</span> <span class="string">&#x27;\n&#x27;</span>.<span class="built_in">join</span>([</span><br><span class="line">        f<span class="string">&#x27;Total window size: &#123;self.total_window_size&#125;&#x27;</span>,</span><br><span class="line">        f<span class="string">&#x27;Input indices: &#123;self.input_indices&#125;&#x27;</span>,</span><br><span class="line">        f<span class="string">&#x27;Label indices: &#123;self.label_indices&#125;&#x27;</span>,</span><br><span class="line">        f<span class="string">&#x27;Label column name(s): &#123;self.label_columns&#125;&#x27;</span>])</span><br><span class="line"></span><br><span class="line">  @property</span><br><span class="line">  def train(self):</span><br><span class="line">    <span class="built_in">return</span> self.make_dataset(self.train_df)</span><br><span class="line"></span><br><span class="line">  @property</span><br><span class="line">  def val(self):</span><br><span class="line">    <span class="built_in">return</span> self.make_dataset(self.val_df)</span><br><span class="line"></span><br><span class="line">  @property</span><br><span class="line">  def <span class="built_in">test</span>(self):</span><br><span class="line">    <span class="built_in">return</span> self.make_dataset(self.test_df)</span><br><span class="line"></span><br><span class="line">  @property</span><br><span class="line">  def example(self):</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;Get and cache an example batch of `inputs, labels` for plotting.&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">    result = getattr(self, <span class="string">&#x27;_example&#x27;</span>, None)</span><br><span class="line">    <span class="keyword">if</span> result is None:</span><br><span class="line">        <span class="comment"># No example batch was found, so get one from the `.train` dataset</span></span><br><span class="line">        result = next(iter(self.train))</span><br><span class="line">        <span class="comment"># And cache it for next time</span></span><br><span class="line">        self._example = result</span><br><span class="line">    <span class="built_in">return</span> result</span><br><span class="line"></span><br><span class="line">  def plot(self, plot_col=<span class="string">&#x27;T (degC)&#x27;</span>, max_subplots=1, pred_tensor):</span><br><span class="line">    inputs, labels = self.example</span><br><span class="line">    plt.figure(figsize=(12, 8))</span><br><span class="line">    plot_col_index = self.column_indices[plot_col]</span><br><span class="line">    max_n = min(max_subplots, len(inputs))</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(max_n):</span><br><span class="line">      plt.subplot(max_n, 1, n+1)</span><br><span class="line">      plt.ylabel(f<span class="string">&#x27;&#123;plot_col&#125; [normed]&#x27;</span>)</span><br><span class="line">      plt.plot(self.input_indices, inputs[n, :, plot_col_index],</span><br><span class="line">              label=<span class="string">&#x27;Inputs&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>, zorder=-10)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> self.label_columns:</span><br><span class="line">        label_col_index = self.label_columns_indices.get(plot_col, None)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        label_col_index = plot_col_index</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> label_col_index is None:</span><br><span class="line">        <span class="built_in">continue</span></span><br><span class="line"> </span><br><span class="line">      plt.scatter(self.label_indices, pred_tensor[n, :, label_col_index],</span><br><span class="line">                    marker=<span class="string">&#x27;X&#x27;</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>, label=<span class="string">&#x27;Predictions&#x27;</span>,</span><br><span class="line">                    c=<span class="string">&#x27;#ff7f0e&#x27;</span>, s=64)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> n == 0:</span><br><span class="line">        plt.legend()</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Time [h]&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">  def split_window(self, features):</span><br><span class="line">        inputs = features[:, self.input_slice, :]</span><br><span class="line">        labels = features[:, self.labels_slice, :]</span><br><span class="line">        <span class="keyword">if</span> self.label_columns is not None:</span><br><span class="line">            labels = tf.stack(</span><br><span class="line">                [labels[:, :, self.column_indices[name]] <span class="keyword">for</span> name <span class="keyword">in</span> self.label_columns],</span><br><span class="line">                axis=-1)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Slicing doesn&#x27;t preserve static shape information, so set the shapes</span></span><br><span class="line">        <span class="comment"># manually. This way the `tf.data.Datasets` are easier to inspect.</span></span><br><span class="line">        inputs.set_shape([None, self.input_width, None])</span><br><span class="line">        labels.set_shape([None, self.label_width, None])</span><br><span class="line"></span><br><span class="line">        <span class="built_in">return</span> inputs, labels</span><br><span class="line"></span><br><span class="line">  def make_dataset(self, data):</span><br><span class="line">        data = np.array(data, dtype=np.float32)</span><br><span class="line">        ds = tf.keras.utils.timeseries_dataset_from_array(</span><br><span class="line">            data=data,</span><br><span class="line">            targets=None,</span><br><span class="line">            sequence_length=self.total_window_size,</span><br><span class="line">            sequence_stride=1,</span><br><span class="line">            shuffle=True,</span><br><span class="line">            batch_size=32,)</span><br><span class="line"></span><br><span class="line">        ds = ds.map(self.split_window)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">return</span> ds      </span><br><span class="line">      </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">	from kserve import KServeClient</span><br><span class="line">  import requests</span><br><span class="line"></span><br><span class="line">	<span class="built_in">df</span>, date_time = getDataset()        </span><br><span class="line">	cleanUpOutlier(<span class="built_in">df</span>)</span><br><span class="line">	train_df,val_df,test_df,_ = splitDataAndNormalization(<span class="built_in">df</span>)</span><br><span class="line">	wide_window = WindowGenerator(</span><br><span class="line">	        input_width=24, label_width=24, <span class="built_in">shift</span>=24,</span><br><span class="line">	        train_df=train_df,val_df=val_df,test_df=test_df,</span><br><span class="line">	        label_columns=None)</span><br><span class="line">	inputs, _=wide_window.example</span><br><span class="line">	</span><br><span class="line">	KServe = KServeClient()</span><br><span class="line">	</span><br><span class="line">	isvc_resp = KServe.get(<span class="string">&quot;weather-prediction-kserve-inference-service-v1&quot;</span>, namespace=<span class="string">&quot;kubeflow-user-example-com&quot;</span>)</span><br><span class="line">	isvc_url = isvc_resp[<span class="string">&#x27;status&#x27;</span>][<span class="string">&#x27;address&#x27;</span>][<span class="string">&#x27;url&#x27;</span>]</span><br><span class="line">	inference_input = &#123;</span><br><span class="line">	  <span class="string">&#x27;instances&#x27;</span>: inputs.numpy().tolist()</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	response = requests.post(isvc_url, json=inference_input)</span><br><span class="line">	predictions = response.json()[<span class="string">&#x27;predictions&#x27;</span>]</span><br><span class="line">	pred_tensor = tf.convert_to_tensor(predictions)</span><br><span class="line">	wide_window.plot(pred_tensor=pred_tensor)</span><br></pre></td></tr></table></figure>

<p>after getting inputs tensor, We change the tensor format as list for inference input and make an request to the endpoint deployed with the list. And we use the plot function to plot the response data got back from the endpoint. And the pic is like:</p>
<figcaption align="center">
  <img src="../../images/assets/config_kubeflow/image 1.png" >
</figcaption>

<h3 id="Using-Docker"><a href="#Using-Docker" class="headerlink" title="Using Docker"></a>Using Docker</h3><ol>
<li>In the second method, we use docker to implement it will be similar to the first one</li>
</ol>
<p>open a new Jupyter file and pull the docker image</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pull the image</span></span><br><span class="line">client = docker.from_env()</span><br><span class="line">image = client.images.pull(<span class="string">&quot;&lt;docker_image_address&gt;&quot;</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Launch the container</span></span><br><span class="line">container = client.containers.run(</span><br><span class="line">    image=image.tags[0],</span><br><span class="line">    name=<span class="string">&quot;my_container&quot;</span>,</span><br><span class="line">    detach=True,</span><br><span class="line">    <span class="built_in">command</span>=<span class="string">&quot;tail -f /dev/null&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Exec the container and check out the model dir</span></span><br><span class="line">result = container.exec_run(<span class="string">&quot;ls /path/to/your/model&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(result.output.decode())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Copy the model dir to the expected dir in the Jupyter server</span></span><br><span class="line">container.copy(<span class="string">&quot;my_container:/path/to/your/model&quot;</span>, <span class="string">&quot;/local/path/to/save/model&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Stop and delete container</span></span><br><span class="line">container.stop()</span><br><span class="line">container.remove()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>and then repeat the steps in the first method to deploy the kserve inference service</p>
<h3 id="Using-Kubeflow-pipeline-kfp"><a href="#Using-Kubeflow-pipeline-kfp" class="headerlink" title="Using Kubeflow pipeline(kfp)"></a>Using Kubeflow pipeline(kfp)</h3><ol>
<li><p>In the third method, we use kfp component fully to finish the most of MLOps including data_ingestion, pretrain_model, model_fit_train and the kserve inference service deployment，these 4 phases. And the implementing code will be similar to method one about data_ingestion and pretrain_model phases.</p>
<p> Here is the code showing complete process of the phases and testing on Kfp</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import pandas as pd</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import zipfile</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">import minio </span><br><span class="line">minio_client = minio(</span><br><span class="line">        <span class="string">&quot;&lt;your-minio-cluster-ip&gt;:9000&quot;</span>,</span><br><span class="line">        access_key=<span class="string">&quot;minio&quot;</span>,</span><br><span class="line">        secret_key=<span class="string">&quot;minio123&quot;</span>,</span><br><span class="line">        secure=False</span><br><span class="line">    )</span><br><span class="line">minio_bucket = <span class="string">&quot;mlpipeline&quot;</span></span><br><span class="line"></span><br><span class="line">def getDataset():</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    Downloads and extracts a CSV dataset from a remote ZIP file, processes the data, and returns a DataFrame and a Series.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The function performs the following steps:</span></span><br><span class="line"><span class="string">    1. Downloads a ZIP file containing the dataset from a specified URL.</span></span><br><span class="line"><span class="string">    2. Extracts the ZIP file into the current working directory.</span></span><br><span class="line"><span class="string">    3. Reads the CSV file from the extracted contents into a DataFrame.</span></span><br><span class="line"><span class="string">    4. Processes the DataFrame by slicing it to include every 6th row starting from the 5th row and converting the &#x27;Date Time&#x27; column to datetime objects.</span></span><br><span class="line"><span class="string">    5. Cleans up by removing the ZIP file and extracted CSV file.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        df (pd.DataFrame): Processed DataFrame containing the dataset with every 6th row.</span></span><br><span class="line"><span class="string">        date_time (pd.Series): Series containing datetime objects converted from the &#x27;Date Time&#x27; column.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Raises:</span></span><br><span class="line"><span class="string">        KeyError: If the &#x27;Date Time&#x27; column is not found in the CSV file.</span></span><br><span class="line"><span class="string">    &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    zip_path = tf.keras.utils.get_file(</span><br><span class="line">        origin=<span class="string">&#x27;https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip&#x27;</span>,</span><br><span class="line">        fname=<span class="string">&#x27;jena_climate_2009_2016.csv.zip&#x27;</span>,</span><br><span class="line">        extract=False)  </span><br><span class="line"></span><br><span class="line">    extract_dir = os.path.dirname(zip_path)</span><br><span class="line"></span><br><span class="line">    with zipfile.ZipFile(zip_path, <span class="string">&#x27;r&#x27;</span>) as zip_ref:</span><br><span class="line">        zip_ref.extractall(extract_dir)</span><br><span class="line">        extracted_files = zip_ref.namelist()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    csv_files = [f <span class="keyword">for</span> f <span class="keyword">in</span> extracted_files <span class="keyword">if</span> f.endswith(<span class="string">&#x27;.csv&#x27;</span>)]</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> csv_files:</span><br><span class="line">        csv_path = os.path.join(extract_dir, csv_files[0])</span><br><span class="line">        <span class="built_in">df</span> = pd.read_csv(csv_path)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;Date Time&#x27;</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">            <span class="comment"># sliceData</span></span><br><span class="line">            <span class="built_in">df</span> = <span class="built_in">df</span>[5::6]</span><br><span class="line">            date_time = pd.to_datetime(df.pop(<span class="string">&#x27;Date Time&#x27;</span>), format=<span class="string">&#x27;%d.%m.%Y %H:%M:%S&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            raise KeyError(<span class="string">&quot;&#x27;Date Time&#x27; column not found in the CSV file.&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> os.path.exists(zip_path):</span><br><span class="line">        os.remove(zip_path)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> file_name <span class="keyword">in</span> extracted_files:</span><br><span class="line">        file_path = os.path.join(extract_dir, file_name)</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(file_path):</span><br><span class="line">            os.remove(file_path)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    df_npy = df.to_numpy()</span><br><span class="line">    np.save(<span class="string">&quot;dataframes/df.npy&quot;</span>,df_npy)</span><br><span class="line">    minio_client.fput_object(minio_bucket,<span class="string">&quot;models/lstm/df&quot;</span>,<span class="string">&quot;dataframes/df.npy&quot;</span>)    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">def splitDataAndNormalization():</span><br><span class="line">    minio_client.fget_object(minio_bucket,<span class="string">&quot;models/lstm/df&quot;</span>,<span class="string">&quot;dataframes/df.npy&quot;</span>) </span><br><span class="line">    df_npy = np.load(<span class="string">&#x27;dataframes/df.npy&#x27;</span>)</span><br><span class="line">    <span class="built_in">df</span> = pd.DataFrame(df_npy)</span><br><span class="line">    wv = <span class="built_in">df</span>[<span class="string">&#x27;wv (m/s)&#x27;</span>]</span><br><span class="line">    bad_wv = wv == -9999.0</span><br><span class="line">    wv[bad_wv] = 0.0</span><br><span class="line"></span><br><span class="line">    max_wv = <span class="built_in">df</span>[<span class="string">&#x27;max. wv (m/s)&#x27;</span>]</span><br><span class="line">    bad_max_wv = max_wv == -9999.0</span><br><span class="line">    max_wv[bad_max_wv] = 0.0</span><br><span class="line">    </span><br><span class="line">    n = len(<span class="built_in">df</span>)</span><br><span class="line">    train_df = <span class="built_in">df</span>[0:int(n*0.7)]</span><br><span class="line">    val_df = <span class="built_in">df</span>[int(n*0.7):int(n*0.9)]</span><br><span class="line">    test_df = <span class="built_in">df</span>[int(n*0.9):]</span><br><span class="line">    num_features = df.shape[1]</span><br><span class="line">    train_mean = train_df.mean()</span><br><span class="line">    train_std = train_df.std()</span><br><span class="line"></span><br><span class="line">    train_df = (train_df - train_mean) / train_std</span><br><span class="line">    val_df = (val_df - train_mean) / train_std <span class="comment">#validation_df</span></span><br><span class="line">    test_df = (test_df - train_mean) / train_std</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    train_npy = train_df.to_numpy()</span><br><span class="line">    test_npy = test_df.to_numpy()</span><br><span class="line">    val_npy = val_df.to_numpy()</span><br><span class="line">    np.save(<span class="string">&quot;dataframes/train.npy&quot;</span>,train_npy)</span><br><span class="line">    np.save(<span class="string">&quot;dataframes/test.npy&quot;</span>,test_npy)</span><br><span class="line">    np.save(<span class="string">&quot;dataframes/val.npy&quot;</span>,val_npy)</span><br><span class="line">    minio_client.fput_object(minio_bucket,<span class="string">&quot;models/lstm/train&quot;</span>,<span class="string">&quot;dataframes/train.npy&quot;</span>)  </span><br><span class="line">    minio_client.fput_object(minio_bucket,<span class="string">&quot;models/lstm/test&quot;</span>,<span class="string">&quot;dataframes/test.npy&quot;</span>) </span><br><span class="line">    minio_client.fput_object(minio_bucket,<span class="string">&quot;models/lstm/val&quot;</span>,<span class="string">&quot;dataframes/val.npy&quot;</span>)  </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">def compile_and_fit(model, window, patience=2):</span><br><span class="line"></span><br><span class="line">    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">                                                        patience=patience,</span><br><span class="line">                                                        mode=<span class="string">&#x27;min&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    model.compile(loss=tf.keras.losses.MeanSquaredError(),</span><br><span class="line">                    optimizer=tf.keras.optimizers.Adam(),</span><br><span class="line">                    metrics=[tf.keras.metrics.MeanAbsoluteError()])</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">history</span> = model.fit(window.train, epochs=20,</span><br><span class="line">                        validation_data=window.val,</span><br><span class="line">                        callbacks=[early_stopping])</span><br><span class="line">    </span><br><span class="line">                        </span><br><span class="line">    <span class="built_in">return</span> <span class="built_in">history</span>   </span><br><span class="line">    </span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">class WindowGenerator():</span><br><span class="line">  def __init__(self, input_width, label_width, <span class="built_in">shift</span>,</span><br><span class="line">               train_df, val_df, test_df,</span><br><span class="line">               label_columns=None):</span><br><span class="line">    <span class="comment"># Store the raw data.</span></span><br><span class="line">    self.train_df = train_df</span><br><span class="line">    self.val_df = val_df</span><br><span class="line">    self.test_df = test_df</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Work out the label column indices.</span></span><br><span class="line">    self.label_columns = label_columns</span><br><span class="line">    <span class="keyword">if</span> label_columns is not None:</span><br><span class="line">      self.label_columns_indices = &#123;name: i <span class="keyword">for</span> i, name <span class="keyword">in</span></span><br><span class="line">                                    enumerate(label_columns)&#125;</span><br><span class="line">    self.column_indices = &#123;name: i <span class="keyword">for</span> i, name <span class="keyword">in</span></span><br><span class="line">                           enumerate(train_df.columns)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Work out the window parameters.</span></span><br><span class="line">    self.input_width = input_width</span><br><span class="line">    self.label_width = label_width</span><br><span class="line">    self.shift = <span class="built_in">shift</span></span><br><span class="line"></span><br><span class="line">    self.total_window_size = input_width + <span class="built_in">shift</span></span><br><span class="line"></span><br><span class="line">    self.input_slice = slice(0, input_width)</span><br><span class="line">    self.input_indices = np.arange(self.total_window_size)[self.input_slice]</span><br><span class="line"></span><br><span class="line">    self.label_start = self.total_window_size - self.label_width</span><br><span class="line">    self.labels_slice = slice(self.label_start, None)</span><br><span class="line">    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]</span><br><span class="line"></span><br><span class="line">  def __repr__(self):</span><br><span class="line">    <span class="built_in">return</span> <span class="string">&#x27;\n&#x27;</span>.<span class="built_in">join</span>([</span><br><span class="line">        f<span class="string">&#x27;Total window size: &#123;self.total_window_size&#125;&#x27;</span>,</span><br><span class="line">        f<span class="string">&#x27;Input indices: &#123;self.input_indices&#125;&#x27;</span>,</span><br><span class="line">        f<span class="string">&#x27;Label indices: &#123;self.label_indices&#125;&#x27;</span>,</span><br><span class="line">        f<span class="string">&#x27;Label column name(s): &#123;self.label_columns&#125;&#x27;</span>])</span><br><span class="line"></span><br><span class="line">  @property</span><br><span class="line">  def train(self):</span><br><span class="line">    <span class="built_in">return</span> self.make_dataset(self.train_df)</span><br><span class="line"></span><br><span class="line">  @property</span><br><span class="line">  def val(self):</span><br><span class="line">    <span class="built_in">return</span> self.make_dataset(self.val_df)</span><br><span class="line"></span><br><span class="line">  @property</span><br><span class="line">  def <span class="built_in">test</span>(self):</span><br><span class="line">    <span class="built_in">return</span> self.make_dataset(self.test_df)</span><br><span class="line"></span><br><span class="line">  @property</span><br><span class="line">  def example(self):</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;Get and cache an example batch of `inputs, labels` for plotting.&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">    result = getattr(self, <span class="string">&#x27;_example&#x27;</span>, None)</span><br><span class="line">    <span class="keyword">if</span> result is None:</span><br><span class="line">        <span class="comment"># No example batch was found, so get one from the `.train` dataset</span></span><br><span class="line">        result = next(iter(self.train))</span><br><span class="line">        <span class="comment"># And cache it for next time</span></span><br><span class="line">        self._example = result</span><br><span class="line">    <span class="built_in">return</span> result</span><br><span class="line"></span><br><span class="line">  def plot(self, plot_col=<span class="string">&#x27;T (degC)&#x27;</span>, max_subplots=1, pred_tensor=None):</span><br><span class="line">    inputs, labels = self.example</span><br><span class="line">    plt.figure(figsize=(12, 8))</span><br><span class="line">    plot_col_index = self.column_indices[plot_col]</span><br><span class="line">    max_n = min(max_subplots, len(inputs))</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> range(max_n):</span><br><span class="line">      plt.subplot(max_n, 1, n+1)</span><br><span class="line">      plt.ylabel(f<span class="string">&#x27;&#123;plot_col&#125; [normed]&#x27;</span>)</span><br><span class="line">      plt.plot(self.input_indices, inputs[n, :, plot_col_index],</span><br><span class="line">              label=<span class="string">&#x27;Inputs&#x27;</span>, marker=<span class="string">&#x27;.&#x27;</span>, zorder=-10)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> self.label_columns:</span><br><span class="line">        label_col_index = self.label_columns_indices.get(plot_col, None)</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        label_col_index = plot_col_index</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> label_col_index is None:</span><br><span class="line">        <span class="built_in">continue</span></span><br><span class="line">			 </span><br><span class="line">			 <span class="keyword">if</span> not pred_tensor is None:</span><br><span class="line">	      plt.scatter(self.label_indices, pred_tensor[n, :, label_col_index],</span><br><span class="line">	                  marker=<span class="string">&#x27;X&#x27;</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>, label=<span class="string">&#x27;Predictions&#x27;</span>,</span><br><span class="line">	                  c=<span class="string">&#x27;#ff7f0e&#x27;</span>, s=64)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> n == 0:</span><br><span class="line">        plt.legend()</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Time [h]&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">  def split_window(self, features):</span><br><span class="line">        inputs = features[:, self.input_slice, :]</span><br><span class="line">        labels = features[:, self.labels_slice, :]</span><br><span class="line">        <span class="keyword">if</span> self.label_columns is not None:</span><br><span class="line">            labels = tf.stack(</span><br><span class="line">                [labels[:, :, self.column_indices[name]] <span class="keyword">for</span> name <span class="keyword">in</span> self.label_columns],</span><br><span class="line">                axis=-1)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Slicing doesn&#x27;t preserve static shape information, so set the shapes</span></span><br><span class="line">        <span class="comment"># manually. This way the `tf.data.Datasets` are easier to inspect.</span></span><br><span class="line">        inputs.set_shape([None, self.input_width, None])</span><br><span class="line">        labels.set_shape([None, self.label_width, None])</span><br><span class="line"></span><br><span class="line">        <span class="built_in">return</span> inputs, labels</span><br><span class="line"></span><br><span class="line">  def make_dataset(self, data):</span><br><span class="line">        <span class="keyword">if</span> not isinstance(data, np.ndarray):</span><br><span class="line">           data = np.array(data, dtype=np.float32)</span><br><span class="line">        ds = tf.keras.utils.timeseries_dataset_from_array(</span><br><span class="line">            data=data,</span><br><span class="line">            targets=None,</span><br><span class="line">            sequence_length=self.total_window_size,</span><br><span class="line">            sequence_stride=1,</span><br><span class="line">            shuffle=True,</span><br><span class="line">            batch_size=32,)</span><br><span class="line"></span><br><span class="line">        ds = ds.map(self.split_window)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">return</span> ds   </span><br><span class="line"></span><br><span class="line">def upload_local_directory_to_minio(local_path, bucket_name, minio_path):</span><br><span class="line">		 import glob</span><br><span class="line">    assert os.path.isdir(local_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> local_file <span class="keyword">in</span> glob.glob(local_path + <span class="string">&#x27;/**&#x27;</span>):</span><br><span class="line">        local_file = local_file.replace(os.sep, <span class="string">&quot;/&quot;</span>) <span class="comment"># Replace \ with / on Windows</span></span><br><span class="line">        <span class="keyword">if</span> not os.path.isfile(local_file):</span><br><span class="line">            upload_local_directory_to_minio(</span><br><span class="line">                local_file, bucket_name, minio_path + <span class="string">&quot;/&quot;</span> + os.path.basename(local_file))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            remote_path = os.path.join(</span><br><span class="line">                minio_path, local_file[1 + len(local_path):])</span><br><span class="line">            remote_path = remote_path.replace(</span><br><span class="line">                os.sep, <span class="string">&quot;/&quot;</span>)  <span class="comment"># Replace \ with / on Windows</span></span><br><span class="line">            minio_client.fput_object(bucket_name, remote_path, local_file)</span><br><span class="line">               </span><br><span class="line">def train_model()</span><br><span class="line">	  minio_client.fget_object(minio_bucket,<span class="string">&quot;models/lstm/train&quot;</span>,<span class="string">&quot;dataframes/train.npy&quot;</span>)  </span><br><span class="line">    minio_client.fget_object(minio_bucket,<span class="string">&quot;models/lstm/test&quot;</span>,<span class="string">&quot;dataframes/test.npy&quot;</span>) </span><br><span class="line">    minio_client.fget_object(minio_bucket,<span class="string">&quot;models/lstm/val&quot;</span>,<span class="string">&quot;dataframes/val.npy&quot;</span>) </span><br><span class="line">    train_npy = np.load(<span class="string">&#x27;dataframes/train.npy&#x27;</span>)</span><br><span class="line">    test_npy = np.load(<span class="string">&#x27;dataframes/test.npy&#x27;</span>)</span><br><span class="line">    val_npy = np.load(<span class="string">&#x27;dataframes/val.npy&#x27;</span>) </span><br><span class="line">    multi_window = WindowGenerator(</span><br><span class="line">        input_width=24, label_width=24, <span class="built_in">shift</span>=24,</span><br><span class="line">        train_df=train_npy,val_df=val_npy,test_df=test_npy,</span><br><span class="line">	      label_columns=None)</span><br><span class="line">	  multi_lstm_model = tf.keras.Sequential([</span><br><span class="line">	  <span class="comment"># Shape [batch, time, features] =&gt; [batch, lstm_units].</span></span><br><span class="line">	  <span class="comment"># Adding more `lstm_units` just overfits more quickly.</span></span><br><span class="line">	  tf.keras.layers.LSTM(32, return_sequences=False),</span><br><span class="line">	  <span class="comment"># Shape =&gt; [batch, 24*features].</span></span><br><span class="line">	  tf.keras.layers.Dense(24*14,</span><br><span class="line">	                      kernel_initializer=tf.initializers.zeros()),</span><br><span class="line">	  <span class="comment"># Shape =&gt; [batch, out_steps, features].</span></span><br><span class="line">	  tf.keras.layers.Reshape([24, 14])</span><br><span class="line">	  ])</span><br><span class="line">	</span><br><span class="line">	  _ = compile_and_fit(multi_lstm_model, multi_window)  </span><br><span class="line">	  tf.saved_model.save(multi_lstm_model,<span class="string">&#x27;models/lstm/model_dir&#x27;</span>)</span><br><span class="line">	     </span><br><span class="line">    upload_local_directory_to_minio(<span class="string">&quot;models/lstm/model_dir&quot;</span>,minio_bucket,<span class="string">&quot;/models/lstm/model_dir/&quot;</span>)      </span><br><span class="line">   </span><br><span class="line">import kfp</span><br><span class="line">import kfp.components as components</span><br><span class="line"></span><br><span class="line">def model_serving():</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    Create kserve instance</span></span><br><span class="line"><span class="string">    &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line">    from kubernetes import client </span><br><span class="line">    from kserve import KServeClient</span><br><span class="line">    from kserve import constants</span><br><span class="line">    from kserve import utils</span><br><span class="line">    from kserve import V1beta1InferenceService</span><br><span class="line">    from kserve import V1beta1InferenceServiceSpec</span><br><span class="line">    from kserve import V1beta1PredictorSpec</span><br><span class="line">    from kserve import V1beta1TFServingSpec</span><br><span class="line"></span><br><span class="line">    namespace = utils.get_default_target_namespace()</span><br><span class="line"></span><br><span class="line">    name=<span class="string">&#x27;weather-prediction-kserve-inference-service-v1&#x27;</span></span><br><span class="line">    kserve_version=<span class="string">&#x27;v1beta1&#x27;</span></span><br><span class="line">    api_version = constants.KSERVE_GROUP + <span class="string">&#x27;/&#x27;</span> + kserve_version</span><br><span class="line"></span><br><span class="line">    isvc = V1beta1InferenceService(api_version=api_version,</span><br><span class="line">                                   kind=constants.KSERVE_KIND,</span><br><span class="line">                                   metadata=client.V1ObjectMeta(</span><br><span class="line">                                       name=name, namespace=namespace, annotations=&#123;<span class="string">&#x27;sidecar.istio.io/inject&#x27;</span>:<span class="string">&#x27;false&#x27;</span>&#125;),</span><br><span class="line">                                   spec=V1beta1InferenceServiceSpec(</span><br><span class="line">                                   predictor=V1beta1PredictorSpec(</span><br><span class="line">                                       service_account_name=<span class="string">&quot;sa-minio-kserve&quot;</span>, <span class="comment">#see apply-minio-secret-to-kserve.yaml</span></span><br><span class="line">                                       tensorflow=(V1beta1TFServingSpec(</span><br><span class="line">                                           storage_uri=<span class="string">&quot;s3://mlpipeline/models/lstm/model_dir/&quot;</span>))))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    KServe = KServeClient()</span><br><span class="line">    KServe.create(isvc)</span><br><span class="line">comp_getting_df = components.create_component_from_func(getDataset,base_image=<span class="string">&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;</span>,</span><br><span class="line">                                                           packages_to_install=[<span class="string">&#x27;kserve==0.8.0.1&#x27;</span>])   </span><br><span class="line">comp_splitData_norm = components.create_component_from_func(splitDataAndNormalization,base_image=<span class="string">&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;</span>,</span><br><span class="line">                                                           packages_to_install=[<span class="string">&#x27;kserve==0.8.0.1&#x27;</span>])   </span><br><span class="line">comp_model_training = components.create_component_from_func(train_model,base_image=<span class="string">&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;</span>,</span><br><span class="line">                                                           packages_to_install=[<span class="string">&#x27;kserve==0.8.0.1&#x27;</span>])   </span><br><span class="line">comp_model_serving = components.create_component_from_func(model_serving,base_image=<span class="string">&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;</span>,</span><br><span class="line">                                                           packages_to_install=[<span class="string">&#x27;kserve==0.8.0.1&#x27;</span>])   </span><br><span class="line"><span class="comment">#define the pipeline</span></span><br><span class="line">from kfp import dsl</span><br><span class="line">@dsl.pipeline(</span><br><span class="line">    name=<span class="string">&#x27;weather-pred-pipeline&#x27;</span>,</span><br><span class="line">    description=<span class="string">&#x27;weather-prediction&#x27;</span></span><br><span class="line">)</span><br><span class="line">def weather_pred_pipeline():</span><br><span class="line">    step1 = comp_getting_df()</span><br><span class="line">  </span><br><span class="line">    step2 = comp_splitData_norm()</span><br><span class="line">    step2.after(step1)</span><br><span class="line">    </span><br><span class="line">    step3 = comp_model_training()</span><br><span class="line">    step3.after(step2)</span><br><span class="line">    </span><br><span class="line">    step4 = comp_model_serving()</span><br><span class="line">    step4.after(step3)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">	<span class="comment">#connect to kfp client</span></span><br><span class="line">	import requests</span><br><span class="line">  from kserve import KServeClient</span><br><span class="line">  </span><br><span class="line">	USERNAME=<span class="string">&quot;user@example.com&quot;</span></span><br><span class="line">	PASSWORD=<span class="string">&quot;12341234&quot;</span></span><br><span class="line">	NAMESPACE=<span class="string">&quot;kubeflow-user-example-com&quot;</span></span><br><span class="line">	HOST=<span class="string">&#x27;http://istio-ingressgateway.istio-system.svc.cluster.local:80&#x27;</span></span><br><span class="line">	session=requests.Session()</span><br><span class="line">	response=session.get(HOST)</span><br><span class="line">	headers=&#123;<span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/x-www-form-urlencoded&quot;</span>,&#125;</span><br><span class="line">	data=&#123;<span class="string">&quot;login&quot;</span>: USERNAME, <span class="string">&quot;password&quot;</span>: PASSWORD&#125;</span><br><span class="line">	session.post(response.url, headers=headers, data=data)</span><br><span class="line">	session_cookie=session.cookies.get_dict()[<span class="string">&quot;authservice_session&quot;</span>]</span><br><span class="line">	client=kfp.Client(host=f<span class="string">&quot;&#123;HOST&#125;/pipeline&quot;</span>, cookies=f<span class="string">&quot;authservice_session=&#123;session_cookie&#125;&quot;</span>,)</span><br><span class="line"></span><br><span class="line">  client.create_run_from_pipeline_func(weather_pred_pipeline,arguments=None,experiment_name=<span class="string">&quot;weather-prediction-v1-exp&quot;</span>) </span><br><span class="line">  </span><br><span class="line">  _, _ = getDataset()        </span><br><span class="line">	train_df,val_df,test_df,_ = splitDataAndNormalization()</span><br><span class="line">	wide_window = WindowGenerator(</span><br><span class="line">	        input_width=24, label_width=24, <span class="built_in">shift</span>=24,</span><br><span class="line">	        train_df=train_df,val_df=val_df,test_df=test_df,</span><br><span class="line">	        label_columns=None)</span><br><span class="line">	inputs, _=wide_window.example</span><br><span class="line">	</span><br><span class="line">	KServe = KServeClient()</span><br><span class="line">	</span><br><span class="line">	isvc_resp = KServe.get(<span class="string">&quot;weather-prediction-kserve-inference-service-v1&quot;</span>, namespace=<span class="string">&quot;kubeflow-user-example-com&quot;</span>)</span><br><span class="line">	isvc_url = isvc_resp[<span class="string">&#x27;status&#x27;</span>][<span class="string">&#x27;address&#x27;</span>][<span class="string">&#x27;url&#x27;</span>]</span><br><span class="line">	inference_input = &#123;</span><br><span class="line">	  <span class="string">&#x27;instances&#x27;</span>: inputs.numpy().tolist()</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	response = requests.post(isvc_url, json=inference_input)</span><br><span class="line">	predictions = response.json()[<span class="string">&#x27;predictions&#x27;</span>]</span><br><span class="line">	pred_tensor = tf.convert_to_tensor(predictions)</span><br><span class="line">	wide_window.plot(pred_tensor=pred_tensor)        </span><br></pre></td></tr></table></figure>

<h3 id="Using-argo-workflow"><a href="#Using-argo-workflow" class="headerlink" title="Using argo workflow"></a>Using argo workflow</h3><p>In the fourth method, We will be using argo workflows to spin up the kserve inferenece service and evaluate the model from the response after requesting to the endpoint deployed. Reference the <a target="_blank" rel="noopener" href="https://argo-workflows.readthedocs.io/en/latest/quick-start/">tutorial</a> for more info on argo installation </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#install argo-workflows</span></span><br><span class="line">kubectl create namespace argo</span><br><span class="line">kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo/v2.12.2/manifests/namespace-install.yaml</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">!git <span class="built_in">clone</span> https://github.com/PaddyZz/Time_Series_Forecasting.git</span><br><span class="line">!<span class="built_in">cd</span> my-lstm-repo-dir/.../argo </span><br><span class="line"><span class="comment">#build a docker container for env and dependencies required</span></span><br><span class="line"><span class="comment">#dockerfile</span></span><br><span class="line">FROM python:3.10.2</span><br><span class="line">RUN pip install virtualenv</span><br><span class="line">RUN virtualenv /env</span><br><span class="line">ENV VIRTUAL_ENV=/env</span><br><span class="line">ENV PATH=<span class="string">&quot;<span class="variable">$VIRTUAL_ENV</span>/bin:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line">WORKDIR [<span class="string">&#x27;/argo&#x27;</span>,<span class="string">&#x27;/models/lstm&#x27;</span>] <span class="comment"># set it up for model_save path </span></span><br><span class="line">COPY . /argo</span><br><span class="line">RUN python -m pip install --no-cache-dir -r requirements.txt</span><br><span class="line">CMD [<span class="string">&quot;python&quot;</span>, <span class="string">&quot;main.py&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#requirements.txt includes all the dependencies we need to build the other conatiners in argo workflow</span></span><br><span class="line">IPython==7.34.0</span><br><span class="line">matplotlib==3.7.1</span><br><span class="line">numpy==1.26.4</span><br><span class="line">pandas==2.1.4</span><br><span class="line">seaborn==0.13.1</span><br><span class="line">tensorflow==2.17.0</span><br><span class="line">pickle</span><br><span class="line">minio</span><br><span class="line">glob</span><br><span class="line">kserve=0.8.0.1</span><br><span class="line">kfp</span><br><span class="line"></span><br><span class="line"><span class="comment">#build and push to docker repo for following deployment</span></span><br><span class="line">import docker</span><br><span class="line"></span><br><span class="line">def build_and_push_image(repo, image_name, tag):</span><br><span class="line">  <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">  Builds and pushes a Docker image to a registry.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args:</span></span><br><span class="line"><span class="string">    repo: The registry where the image will be pushed.</span></span><br><span class="line"><span class="string">    image_name: The name of the image.</span></span><br><span class="line"><span class="string">    tag: The tag for the image.</span></span><br><span class="line"><span class="string">  &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  client = docker.from_env()  <span class="comment"># Create a Docker client</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Build the image</span></span><br><span class="line">  try:</span><br><span class="line">      client.images.build(path=<span class="string">&#x27;.&#x27;</span>, tag=f<span class="string">&quot;&#123;repo&#125;/&#123;image_name&#125;:&#123;tag&#125;&quot;</span>)</span><br><span class="line">  except docker.errors.BuildError as e:</span><br><span class="line">      <span class="built_in">print</span>(f<span class="string">&quot;Build error: &#123;str(e)&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Log in to the registry (if necessary)</span></span><br><span class="line">  try:</span><br><span class="line">      client.login(username=<span class="string">&quot;&lt;your-username&gt;&quot;</span>, password=<span class="string">&quot;&lt;your-password&gt;&quot;</span>)</span><br><span class="line">  except docker.errors.APIError as e:</span><br><span class="line">      <span class="built_in">print</span>(f<span class="string">&quot;Login error: &#123;str(e)&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Push the image to the registry</span></span><br><span class="line">  try:</span><br><span class="line">      <span class="keyword">for</span> line <span class="keyword">in</span> client.images.push(f<span class="string">&quot;&#123;repo&#125;/&#123;image_name&#125;:&#123;tag&#125;&quot;</span>, stream=True):</span><br><span class="line">          <span class="built_in">print</span>(line.decode(<span class="string">&#x27;utf-8&#x27;</span>).strip())</span><br><span class="line">  except docker.errors.APIError as e:</span><br><span class="line">      <span class="built_in">print</span>(f<span class="string">&quot;Push error: &#123;str(e)&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example usage</span></span><br><span class="line">repo = <span class="string">&quot;your_repo&quot;</span></span><br><span class="line">image_name = <span class="string">&quot;your_image&quot;</span></span><br><span class="line">tag = <span class="string">&quot;latest&quot;</span></span><br><span class="line"></span><br><span class="line">build_and_push_image(lstm_kserve_env, lstm_kserve_env, v1)</span><br></pre></td></tr></table></figure>

<p>after that we need to deal with data_ingestion, pretain_model, model_training, model_serving, these four phases for argo workflow deployment</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#data_ingestion.py</span></span><br><span class="line">import os</span><br><span class="line">import pandas as pd</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import zipfile</span><br><span class="line">import pickle</span><br><span class="line"></span><br><span class="line">def getDataset(inputs=False):</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    Downloads and extracts a CSV dataset from a remote ZIP file, processes the data, and returns a DataFrame and a Series.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The function performs the following steps:</span></span><br><span class="line"><span class="string">    1. Downloads a ZIP file containing the dataset from a specified URL.</span></span><br><span class="line"><span class="string">    2. Extracts the ZIP file into the current working directory.</span></span><br><span class="line"><span class="string">    3. Reads the CSV file from the extracted contents into a DataFrame.</span></span><br><span class="line"><span class="string">    4. Processes the DataFrame by slicing it to include every 6th row starting from the 5th row and converting the &#x27;Date Time&#x27; column to datetime objects.</span></span><br><span class="line"><span class="string">    5. Cleans up by removing the ZIP file and extracted CSV file.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        df (pd.DataFrame): Processed DataFrame containing the dataset with every 6th row.</span></span><br><span class="line"><span class="string">        date_time (pd.Series): Series containing datetime objects converted from the &#x27;Date Time&#x27; column.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Raises:</span></span><br><span class="line"><span class="string">        KeyError: If the &#x27;Date Time&#x27; column is not found in the CSV file.</span></span><br><span class="line"><span class="string">    &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    zip_path = tf.keras.utils.get_file(</span><br><span class="line">        origin=<span class="string">&#x27;https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip&#x27;</span>,</span><br><span class="line">        fname=<span class="string">&#x27;jena_climate_2009_2016.csv.zip&#x27;</span>,</span><br><span class="line">        extract=False)  </span><br><span class="line"></span><br><span class="line">    extract_dir = os.path.dirname(zip_path)</span><br><span class="line"></span><br><span class="line">    with zipfile.ZipFile(zip_path, <span class="string">&#x27;r&#x27;</span>) as zip_ref:</span><br><span class="line">        zip_ref.extractall(extract_dir)</span><br><span class="line">        extracted_files = zip_ref.namelist()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    csv_files = [f <span class="keyword">for</span> f <span class="keyword">in</span> extracted_files <span class="keyword">if</span> f.endswith(<span class="string">&#x27;.csv&#x27;</span>)]</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> csv_files:</span><br><span class="line">        csv_path = os.path.join(extract_dir, csv_files[0])</span><br><span class="line">        <span class="built_in">df</span> = pd.read_csv(csv_path)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;Date Time&#x27;</span> <span class="keyword">in</span> df.columns:</span><br><span class="line">            <span class="comment"># sliceData</span></span><br><span class="line">            <span class="built_in">df</span> = <span class="built_in">df</span>[5::6]</span><br><span class="line">            date_time = pd.to_datetime(df.pop(<span class="string">&#x27;Date Time&#x27;</span>), format=<span class="string">&#x27;%d.%m.%Y %H:%M:%S&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            raise KeyError(<span class="string">&quot;&#x27;Date Time&#x27; column not found in the CSV file.&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> os.path.exists(zip_path):</span><br><span class="line">        os.remove(zip_path)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> file_name <span class="keyword">in</span> extracted_files:</span><br><span class="line">        file_path = os.path.join(extract_dir, file_name)</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(file_path):</span><br><span class="line">            os.remove(file_path)</span><br><span class="line">    <span class="keyword">if</span> inputs:</span><br><span class="line">        <span class="built_in">return</span> <span class="built_in">df</span></span><br><span class="line">        </span><br><span class="line">     <span class="comment">#we use pickle to sequentilize our data for sharing with other funcs </span></span><br><span class="line">    with open(<span class="string">&#x27;/models/lstm/df.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) as f:</span><br><span class="line">        pickle.dump(<span class="built_in">df</span>, f)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> None</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    getDataset()</span><br><span class="line"></span><br><span class="line"><span class="comment">#pretrain_model.py</span></span><br><span class="line">import pickle</span><br><span class="line"></span><br><span class="line">def splitDataAndNormalization(inputs=False,<span class="built_in">df</span>=None):</span><br><span class="line">    <span class="keyword">if</span> inputs is True and <span class="built_in">df</span> is not None:</span><br><span class="line">        pass</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        with open(<span class="string">&#x27;/models/lstm/df.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) as f:</span><br><span class="line">            <span class="built_in">df</span> = pickle.load(f)</span><br><span class="line">    wv = <span class="built_in">df</span>[<span class="string">&#x27;wv (m/s)&#x27;</span>]</span><br><span class="line">    bad_wv = wv == -9999.0</span><br><span class="line">    wv[bad_wv] = 0.0</span><br><span class="line"></span><br><span class="line">    max_wv = <span class="built_in">df</span>[<span class="string">&#x27;max. wv (m/s)&#x27;</span>]</span><br><span class="line">    bad_max_wv = max_wv == -9999.0</span><br><span class="line">    max_wv[bad_max_wv] = 0.0</span><br><span class="line">    n = len(<span class="built_in">df</span>)</span><br><span class="line">    train_df = <span class="built_in">df</span>[0:int(n*0.7)]</span><br><span class="line">    val_df = <span class="built_in">df</span>[int(n*0.7):int(n*0.9)]</span><br><span class="line">    test_df = <span class="built_in">df</span>[int(n*0.9):]</span><br><span class="line">    num_features = df.shape[1]</span><br><span class="line">    train_mean = train_df.mean()</span><br><span class="line">    train_std = train_df.std()</span><br><span class="line"></span><br><span class="line">    train_df = (train_df - train_mean) / train_std</span><br><span class="line">    val_df = (val_df - train_mean) / train_std <span class="comment">#validation_df</span></span><br><span class="line">    test_df = (test_df - train_mean) / train_std</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> input is True:</span><br><span class="line">        <span class="built_in">return</span> train_df, val_df, test_df</span><br><span class="line">    with open(<span class="string">&#x27;/models/lstm/train.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) as f:</span><br><span class="line">        pickle.dump(train_df, f)</span><br><span class="line">    with open(<span class="string">&#x27;/models/lstm/val.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) as f:</span><br><span class="line">        pickle.dump(val_df, f)</span><br><span class="line">    with open(<span class="string">&#x27;/models/lstm/test.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) as f:</span><br><span class="line">        pickle.dump(test_df, f)</span><br><span class="line">    <span class="built_in">return</span> None</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    splitDataAndNormalization()</span><br><span class="line"></span><br><span class="line"><span class="comment">#model_training</span></span><br><span class="line">import tensorflow as tf</span><br><span class="line">import os</span><br><span class="line">import glob</span><br><span class="line">import pickle</span><br><span class="line">import minio</span><br><span class="line">from argo.compile_and_fit import compile_and_fit</span><br><span class="line">from argo.data_windowing import WindowGenerator</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">minio_client = minio(</span><br><span class="line">        <span class="string">&quot;&lt;your-minio-cluster-ip&gt;:9000&quot;</span>,</span><br><span class="line">        access_key=<span class="string">&quot;minio&quot;</span>,</span><br><span class="line">        secret_key=<span class="string">&quot;minio123&quot;</span>,</span><br><span class="line">        secure=False</span><br><span class="line">    )</span><br><span class="line">minio_bucket = <span class="string">&quot;mlpipeline&quot;</span></span><br><span class="line"></span><br><span class="line">def upload_local_directory_to_minio(local_path, bucket_name, minio_path):</span><br><span class="line">		 </span><br><span class="line">    assert os.path.isdir(local_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> local_file <span class="keyword">in</span> glob.glob(local_path + <span class="string">&#x27;/**&#x27;</span>):</span><br><span class="line">        local_file = local_file.replace(os.sep, <span class="string">&quot;/&quot;</span>) <span class="comment"># Replace \ with / on Windows</span></span><br><span class="line">        <span class="keyword">if</span> not os.path.isfile(local_file):</span><br><span class="line">            upload_local_directory_to_minio(</span><br><span class="line">                local_file, bucket_name, minio_path + <span class="string">&quot;/&quot;</span> + os.path.basename(local_file))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            remote_path = os.path.join(</span><br><span class="line">                minio_path, local_file[1 + len(local_path):])</span><br><span class="line">            remote_path = remote_path.replace(</span><br><span class="line">                os.sep, <span class="string">&quot;/&quot;</span>)  <span class="comment"># Replace \ with / on Windows</span></span><br><span class="line">            minio_client.fput_object(bucket_name, remote_path, local_file)</span><br><span class="line">def model_train():</span><br><span class="line">    with open(<span class="string">&#x27;/models/lstm/train.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) as f:</span><br><span class="line">        train_df = pickle.load(f)</span><br><span class="line">    with open(<span class="string">&#x27;/models/lstm/val.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) as f:</span><br><span class="line">        val_df = pickle.load(f)</span><br><span class="line">    with open(<span class="string">&#x27;/models/lstm/test.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) as f:</span><br><span class="line">        test_df = pickle.load(f)</span><br><span class="line">    multi_window = WindowGenerator(</span><br><span class="line">    input_width=24, label_width=24, <span class="built_in">shift</span>=24,</span><br><span class="line">    train_df=train_df,val_df=val_df,test_df=test_df,</span><br><span class="line">        label_columns=None)</span><br><span class="line">    multi_lstm_model = tf.keras.Sequential([</span><br><span class="line">    <span class="comment"># Shape [batch, time, features] =&gt; [batch, lstm_units].</span></span><br><span class="line">    <span class="comment"># Adding more `lstm_units` just overfits more quickly.</span></span><br><span class="line">    tf.keras.layers.LSTM(32, return_sequences=False),</span><br><span class="line">    <span class="comment"># Shape =&gt; [batch, 24*features].</span></span><br><span class="line">    tf.keras.layers.Dense(24*14,</span><br><span class="line">                        kernel_initializer=tf.initializers.zeros()),</span><br><span class="line">    <span class="comment"># Shape =&gt; [batch, out_steps, features].</span></span><br><span class="line">    tf.keras.layers.Reshape([24, 14])</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    _ = compile_and_fit(multi_lstm_model, multi_window)  </span><br><span class="line">    tf.saved_model.save(multi_lstm_model,<span class="string">&#x27;/models/lstm/model_dir&#x27;</span>)</span><br><span class="line">    upload_local_directory_to_minio(<span class="string">&quot;/models/lstm/model_dir&quot;</span>,minio_bucket,<span class="string">&quot;/models/lstm/model_dir/&quot;</span>)      </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    model_train()</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#model_serving</span></span><br><span class="line">import kfp</span><br><span class="line">import kfp.components as components</span><br><span class="line">from kubernetes import client </span><br><span class="line">from kserve import KServeClient</span><br><span class="line">from kserve import constants</span><br><span class="line">from kserve import utils</span><br><span class="line">from kserve import V1beta1InferenceService</span><br><span class="line">from kserve import V1beta1InferenceServiceSpec</span><br><span class="line">from kserve import V1beta1PredictorSpec</span><br><span class="line">from kserve import V1beta1TFServingSpec</span><br><span class="line">from kfp import dsl</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">def model_serving():</span><br><span class="line">    <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    Create kserve instance</span></span><br><span class="line"><span class="string">    &quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    namespace = utils.get_default_target_namespace()</span><br><span class="line"></span><br><span class="line">    name=<span class="string">&#x27;weather-prediction-kserve-inference-service-v1&#x27;</span></span><br><span class="line">    kserve_version=<span class="string">&#x27;v1beta1&#x27;</span></span><br><span class="line">    api_version = constants.KSERVE_GROUP + <span class="string">&#x27;/&#x27;</span> + kserve_version</span><br><span class="line"></span><br><span class="line">    isvc = V1beta1InferenceService(api_version=api_version,</span><br><span class="line">                                   kind=constants.KSERVE_KIND,</span><br><span class="line">                                   metadata=client.V1ObjectMeta(</span><br><span class="line">                                       name=name, namespace=namespace, annotations=&#123;<span class="string">&#x27;sidecar.istio.io/inject&#x27;</span>:<span class="string">&#x27;false&#x27;</span>&#125;),</span><br><span class="line">                                   spec=V1beta1InferenceServiceSpec(</span><br><span class="line">                                   predictor=V1beta1PredictorSpec(</span><br><span class="line">                                       service_account_name=<span class="string">&quot;sa-minio-kserve&quot;</span>, <span class="comment">#see apply-minio-secret-to-kserve.yaml</span></span><br><span class="line">                                       tensorflow=(V1beta1TFServingSpec(</span><br><span class="line">                                           storage_uri=<span class="string">&quot;s3://mlpipeline/models/lstm/model_dir/&quot;</span>))))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    KServe = KServeClient()</span><br><span class="line">    KServe.create(isvc)</span><br><span class="line">comp_model_serving = components.create_component_from_func(model_serving,base_image=<span class="string">&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;</span>,</span><br><span class="line">                                                           packages_to_install=[<span class="string">&#x27;kserve==0.8.0.1&#x27;</span>])   </span><br><span class="line"></span><br><span class="line">@dsl.pipeline(</span><br><span class="line">    name=<span class="string">&#x27;weather-pred-pipeline&#x27;</span>,</span><br><span class="line">    description=<span class="string">&#x27;weather-prediction&#x27;</span>)</span><br><span class="line">def weather_pred_pipeline():</span><br><span class="line"></span><br><span class="line">    comp_model_serving()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    USERNAME=<span class="string">&quot;user@example.com&quot;</span></span><br><span class="line">    PASSWORD=<span class="string">&quot;12341234&quot;</span></span><br><span class="line">    NAMESPACE=<span class="string">&quot;kubeflow-user-example-com&quot;</span></span><br><span class="line">	HOST=<span class="string">&#x27;http://istio-ingressgateway.istio-system.svc.cluster.local:80&#x27;</span></span><br><span class="line">	session=requests.Session()</span><br><span class="line">	response=session.get(HOST)</span><br><span class="line">	headers=&#123;<span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/x-www-form-urlencoded&quot;</span>,&#125;</span><br><span class="line">	data=&#123;<span class="string">&quot;login&quot;</span>: USERNAME, <span class="string">&quot;password&quot;</span>: PASSWORD&#125;</span><br><span class="line">	session.post(response.url, headers=headers, data=data)</span><br><span class="line">	session_cookie=session.cookies.get_dict()[<span class="string">&quot;authservice_session&quot;</span>]</span><br><span class="line">	client=kfp.Client(host=f<span class="string">&quot;&#123;HOST&#125;/pipeline&quot;</span>, cookies=f<span class="string">&quot;authservice_session=&#123;session_cookie&#125;&quot;</span>,)</span><br><span class="line">    client.create_run_from_pipeline_func(weather_pred_pipeline,arguments=None,experiment_name=<span class="string">&quot;weather-prediction-v1-exp&quot;</span>) </span><br><span class="line">                                                        </span><br><span class="line"><span class="comment">#model_evaluating</span></span><br><span class="line">from kserve import KServeClient</span><br><span class="line">import requests</span><br><span class="line">import tensorflow as tf </span><br><span class="line">from argo.data_ingestion import getDataset</span><br><span class="line">from argo.pretrian_model import splitDataAndNormalization</span><br><span class="line">from argo.data_windowing import WindowGenerator</span><br><span class="line"></span><br><span class="line">def model_evaluating():</span><br><span class="line">	<span class="built_in">df</span> = getDataset(inputs=True)        </span><br><span class="line">	train_df,val_df,test_df,_ = splitDataAndNormalization(inputs=True,<span class="built_in">df</span>=<span class="built_in">df</span>)</span><br><span class="line">	wide_window = WindowGenerator(</span><br><span class="line">	        input_width=24, label_width=24, <span class="built_in">shift</span>=24,</span><br><span class="line">	        train_df=train_df,val_df=val_df,test_df=test_df,</span><br><span class="line">	        label_columns=None)</span><br><span class="line">	inputs, _=wide_window.example</span><br><span class="line">	</span><br><span class="line">	KServe = KServeClient()</span><br><span class="line">	</span><br><span class="line">	isvc_resp = KServe.get(<span class="string">&quot;weather-prediction-kserve-inference-service-v1&quot;</span>, namespace=<span class="string">&quot;kubeflow-user-example-com&quot;</span>)</span><br><span class="line">	isvc_url = isvc_resp[<span class="string">&#x27;status&#x27;</span>][<span class="string">&#x27;address&#x27;</span>][<span class="string">&#x27;url&#x27;</span>]</span><br><span class="line">	inference_input = &#123;</span><br><span class="line">	  <span class="string">&#x27;instances&#x27;</span>: inputs.numpy().tolist()</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	response = requests.post(isvc_url, json=inference_input)</span><br><span class="line">	predictions = response.json()[<span class="string">&#x27;predictions&#x27;</span>]</span><br><span class="line">	pred_tensor = tf.convert_to_tensor(predictions)</span><br><span class="line">	wide_window.plot(pred_tensor=pred_tensor)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    model_evaluating()</span><br></pre></td></tr></table></figure>

<p>and then we will set up the argo workflows yaml file to deploy it simply</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#deploy-kserve-with-argo-workflow.yaml</span></span><br><span class="line">apiVersion: argoproj.io/v1alpha1</span><br><span class="line">kind: Workflow</span><br><span class="line">metadata:</span><br><span class="line">  namespace: argo</span><br><span class="line">  generateName: deploy kserve</span><br><span class="line">  annotations: &#123;pipelines.kubeflow.org/kserve_sdk_version: 0.8.0.1</span><br><span class="line">  labels: &#123;pipelines.kubeflow.org/kserve_sdk_version: 0.8.0.1&#125;</span><br><span class="line">spec:</span><br><span class="line">  entrypoint: data_ingestion</span><br><span class="line">  dag:</span><br><span class="line">    tasks:</span><br><span class="line">    - name: data_ingestion</span><br><span class="line">      template: data_ingestion</span><br><span class="line">      outputs:</span><br><span class="line">        parameters:</span><br><span class="line">        - name: <span class="built_in">df</span></span><br><span class="line">    - name: pretrain_model</span><br><span class="line">      template: pretrain_model</span><br><span class="line">      dependsOn:</span><br><span class="line">      - data_ingestion</span><br><span class="line">      inputs:</span><br><span class="line">        parameters:</span><br><span class="line">        - name: <span class="built_in">df</span></span><br><span class="line">          valueFrom:</span><br><span class="line">            from: <span class="string">&quot;&#123;&#123;tasks.data_ingestion.outputs.parameters.df&#125;&#125;&quot;</span></span><br><span class="line">       outputs:</span><br><span class="line">          parameters:</span><br><span class="line">          - name: train_df</span><br><span class="line">          - name: test_df</span><br><span class="line">          - name: val_df</span><br><span class="line">     - name: model_training</span><br><span class="line">      template: model_training</span><br><span class="line">      dependsOn:</span><br><span class="line">      - pretrain_model</span><br><span class="line">      inputs:</span><br><span class="line">        parameters:</span><br><span class="line">        - name: train_df</span><br><span class="line">          valueFrom:</span><br><span class="line">            from: <span class="string">&quot;&#123;&#123;tasks.pretrain_model.outputs.parameters.train_df&#125;&#125;&quot;</span></span><br><span class="line">         - name: test_df</span><br><span class="line">          valueFrom:</span><br><span class="line">            from: <span class="string">&quot;&#123;&#123;tasks.pretrain_model.outputs.parameters.test_df&#125;&#125;&quot;</span></span><br><span class="line">         - name: val_df</span><br><span class="line">          valueFrom:</span><br><span class="line">            from: <span class="string">&quot;&#123;&#123;tasks.pretrain_model.outputs.parameters.val_df&#125;&#125;&quot;</span> </span><br><span class="line">       outputs:</span><br><span class="line">          parameters:</span><br><span class="line">          - name: model_trained</span><br><span class="line">     - name: model_serving</span><br><span class="line">      template: model_serving</span><br><span class="line">      dependsOn:</span><br><span class="line">      - model_training</span><br><span class="line">     - name: model_evaluating</span><br><span class="line">       template: model_evaluating</span><br><span class="line">       dependsOn:</span><br><span class="line">       - model_serving</span><br><span class="line">      </span><br><span class="line">          </span><br><span class="line">          </span><br><span class="line">  templates:</span><br><span class="line">  - name: data_ingestion</span><br><span class="line">    outputs:</span><br><span class="line">      parameters:</span><br><span class="line">      - name: <span class="built_in">df</span> </span><br><span class="line">    volumes:</span><br><span class="line">    - name: data-volume</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: &#123;&#123;inputs.parameters.pvc-name&#125;&#125;</span><br><span class="line">    container:</span><br><span class="line">      image: (lstm_kserve_env/lstm_kserve_env:v1</span><br><span class="line">      volumeMounts:</span><br><span class="line">      - name: data-volume</span><br><span class="line">        mountPath: /models/lstm</span><br><span class="line">      <span class="built_in">command</span>: [<span class="string">&quot;python&quot;</span>, <span class="string">&quot;data_ingestion.py&quot;</span>]</span><br><span class="line">   - name: pretrain_model</span><br><span class="line">    inputs:</span><br><span class="line">      parameters:</span><br><span class="line">      - name: <span class="built_in">df</span></span><br><span class="line">    outputs:</span><br><span class="line">      parameters:</span><br><span class="line">      - name: train_df</span><br><span class="line">      - name: val_df</span><br><span class="line">      - name: test_df </span><br><span class="line">    volumes:</span><br><span class="line">    - name: data-volume</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: &#123;&#123;inputs.parameters.pvc-name&#125;&#125;</span><br><span class="line">    container:</span><br><span class="line">      image: (lstm_kserve_env/lstm_kserve_env:v1</span><br><span class="line">      volumeMounts:</span><br><span class="line">      - name: data-volume</span><br><span class="line">        mountPath: /models/lstm</span><br><span class="line">      <span class="built_in">command</span>: [<span class="string">&quot;python&quot;</span>, <span class="string">&quot;pretrain_model.py&quot;</span>]</span><br><span class="line">  - name: model_training</span><br><span class="line">    inputs:</span><br><span class="line">      parameters:</span><br><span class="line">      - name: train_df</span><br><span class="line">      - name: test_df</span><br><span class="line">      - name: val_df</span><br><span class="line">    outputs:</span><br><span class="line">      parameters:</span><br><span class="line">      - name: models_traine </span><br><span class="line">    volumes:</span><br><span class="line">    - name: data-volume</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: &#123;&#123;inputs.parameters.pvc-name&#125;&#125;</span><br><span class="line">    container:</span><br><span class="line">      image: (lstm_kserve_env/lstm_kserve_env:v1</span><br><span class="line">      volumeMounts:</span><br><span class="line">      - name: data-volume</span><br><span class="line">        mountPath: /models/lstm</span><br><span class="line">      <span class="built_in">command</span>: [<span class="string">&quot;python&quot;</span>, <span class="string">&quot;model_training.py&quot;</span>]</span><br><span class="line">  - name: model-serving</span><br><span class="line">    volumes:</span><br><span class="line">    - name: data-volume</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: &#123;&#123;inputs.parameters.pvc-name&#125;&#125;</span><br><span class="line">    container:</span><br><span class="line">      image: (lstm_kserve_env/lstm_kserve_env:v1</span><br><span class="line">      volumeMounts:</span><br><span class="line">      - name: data-volume</span><br><span class="line">        mountPath: /models/lstm</span><br><span class="line">      <span class="built_in">command</span>: [<span class="string">&quot;python&quot;</span>, <span class="string">&quot;model_serving.py&quot;</span>]</span><br><span class="line">  - name: model_evaluating</span><br><span class="line">    volumes:</span><br><span class="line">    - name: data-volume</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: &#123;&#123;inputs.parameters.pvc-name&#125;&#125;</span><br><span class="line">    container:</span><br><span class="line">      image: (lstm_kserve_env/lstm_kserve_env:v1</span><br><span class="line">      volumeMounts:</span><br><span class="line">      - name: data-volume</span><br><span class="line">        mountPath: /models/lstm</span><br><span class="line">      <span class="built_in">command</span>: [<span class="string">&quot;python&quot;</span>, <span class="string">&quot;model_evaluating.py&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f deploy-kserve-with-argo-workflow.yaml</span><br></pre></td></tr></table></figure>

<h3 id="Using-Tekton"><a href="#Using-Tekton" class="headerlink" title="Using Tekton"></a>Using Tekton</h3><p>In the final method, we will deploy Tekton simply with yaml file simply and Tekton ‘s deployment method is similar to argo workflow deployment one’s with some additional fine-tunes in yaml file. Reference the tutorial for more info on Tekton installation</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#install kfp-Tekton</span></span><br><span class="line">kubectl create namespace tekton</span><br><span class="line">kubectl apply -k https://github.com/kubeflow/kfp-tekton//manifests/kustomize/env/platform-agnostic-tekton?ref=v2.0.5 -n tekton</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#deploy-kserve-with-tekton.yaml</span></span><br><span class="line">apiVersion: tekton.dev/v1beta1</span><br><span class="line">kind: Pipeline</span><br><span class="line">metadata:</span><br><span class="line">  namespace: tekton</span><br><span class="line">  generateName: deploy-kserve-</span><br><span class="line">  annotations:</span><br><span class="line">    pipelines.kubeflow.org/kserve_sdk_version: <span class="string">&quot;0.8.0.1&quot;</span></span><br><span class="line">  labels:</span><br><span class="line">    pipelines.kubeflow.org/kserve_sdk_version: <span class="string">&quot;0.8.0.1&quot;</span></span><br><span class="line">spec:</span><br><span class="line">  params:</span><br><span class="line">    - name: pvc-name</span><br><span class="line">      <span class="built_in">type</span>: string </span><br><span class="line">  tasks:</span><br><span class="line">    - name: data-ingestion</span><br><span class="line">      taskRef:</span><br><span class="line">        name: data-ingestion-task</span><br><span class="line">      outputs:</span><br><span class="line">        results:</span><br><span class="line">          - name: <span class="built_in">df</span></span><br><span class="line"></span><br><span class="line">    - name: pretrain-model</span><br><span class="line">      taskRef:</span><br><span class="line">        name: pretrain-model-task</span><br><span class="line">      runAfter:</span><br><span class="line">        - data-ingestion</span><br><span class="line">      params:</span><br><span class="line">        - name: <span class="built_in">df</span></span><br><span class="line">          value: <span class="string">&quot;<span class="subst">$(tasks.data-ingestion.results.df)</span>&quot;</span></span><br><span class="line">      outputs:</span><br><span class="line">        results:</span><br><span class="line">          - name: train_df</span><br><span class="line">          - name: test_df</span><br><span class="line">          - name: val_df</span><br><span class="line"></span><br><span class="line">    - name: model-training</span><br><span class="line">      taskRef:</span><br><span class="line">        name: model-training-task</span><br><span class="line">      runAfter:</span><br><span class="line">        - pretrain-model</span><br><span class="line">      params:</span><br><span class="line">        - name: train_df</span><br><span class="line">          value: <span class="string">&quot;<span class="subst">$(tasks.pretrain-model.results.train_df)</span>&quot;</span></span><br><span class="line">        - name: test_df</span><br><span class="line">          value: <span class="string">&quot;<span class="subst">$(tasks.pretrain-model.results.test_df)</span>&quot;</span></span><br><span class="line">        - name: val_df</span><br><span class="line">          value: <span class="string">&quot;<span class="subst">$(tasks.pretrain-model.results.val_df)</span>&quot;</span></span><br><span class="line">      outputs:</span><br><span class="line">        results:</span><br><span class="line">          - name: model_trained</span><br><span class="line"></span><br><span class="line">    - name: model-serving</span><br><span class="line">      taskRef:</span><br><span class="line">        name: model-serving-task</span><br><span class="line">      runAfter:</span><br><span class="line">        - model-training</span><br><span class="line"></span><br><span class="line">    - name: model-evaluating</span><br><span class="line">      taskRef:</span><br><span class="line">        name: model-evaluating-task</span><br><span class="line">      runAfter:</span><br><span class="line">        - model-serving</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: tekton.dev/v1beta1</span><br><span class="line">kind: Task</span><br><span class="line">metadata:</span><br><span class="line">  name: data-ingestion-task</span><br><span class="line">spec:</span><br><span class="line"></span><br><span class="line">  results:</span><br><span class="line">    - name: <span class="built_in">df</span></span><br><span class="line">  steps:</span><br><span class="line">    - name: ingest-data</span><br><span class="line">      image: lstm_kserve_env/lstm_kserve_env:v1</span><br><span class="line">      script: |</span><br><span class="line">        <span class="comment">#!/bin/sh</span></span><br><span class="line">        python data_ingestion.py</span><br><span class="line">		  volumeMounts:</span><br><span class="line">		    - name: data-volume</span><br><span class="line">		      mountPath: /models/lstm</span><br><span class="line">  volumes:</span><br><span class="line">    - name: data-volume</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: $(params.pvc-name)</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: tekton.dev/v1beta1</span><br><span class="line">kind: Task</span><br><span class="line">metadata:</span><br><span class="line">  name: pretrain-model-task</span><br><span class="line">spec:</span><br><span class="line">  params:</span><br><span class="line">    - name: <span class="built_in">df</span></span><br><span class="line">      <span class="built_in">type</span>: dataframe</span><br><span class="line">  results:</span><br><span class="line">    - name: train_d</span><br><span class="line">    - name: test_df</span><br><span class="line">    - name: val_df</span><br><span class="line">  steps:</span><br><span class="line">    - name: pretrain</span><br><span class="line">      image: lstm_kserve_env/lstm_kserve_env:v1</span><br><span class="line">      script: |</span><br><span class="line">        <span class="comment">#!/bin/sh</span></span><br><span class="line">        python pretrain_model.py</span><br><span class="line">		  volumeMounts:</span><br><span class="line">		    - name: data-volume</span><br><span class="line">		      mountPath: /models/lstm</span><br><span class="line">  volumes:</span><br><span class="line">    - name: data-volume</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: $(params.pvc-name)</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: tekton.dev/v1beta1</span><br><span class="line">kind: Task</span><br><span class="line">metadata:</span><br><span class="line">  name: model-training-task</span><br><span class="line">spec:</span><br><span class="line">  params:</span><br><span class="line">    - name: pvc-name</span><br><span class="line">      <span class="built_in">type</span>: dataframe</span><br><span class="line">    - name: train_df</span><br><span class="line">      <span class="built_in">type</span>: dataframe</span><br><span class="line">    - name: test_df</span><br><span class="line">      <span class="built_in">type</span>: dataframe</span><br><span class="line">    - name: val_df</span><br><span class="line">      <span class="built_in">type</span>: dataframe</span><br><span class="line">  results:</span><br><span class="line">    - name: model_trained</span><br><span class="line">  steps:</span><br><span class="line">    - name: train</span><br><span class="line">      image: lstm_kserve_env/lstm_kserve_env:v1</span><br><span class="line">      script: |</span><br><span class="line">        <span class="comment">#!/bin/sh</span></span><br><span class="line">        python model_training.py</span><br><span class="line">		  volumeMounts:</span><br><span class="line">		    - name: data-volume</span><br><span class="line">		      mountPath: /models/lstm</span><br><span class="line">  volumes:</span><br><span class="line">    - name: data-volume</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: $(params.pvc-name)</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: tekton.dev/v1beta1</span><br><span class="line">kind: Task</span><br><span class="line">metadata:</span><br><span class="line">  name: model-serving-task</span><br><span class="line">spec:</span><br><span class="line">  </span><br><span class="line">  steps:</span><br><span class="line">    - name: serve</span><br><span class="line">      image: lstm_kserve_env/lstm_kserve_env:v1</span><br><span class="line">      script: |</span><br><span class="line">        <span class="comment">#!/bin/sh</span></span><br><span class="line">        python model_serving.py</span><br><span class="line">		  volumeMounts:</span><br><span class="line">		    - name: data-volume</span><br><span class="line">		      mountPath: /models/lstm</span><br><span class="line">  volumes:</span><br><span class="line">    - name: data-volume</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: $(params.pvc-name)</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: tekton.dev/v1beta1</span><br><span class="line">kind: Task</span><br><span class="line">metadata:</span><br><span class="line">  name: model-evaluating-task</span><br><span class="line">spec:</span><br><span class="line">  </span><br><span class="line">  steps:</span><br><span class="line">    - name: evaluate</span><br><span class="line">      image: lstm_kserve_env/lstm_kserve_env:v1</span><br><span class="line">      script: |</span><br><span class="line">        <span class="comment">#!/bin/sh</span></span><br><span class="line">        python model_evaluating.py</span><br><span class="line">		  volumeMounts:</span><br><span class="line">		    - name: data-volume</span><br><span class="line">		      mountPath: /models/lstm</span><br><span class="line">  volumes:</span><br><span class="line">    - name: data-volume</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: $(params.pvc-name)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f deploy-kserve-with-tekton.yaml</span><br></pre></td></tr></table></figure>

<h2 id="Potential-Improvement-Opportunities"><a href="#Potential-Improvement-Opportunities" class="headerlink" title="Potential Improvement Opportunities"></a>Potential Improvement Opportunities</h2><p>using RabbitMQ or Kafka message queue suitable for high concurrency scenarios when deploying Kserve if needed</p>
<p><strong>Thanks for the watching!</strong> Hope the blog can help you improve your understanding of how to spin up Kubeflow on AWS EC2 and deploy the KServe inference service!</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>We have finished:<br>• Create and Configure EC2 instance in AWS console dashboard<br>• Connect and access your EC2 instance<br>• Install basic tools (apt, conda, kubeflow-manifests repo etc)<br>• Configure AWS credentials, regions and deploy AWS EKS cluster, node-group<br>• Install Kubeflow Pods required<br>• Connect the Kubeflow Dashboard<br>• Connect the Kubeflow Notebooks Server<br>• Setup MinIO for Object Storage<br>• Setting up MinIO secret for Kserve for inference service<br>• Deploy models on Kserve inference services</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a target="_blank" rel="noopener" href="https://awslabs.github.io/kubeflow-manifests/docs/deployment/prerequisites/#:~:text=Prerequisites-,Prerequisites,-Set%20up%20your">how to configure kubeflow on AWS EC2</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/flopach/digits-recognizer-kubeflow/#:~:text=MIT%20license-,MLOps%20Workflow%3A%20Recognizing%20Digits%20with%20Kubeflow,-The%20MNIST%20database">how to spin up Kserve on kubeflow</a></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Configure and deploy models on Kubeflow</p><p><a class="link-muted" href="http://paddyzz.github.io/projects/Config_Kubeflow/">http://paddyzz.github.io/projects/Config_Kubeflow/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Paddy</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>02-10-2024</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>24-10-2024</p></div></div><div class="level-item is-narrow"><div><h6>Categories</h6><a class="link-muted is-uppercase is-size-7 article_license_category" href="/projects/">projects</a></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons article_license_logo" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons article_license_logo" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons article_license_logo" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1.5px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 mb-4" style="line-height:21px;height:0"><i class="fas fa-tags has-text-grey"></i><span> </span><a class="link-muted  tag-uppercase" rel="tag" href="/tags/DL/">DL<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/ML/">ML<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/PROJECTS/">PROJECTS<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Conda/">Conda<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/CICD/">CICD<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/AWS/">AWS<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/EC2/">EC2<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/EKS/">EKS<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Docker/">Docker<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/K8s/">K8s<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/End-to-End/">End-to-End<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/MLOps/">MLOps<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Kubeflow/">Kubeflow<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Bash/">Bash<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Python/">Python<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Git/">Git<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/MinIO/">MinIO<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Kserve/">Kserve<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/kfp/">kfp<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/argo/">argo<span>, </span></a><a class="link-muted  tag-uppercase" rel="tag" href="/tags/Tekton/">Tekton</a></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=665ef533f75dab0019ade953&amp;&amp;product=inline-share-buttons" defer></script></article></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blogs/CNNs_For_Text_Classification/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">CNNs for Text Classification</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/projects/time_series_forecasting/"><span class="level-item">Time Series Forecasting</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://paddyzz.github.io/projects/Config_Kubeflow/';
            this.page.identifier = '/projects/Config_Kubeflow/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'paddys-disqus' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div> </div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://assets-global.website-files.com/653dcbdd718cbd5c51c4dbed/653f5e8549a0fbf7dc295818_IMG_20190205_193746-p-500.jpg" alt="Jiahe(Paddy) ZHAO"></figure><p class="title is-size-4 is-block" style="line-height:inherit;margin-bottom:0.5rem;">Jiahe(Paddy) ZHAO</p><p class="is-block" style="font-style:Italic;font-size:0.8rem;">Artificial Intelligence</p><p class="is-block" style="font-style:Italic;font-size:0.8rem;">Machine Learning</p><p class="is-block" style="font-style:Italic;font-size:0.8rem;">Deep Learning</p><p class="is-block" style="font-style:Italic;font-size:0.8rem;">Computer Science</p><p class="is-block" style="font-style:Italic;font-size:0.8rem;">Information Technology</p><p class="is-size-6 is-flex justify-content-center" style="margin-top:0.5rem;"><i class="fas fa-map-marker-alt mr-1"></i><span>Hebei, CHINA</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading widget-profile-article-fontsize-style title-font-style">Posts</p><a href="/archives"><p class="title widget-profile-number-style">14</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading widget-profile-article-fontsize-style title-font-style">Categories</p><a href="/categories"><p class="title widget-profile-number-style">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading widget-profile-article-fontsize-style title-font-style">Tags</p><a href="/tags"><p class="title widget-profile-number-style">62</p></a></div></div></nav><div class="level"><a class="level-item fake-button-style is-rounded widget-profile-follow-button-style title-font-style" href="mailto:jiahe.zhao@uq.net.au?body=Hello%2C%0A%0AIt%20would%20be%20greatly%20appreciated%20if%20you%20could%20send%20me%20an%20email%20using%20your%20personal%20email%20client%20rather%20than%20the%20current%20HTML%20popup%20one%2C%20as%20I%20may%20not%20receive%20your%20message.%0A%0AThank%20you." target="_blank" rel="noopener"> <i class="fa fa-envelope" style="font-size:16.75px;margin-right:0.6rem;"></i>Email Me</a><span>  </span><a class="level-item fake-button-style is-rounded widget-profile-follow-button-style title-font-style" href="https://www.linkedin.com/in/jiahe-paddy-zhao-213b24300" target="_blank" rel="noopener"> <i class="fa-brands fa-linkedin color-linkedin" style="font-size:16.75px;margin-right:0.6rem;"></i>LinkedIn</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless widget-profile-logo-style" target="_blank" rel="noopener" title="Github" href="https://github.com/paddyzz"><i class="fa-brands fa-github color-github"></i></a><a class="level-item button is-transparent is-marginless widget-profile-logo-style" target="_blank" rel="noopener" title="Kaggle" href="https://www.kaggle.com/paddyzhao/"><i class="fa-brands fa-kaggle color-kaggle"></i></a><a class="level-item button is-transparent is-marginless widget-profile-logo-style" target="_blank" rel="noopener" title="Facebook" href="https://www.facebook.com/profile.php?id=100087961621533"><i class="fa-brands fa-facebook-f color-facebook"></i></a><a class="level-item button is-transparent is-marginless widget-profile-logo-style" target="_blank" rel="noopener" title="X" href="https://x.com/paddyzhao150568"><i class="fa-brands fa-x-twitter color-X"></i></a><a class="level-item button is-transparent is-marginless widget-profile-logo-style" target="_blank" rel="noopener" title="Discord" href="https://discord.com/users/1001308889062576139"><i class="fa-brands fa-discord color-discord"></i></a></div></div></div><div class="card widget is-sticky" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#Create-and-Configure-EC2-instance-in-AWS-console-dashboard"><span class="level-left"><span class="level-item">2</span><span class="level-item">Create and Configure EC2 instance in AWS console dashboard</span></span></a></li><li><a class="level is-mobile" href="#Connect-and-access-your-EC2-instance"><span class="level-left"><span class="level-item">3</span><span class="level-item">Connect and access your EC2 instance!</span></span></a></li><li><a class="level is-mobile" href="#Install-basic-tools-apt-conda-kubeflow-manifests-repo-etc"><span class="level-left"><span class="level-item">4</span><span class="level-item">Install basic tools (apt, conda, kubeflow-manifests repo etc)</span></span></a></li><li><a class="level is-mobile" href="#Configure-AWS-credentials-regions-and-deploy-AWS-EKS-cluster-node-group"><span class="level-left"><span class="level-item">5</span><span class="level-item">Configure AWS credentials, regions and deploy AWS EKS cluster, node-group</span></span></a></li><li><a class="level is-mobile" href="#Install-Kubeflow-Pods-required"><span class="level-left"><span class="level-item">6</span><span class="level-item">Install Kubeflow Pods required</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#preparation"><span class="level-left"><span class="level-item">6.1</span><span class="level-item">preparation</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Connect-the-Kubeflow-Dashboard"><span class="level-left"><span class="level-item">7</span><span class="level-item">Connect the Kubeflow Dashboard</span></span></a></li><li><a class="level is-mobile" href="#Connect-the-Kubeflow-Notebooks-Server"><span class="level-left"><span class="level-item">8</span><span class="level-item">Connect the Kubeflow Notebooks Server</span></span></a></li><li><a class="level is-mobile" href="#Setup-MinIO-for-Object-Storage"><span class="level-left"><span class="level-item">9</span><span class="level-item">Setup MinIO for Object Storage</span></span></a></li><li><a class="level is-mobile" href="#Setting-up-MinIO-secret-for-Kserve-for-inference-service"><span class="level-left"><span class="level-item">10</span><span class="level-item">Setting up MinIO secret for Kserve for inference service</span></span></a></li><li><a class="level is-mobile" href="#Deploy-models-on-Kserve-inference-services"><span class="level-left"><span class="level-item">11</span><span class="level-item">Deploy models on Kserve inference services</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Using-GitHub"><span class="level-left"><span class="level-item">11.1</span><span class="level-item">Using GitHub</span></span></a></li><li><a class="level is-mobile" href="#Using-Docker"><span class="level-left"><span class="level-item">11.2</span><span class="level-item">Using Docker</span></span></a></li><li><a class="level is-mobile" href="#Using-Kubeflow-pipeline-kfp"><span class="level-left"><span class="level-item">11.3</span><span class="level-item">Using Kubeflow pipeline(kfp)</span></span></a></li><li><a class="level is-mobile" href="#Using-argo-workflow"><span class="level-left"><span class="level-item">11.4</span><span class="level-item">Using argo workflow</span></span></a></li><li><a class="level is-mobile" href="#Using-Tekton"><span class="level-left"><span class="level-item">11.5</span><span class="level-item">Using Tekton</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Potential-Improvement-Opportunities"><span class="level-left"><span class="level-item">12</span><span class="level-item">Potential Improvement Opportunities</span></span></a></li><li><a class="level is-mobile" href="#Conclusion"><span class="level-left"><span class="level-item">13</span><span class="level-item">Conclusion</span></span></a></li><li><a class="level is-mobile" href="#References"><span class="level-left"><span class="level-item">14</span><span class="level-item">References</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><!--!--><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div></div></div></section><footer class="footer" style="padding:2rem 0.75rem 2rem;"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/favicon.png" alt="Paddy - Paddy&#039;s Log Book" height="28"></a><p class="is-size-7"><span>&copy; 2023-2024 Paddy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a> &amp; <a href="/" target="_blank" rel="noopener">Paddy&#039;s FE Tech</a><br><span id="busuanzi_container_page_uv">Visited by <span id="busuanzi_value_page_uv">88</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent article_license_logo is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent article_license_logo is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent article_license_logo is-large" target="_blank" rel="noopener" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/universe.js"></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script type="text/javascript" src="/js/gsap_progressbar.js"></script><script type="text/javascript" src="/js/night.js"></script></body></html>