{"posts":[{"title":"MOOC Certificates","text":"IntroductionMOOC, massive open online course, is an online course aimed at unlimited participation and open access via the web. This blog will showcase the Machine Learning and Deep Learning MOOC certifications I have obtained, primarily from Coursera. You can find additional certifications on my LinkedIn Page. MOOC HistoryAWS Knowledge: Cloud Essentials, AWS, Feb 2024 - March 2024 Use Machine Learning APIs on Google Cloud, GCP, May 2024 - June 2024 Build a natural language processing solution with Azure AI Language, Microsoft Azure, June 2024 - July 2024 Introduction to Statistics, Coursera, June 2024 - June 2024 Mathematics for Machine Learning: PCA, Coursera, May 2024 - June 2024 Mathematics for Machine Learning: Multivariate Calculus, Coursera, May 2024 - June 2024 Understanding and Visualizing Data with Python, Coursera, June 2024 - June 2024 Machine Learning Specialization, Coursera, June 2024 - June 2024 Convolutional Neural Networks, Coursera, June 2024 - July 2024 Neural Networks and Deep Learning, Coursera, May 2024 - June 2024 Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization, Coursera, June 2024 - July 2024 Sequence Models, Coursera, June 2024 - July 2024 Natural Language Processing Specialization, Coursera, June 2024 - July 2024 Generative Deep Learning with TensorFlow, Coursera, June 2024 - July 2024 Advanced Computer Vision with TensorFlow, Coursera, June 2024 - July 2024 DevOps_DataOps_MLOps, Coursera, May 2024 - June 2024 MLOps Platforms: Amazon SageMaker and Azure ML, Coursera, May 2024 and June 2024","link":"/certificates/1/"},{"title":"curriculum","text":"Curriculum VitaeEducationThe University Of Queensland (Feb, 2019 - June, 2023)I received a Bachelor of Information Technology degree from the University of Queensland, within the Faculty of Engineering, Architecture, and Information Technology (EAIT), and the School of Electrical Engineering and Computer Science (EECS). During the studies, I completed several courses related to Information Technology and Computer Science, including front-end development, functional programming, advanced mathmatics, machine learning, computer systems principles and programming, computer OS architecture and network development, and etc. Here are the key features details of the courses: • Reasoning About Programs (Feb 2023 - June 2023) Dafny functional programming, Behavior Specification, Formal Methods, Correctness Proofs, Weakest Precondition Reasoning, Algorithm Implementation • Artificial Intelligence (July 2022 - Oct 2022) Reinforcement Learning algorithms and principles, Graph Traversal Algorithms: BFS, DFS, IDDFS, Shortest Path Algorithms: Dijkstra, UCS, A*, Bellman-Ford, Floyd-Warshall, reasoning and planning with certainty, decision-making under uncertainty, Markov Decision Process(MDP), Q-learning,State-Action-Reward-State-Action(SARSA), Multi-Armed Bandit • Calculus &amp; Linear Algebra II (Nov 2021 - Feb 2022) Multi-dimensional calculus, Linear algebra, Taylor series, Maxima, minima, and saddle points, Method of least squares, Vector spaces, norms, and inner products, Gram-Schmidt orthogonalisation and orthogonal matrices • Operating Systems Architecture (July 2021 - Oct 2021) OS design and implementation based on FreeBSD, Reverse engineering, Binary files analysis, Disassembly andCoredump debugging, Kernel-level programming, Device driver programming, Principles and programming of operating system support for distributed and real-time computing • Algorithms and Data Structures (July 2021 - Oct 2021) Analysis of time and space complexity of algorithms. Sequences. Lists. Stacks. Queues. Sets, multisets, tables. Trees. Sorting. Hash tables. Priority queues. Graphs. String algorithms. • Numerical Methods in Computational Science (July 2021 - Oct 2021) MATLAB, Curve-fitting, Numerical differentiation and integration, Bisection, Fixed-point iteration, Gaussian elimination. Ordinary differential equations, Monte Carlo methods, Numerical integration and optimisation. • Computer systems principles and programming (Feb 2021 - June 2021) Systems Programming in C, Linux OS Bash Programming, GDB debugging, Processes and threads, Interprocess communication, Network programming The foundation year of University Of Queensland (Feb, 2018 - Nov, 2018)Enrolled in an interdisciplinary program, I successfully completed courses in Physics, Business Management, Mathematics, English Literature and Essay Writing, and Information Technology. Through the information technology course, I acquired fundamental skills in HTML and CSS, and gained a solid understanding of web design principles. This experience cultivated my logical thinking, basic coding abilities, and self-learning skills. Certificates• AWS Knowledge: Cloud Essentials, AWS, Feb 2024 - March 2024• Use Machine Learning APIs on Google Cloud, GCP, May 2024 - June 2024• Build a natural language processing solution with Azure AI Language, Microsoft Azure, June 2024 - July 2024• Machine Learning and Deep Learning Algorithms, MLOps, NLP, CV, Sequence models and other fields related to Deep Learning and Data Science from Coursera(mainly), Kaggle, IBM, Cisco These certificates mentioned above could be accessed from my personal website and LinkedIn Page Skill set (Machine Learning and Deep Learning) • Environments: Conda, Jupyter Notebook• Packages: Numpy, Pandas, Scikit-learn• Visualization: Seaborn, Pillow, Matplotlib• Frameworks: Tensorflow, Keras, Pytorch• Databases: AWS S3, MinIO, GCP bigQuery• Cloud Services: AWS, GCP, Azure• ML Lifecycle Management tool: MLflow• Image Containerisation: Docker, AWS ECR• Image Orchestration: Kubernetes (AWS EC2, EKS)• ML Cloud Platforms: AWS SageMaker, Kubeflow• CI/CD: Argo Workflow, Tekton, GitHub Actions• Repo: GitHub, DagsHub, HuggingFace","link":"/curriculum/"},{"title":"faqs","text":"FAQSFrequently Asked QuestionsHow do I follow and get updates from this website?The best way to follow and get updates is to subscribe to RSS Feeds, but I have not configured. You could easily subscribe to the RSS Feeds by entering the Email address under “Follow.It” and click “Subscribe” on the left widget of the website. How do I support this website?Since the Sponsorship Feature is not yet available, leaving comments and questions under the articles, and providing constructive feedbacks are the best ways to support. What are the major topics this website is covering?While I don’t limit the topics I will be working on, this website is mainly covering the topics including machine learning, deeping learning, artificial intelligence, linux systems, cloud platform services and mathmatics. Where should I leave questions?Please leave the questions under the website content. I am currently using Disqus for managing comments and it will routinely notify and remind me about the comments in case I missed or forgot any. Why the comments I left under the articles are not shown?The comment managing tool Disqus has special spam mechanisms. If your comment is classified as spam, your comment will not show up. I moderate the spam comments on Disqus routinely. If the spam is a false positive, I will make it public manually. Why I can’t see some of the images on the website?Some of the images are hosted on image hosting service or accelerated by CDNs. It is possible that those services are blocked by the internet service providers in some countries or regions.","link":"/faqs/"},{"title":"Jiahe ZHAO","text":"Greetings! oh hi! I am Paddy. Thanks for dropping by and visiting my website, please feel free to check out anything you want in it. Who am IMy name is Jiahe ZHAO and you can also call me Paddy. I focus on artificial intelligence, deep learning. I graduated with a Bachelor of Information Technology degree from the University of Queensland, within the Faculty of Engineering, Architecture, and Information Technology (EAIT), and the School of Electrical Engineering and Computer Science (EECS). My experiences include front-end development, functional programming(Dafny and Haskell), advanced mathematics, machine learning, computer systems principles and programming, computer OS architecture and network development and etc. At the moment, I am doing End-to-End Machine Learning Operations(MLOps) Deep Learning projects in the fields of Natural Language Process(NLP), Computer Vision(CV) and Time Series Forecasting(TSF). Outside of work, I enjoy jogging, bike-riding, stargazing, listening to music,collecting scenic pics, and reflecting on my experiences to grow my intrinsic mental strength through life’s challenges. Two of the life quotes I believe in are, “Fears spring from ignorance; hopes spring from action.” and “You are relentless, then you survive.” And I trust three essential factors for pursuing success. These factors are conviction (faith and belief in success, especially in difficult situations), fortitude, and perseverance. About the site:This website was formally built in the spring of 2024. The main purposes of this website are listed here:• Discuss the technical details of machine learning, deep learning theories and projects• Document the implementation of algorithms for solving real problems• Record my personal achievements and life experiences• Express myself more effectively. Citations:Feel free to cite the blog posts and projects in this site or my GitHub repos you like Contact me:If you have questions or any constructive comments about my blog posts, please leave your questions under the relevant post. For inquiries about my GitHub open-source projects, kindly open an issue ticket in the repository. For private questions, please contact me via my personal email.","link":"/"},{"title":"CNNs for Text Classification","text":"IntroductionThis article will discuss how to use convolutional neural networks to identify general patterns in text and perform text classification. Firstly, how do we represent text and prepare it as input for neural networks? Let’s focus on the case of classifying movie reviews, although the same techniques can be applied to articles, tweets, search queries, and more. For movie reviews, we have hundreds of written comments, each consisting of long, opinionated sentences that vary in length. Neural networks can only learn to find patterns in numerical data. Therefore, before we feed the reviews into the neural network, we must convert each word into a number. This process is commonly referred to as word encoding or tokenization. A typical encoding process works as follows: For all text data (in this case, movie reviews), we record each unique word that appears in the dataset and list them as the model’s vocabulary. We assign a unique integer, called a token, to each word in the vocabulary. Typically, these tokens are assigned based on the frequency of the words in the dataset. Thus, the most frequently occurring word across the dataset will have an associated token: 0. For example, if the most common word is “the,” its associated token value would be 0. The next most common word would be assigned the token 1, and this process continues. In code, this word-token association is represented in a dictionary, which maps each unique word to its token integer value. {'the': 0, 'of': 1, 'so': 2, 'then': 3, 'you': 4, … } Finally, once these tokens are assigned to individual words, we can tokenize the entire corpus. For any document in the dataset, such as a single movie review, we treat it as a list of words in a sequence. We then use the token dictionary to convert this list of words into a list of integer values. It is worth noting that these token values don’t carry much traditional meaning. In other words, we generally consider that the value 1 is closer to 2 than to 1000. As another example, we might view the value 10 as an average of 2 and 18. However, a word with a token of 1 is not necessarily more similar to a word with a token of 2 than to one with a token of 1000. The typical concept of numerical distance doesn’t provide us with any information about the relationships between individual words. Therefore, we must take another encoding step; ideally, we want to either eliminate the numerical order of these tokens or represent the relationships between words. One-Hot EncodingA common encoding step is to perform one-hot encoding for each token, representing each word as a vector with as many values as there are words in the vocabulary. That is, each column in the vector represents a possible word in the vocabulary. All positions in the vector are filled with 0s except for the index corresponding to the token value of the word (for example, the index for the would be 0). For larger vocabularies, these vectors can become quite long and sparse, containing 0s in all positions except one. This is considered a very sparse representation. Word2Vec Word EmbeddingsOften, we desire a more dense representation. One such representation is learned word vectors, known as embeddings. Word embeddings are fixed-length vectors, typically around 100 dimensions, with each vector containing approximately 100 values that represent a word. The values in each column represent features of a word rather than any specific word. These embeddings are formed through training a single-layer neural network (Word2Vec model) in an unsupervised manner on the input words and some surrounding words in sentences. Words that appear in similar contexts (and have similar surrounding words), such as coffee, tea, and water, tend to have similar vectors; the vectors point in roughly the same direction. Thus, similar words can be found by calculating the cosine similarity between word vectors. And there are useful resources available for references, including this illustrative code example. These word embeddings possess some very favorable properties: The embeddings are dense vector representations of words. Words with similar contexts often have embeddings that point in the same direction. These word embeddings can serve as inputs to recurrent neural networks or convolutional neural networks. Convolutional KernelThe convolutional layer aims to detect spatial patterns in images by sliding a small kernel window across the image. These windows are typically small, with sizes like 3x3 pixels, and each kernel unit has an associated weight. As the kernel slides pixel-by-pixel over the image, the kernel weights are multiplied by the pixel values in the underlying image, and the sum of all these products yields an output, the filtered pixel value. In the case of text classification, the convolutional kernel still acts as a sliding window, but its job is to examine multiple word embeddings rather than small areas of pixels in an image. Depending on the task, the size of the convolutional kernel must also change. To look at a sequence of word embeddings, we need a window that examines multiple word embeddings in the sequence. The kernel will no longer be square but will be a wide rectangle of sizes like 3x300 or 5x300 (assuming the embedding length is 300). The height of the kernel corresponds to the number of embeddings it sees at once, similar to representing n-grams in word models. The width of the kernel should span the entire length of the word embeddings. Convolution on Word SequencesLet’s take a look at an example of filtered word embeddings for a pair of (2-grams). Below, we have a toy example showing each word encoded as an embedding with 3 values; usually, this would contain more values, but this is for visualization purposes. To observe the two words in this example sequence, we can use a 2x3 convolutional kernel. The kernel weights are placed on top of the two word embeddings; in this case, the downward direction represents time, so within this short sequence, the word “movie” follows closely after the word “good.” The kernel weights and embedding values are multiplied together, and then summed to obtain a single output value of 0.54. The convolutional neural network will contain many such kernels, and during network training, these kernel weights are learned. Each kernel is designed to view a word along with its surrounding words in a sequential window and produce a value that captures information about that phrase. Thus, the convolution operation can be seen as window-based feature extraction, where features are patterns in groups of sequential words indicating sentiment, grammatical function, etc. It’s also worth noting that the input channel count for this convolutional layer (typically 1 for grayscale images and 3 for RGB images) in this example will be 1 since a single input text source will be encoded as a list of word embeddings. Recognizing General PatternsThis convolution operation has another beneficial characteristic. Recall that similar words will have similar embeddings, and convolution operations are merely linear operations on these vectors. Therefore, when the convolutional kernel is applied to different sets of similar words, it will yield similar output values. In the example below, we can see that the input 2-grams “good movie” and “great song” produce approximately the same convolution output values because the word embeddings for these pairs are also very similar. In this case, the convolutional kernel has learned to capture more general features; not just a good movie or a great song, but overall something positive. Recognizing these high-level features is particularly useful in text classification tasks, as they often rely on general groupings. For instance, in sentiment analysis, the model benefits from being able to represent phrases that are negative, neutral, and positive. The model can use these general features to classify the entire text. 1D ConvolutionTo process entire sequences of words, these kernels will slide down the list of word embeddings sequentially. This is referred to as 1D convolution because the kernels only move in one dimension: time. A single kernel moves down the input embedding list one by one, looking at the first word embedding (along with a small window of the next word embeddings), then the next, and so on. The final output will be a feature vector containing as many values as the input embeddings, so the size of the input sequence is indeed important. I say “about” because sometimes the convolutional kernels won’t perfectly cover the word embeddings, hence padding may need to be included to account for the kernel’s height. The previous article describes the relationship between padding and kernel size in more detail. Below, we can see what the output of 1D convolution might look like when applied to a short sequence of word embeddings. Multiple KernelsJust as in a typical convolutional neural network, a single convolutional kernel is insufficient to detect all the different types of features useful for classification tasks. To build a network capable of learning various relationships between words, we need many different filters of varying heights. In the paper Convolutional Neural Networks for Sentence Classification (Yoon Kim, 2014), they used a total of 300 kernels; 100 kernels for each height: 3, 4, and 5. These heights effectively capture patterns in sequences of 3, 4, and 5 continuous words. They chose 5 words as a cutoff because words that are further apart generally have lower relevance or usefulness for identifying patterns within a phrase. For example, if I say this apple is red, and a banana is yellow then words like this apple and red that are close together are more relevant than words like apple and yellow that are farther apart. Therefore, as a short convolutional kernel slides over the word embeddings one at a time, it is designed to capture local features or characteristics within nearby continuous word windows. The stacked output feature vectors produced by several convolution operations are referred to as the convolutional layer. Maxpooling Over TimeNow that we understand how the convolution operation generates feature vectors that can represent local features within a sequence of word embeddings, one consideration is what these feature vectors will look like when applied to important phrases in the text source. If we are trying to classify movie reviews and see the phrase great plot the position it appears in the review doesn’t matter; what matters is that it appears in the review. This serves as a strong indicator that this is a positive review, regardless of its position in the source text. To indicate the presence of these high-level features, we need a method to recognize them in the vector, regardless of their location in the larger input sequence. One way to identify significant features is to discard less relevant positional information, regardless of where they are in the sequence. For this, we can use the maxpooling operation, which forces the network to retain only the maximum value from the feature vector, which should be the most useful local feature. Since this operation looks at a series of local feature values, it is commonly referred to as max pooling over time. By processing the maximum value produced from each convolutional feature vector, these maximums will be concatenated and passed to the final fully connected layer, which can generate as many class scores as needed for the text classification task. SummarizationIn the text classification process using Convolutional Neural Networks (CNNs), the complete network begins by receiving a batch of texts (for example movie reviews) as input. Initially, these reviews are transformed into word embeddings through a pre-trained embedding layer, which captures semantic similarities between words in a continuous vector space. Following this, the sequences of word embeddings are processed through multiple convolutional layers with varying kernel heights of 3, 4, and 5 or even higher Each convolutional layer applies filters that slide over the embedded sequences, detecting local patterns and features within the text. After the convolution operations, a ReLU activation function is applied to introduce non-linearity, enabling the model to learn complex representations. Subsequently, a max pooling operation is performed, where the maximum values from the feature maps are extracted, effectively summarizing the most salient features detected by each convolutional layer. Finally, the maximum values from the convolutional layers are concatenated to form a comprehensive feature vector. This vector is then fed into a fully connected classification layer, which outputs class scores corresponding to the category of the texts. Through this systematic approach, CNNs leverage their ability to capture spatial hierarchies in data, making them particularly effective for text classification tasks. ReferencesCNNs for text classification Convolutional Neural Networks for Sentence Classification CNNs for text classfication","link":"/blogs/CNNs_For_Text_Classification/"},{"title":"ConvNets","text":"Introduction Convolutional Neural Networks (ConvNet/CNN) are a type of deep learning algorithm that can take input images, assign importance (learnable weights and biases) to various aspects/objects in the images, and distinguish between them. Compared to other classification algorithms, ConvNet requires much less preprocessing. While filters were originally designed manually, ConvNet has the ability to learn these filters/features through sufficient training. The architecture of convolutional networks is inspired by the connection patterns of neurons in the human brain, particularly the organization of the visual cortex. A single neuron responds to stimuli only within a limited region of its visual field known as the receptive field. These fields overlap to cover the entire visual area. Input Image In the illustration, we have an RGB image that is divided into three color planes (red, green, and blue). There are many such color spaces for images—grayscale, RGB, HSV, CMYK, etc. One can imagine the computational load when an image reaches 8K (7680×4320) resolution. The role of ConvNet is to simplify the image into a more manageable form without losing features critical for making accurate predictions. This is especially important when designing an architecture that not only excels at learning features but can also scale to vast datasets. Convolutional Layer - The Kernel Image Size = 5 (Height) x 5 (Width) x 1 (Number of Channels, e.g., RGB) In the above illustration, the green portion resembles our 5x5x1 input image I. The elements involved in the convolution operation in the first part of the convolution layer are called the kernel/filter K, highlighted in yellow. We choose K as a 3x3x1 matrix. With a stride length of 1 (non-strided), we perform element-wise multiplication between K and the image section P under the kernel Hadamard Product, moving the kernel 9 times. The filter moves to the right with a fixed stride value until it covers the entire width of the image. Then, it jumps back to the start (left side) of the image using the same stride value and repeats the process until the entire image is traversed. For images with multiple channels (e.g., RGB), the kernel has the same depth as the input image. Matrix multiplication is performed between Kn and In stacks ([K1, I1]; [K2, I2]; [K3, I3]), summing all results with the bias to produce a compressed single-depth channel convolution feature output. The purpose of the convolution operation is to extract high-level features from the input image, such as edges. Convolutional networks are not limited to just one convolution layer. Traditionally, the first ConvLayer captures low-level features like edges, colors, and gradient directions. By adding more layers, the architecture adapts to capture high-level features, providing us with a network that comprehensively understands images in the dataset, akin to human perception. This operation can yield two types of results: one where the dimensions of the convolution features are reduced compared to the input, and another where dimensions are increased or remain unchanged. This is achieved by applying valid padding in the former case and same padding in the latter. When we enhance a 5x5x1 image to a 6x6x1 image and then apply a 3x3x1 kernel on it, we find that the size of the convolution matrix is 5x5x1, hence the term Same Padding. On the other hand, if we perform the same operation without any padding, we obtain a matrix with the dimensions of the kernel (3x3x1) itself, referred to as Valid Padding. Pooling Layer Similar to the convolutional layer, the pooling layer is responsible for reducing the spatial dimensions of the convolutional features. This is done to decrease the computational power needed for processing the data through dimensionality reduction. Additionally, it is useful for extracting dominant features that are invariant to rotation and position, thereby maintaining an effective training process for the model. There are two types of pooling: max pooling and average pooling. Max pooling returns the maximum value from the portion of the image covered by the kernel. On the other hand, average pooling returns the average of all values in the portion of the image covered by the kernel. Max pooling can also act as a noise suppressor. It completely discards noisy activations and performs denoising along with dimensionality reduction. In contrast, average pooling simply reduces dimensions as a noise suppression mechanism. Therefore, we can say that max pooling performs significantly better than average pooling. The convolutional layer and pooling layer together form the i-th layer of the convolutional neural network. Depending on the complexity of the image, the number of such layers can be increased to further capture low-level details, but this comes at the cost of requiring more computational power. After the above processes, we have successfully enabled the model to understand features. Next, we will flatten the final output and input it into a standard neural network for classification. Classification — Fully Connected Layer (FC Layer) Adding a fully connected layer is a (typically) inexpensive way to learn a nonlinear combination of the high-level features represented by the output of the convolutional layers. The fully connected layer learns the possible nonlinear functions in that space. Now that we have transformed the input image into a format suitable for a multilayer perceptron, we will flatten the image into a column vector. The flattened output is fed into a feedforward neural network, and backpropagation is applied in each iteration of training. Over a series of epochs, the model becomes capable of distinguishing between the main features in the image and certain low-level features, classifying them using Softmax classification techniques. ReferencesConvolutional animations CNN introduction","link":"/blogs/ConvNet/"},{"title":"Mathematical Functions of Common Metrics","text":"IntroductionMathematical functions of common metrics for model evaluation in the fields of NLP, CV, and time series analysis. Time Series MetricsMean Absolute Error (MAE)MAE measures the average magnitude of errors in a set of predictions, without considering their direction. params: • : Number of observations • : Actual value at time • : Predicted value at time and the params of MAE function are same with the following functions in Time Series Metrics part. Mean Squared Error (MSE)MSE squares the errors before averaging, giving more weight to larger errors. Root Mean Squared Error (RMSE)RMSE is the square root of MSE and provides error in the same units as the original data. Mean Absolute Percentage Error (MAPE)MAPE expresses accuracy as a percentage, which is useful for understanding error relative to the size of the actual values. NLP MetricsAccuraryMeasures the overall correctness of the model’s predictions. params:• TP: True Positives (correctly predicted positive cases)• FP: False Positives (incorrectly predicted positive cases)• TN: True Negatives (actual negative cases correctly predicted as negative)• FN: False Negatives (actual positive cases incorrectly predicted as negative) Precision Precision indicates the accuracy of positive predictions. Recall (Sensitivity)Recall measures the model’s ability to identify all relevant instances. F1 ScoreThe F1 Score is the harmonic mean of precision and recall, balancing the two metrics. BLEU Score (Bilingual Evaluation Understudy)BLEU measures the quality of machine-generated text against reference texts, focusing on n-gram matches. params:• : Brevity Penalty• : Precision for n-grams• : Weight for each n-gram precision (often uniform) CV MetricsIntersection over Union (IoU)IoU measures the overlap between the predicted and actual bounding boxes, commonly used in object detection tasks. params:• : Predicted bounding box area• : Ground truth bounding box area Mean Average Precision (mAP)mAP summarizes the precision-recall curve and provides a single measure of performance across different classes. params:• : Total number of categories involved• : Average Precision for recall Pixel AccuracyMeasures the percentage of correctly classified pixels in an image segmentation task. params:• Correct Pixels: Pixels classified correctly.• Total Pixels: Total number of pixels in the image. Structural Similarity Index (SSIM)SSIM measures the similarity between two images, considering luminance, contrast, and structure. params:• : Two images being compared• : Mean values of the images• : Variances of the images• : Covariance of the images• : Constants to stabilize the division ReferencesMath functions of Common Metrics","link":"/blogs/Mathematical_Functions_of_Common_Metrics/"},{"title":"Quotes","text":"IntroductionThis blog will showcase quotes, mottos, poems and even lyrics that inspire me to reflect on my life experiences and attitudes, especially during those grueling days. These words of wisdom have been collected and referenced from various sources online. Content123However bad life may seem, there is always something you can do and succeed at. Where there's life, there's hope – Stephen Hawking 12I can make it through the rain, I can stand up once again on my own – Mariah Carey – Through the Rain 12One day you'll leave this world behind, So live a life you will remember – Avicii - The Nights 123456When thunder clouds start pouring downLight a fire they can't put outCarve your name into those shinning starsHe said, &quot;Go venture far beyond the shores.Don't forsake this life of yours.I'll guide you home no matter where you are.&quot; – Avicii - The Nights 12345When your dreams come alive, you're unstoppableTake a shot, chase the Sun, find the beautifulWe will glow in the darkTurning dust to goldAnd we'll dream it possible – Delacey - Dream It Possible 123456789101112131415161718192021INVICTUSOut of the night that covers meBlack as the pit from pole to pole,I thank whatever gods may beFor my unconquerable soul.In the fell clutch of circumstance,I have not winced nor cried aloud.Under the bludgeonings of chanceMy head is bloody, but unbowed.Beyond this place of wrath and tearsLooms but the Horror of the shade,And yet the menace of the yearsFinds, and shall find, me unafraid.It matters not how strait the gate,How charged with punishments the scroll,I am the master of my fateI am the captain of my soul. – Victorian era British poet William Ernest Henley","link":"/life/quotes/"},{"title":"Scenic Pics","text":"IntroductionThis blog will showcase the scenic picturs from Unsplash, Bing Wallpaer, Momentum Dash and other various sources online. Content","link":"/life/scenic_pics/"},{"title":"Configure and deploy models on Kubeflow","text":"IntroductionThis blog is mainly on how to deploy Kubeflow on AWS EC2 and create model inference services in Kubeflow. Since some of the tutorials available online seem to be outdated, and it’s common to encounter unexpected and challenging bugs during implementation. This blog will also share some of the pitfalls I’ve encountered, along with solutions for future reviewing and reference. Create and Configure EC2 instance in AWS console dashboardWe’ll using an EC2 instance to install awscli, eksctl, and other support tools needed to create the EKS Cluster and Install Kubeflow. Login to the AWS Managment Console go to the AWS EC2 Dashboard Click on “Launch Instance” Name and tags Name: 1kubeflow-cloud-shell OS Image (Ubuntu preferably, for following apt and other command needed installing): 1Ubuntu:latest create your EC2 instance pair-key for following connection and accessing after the instance created 1pair-key Instance type 1t2.micro Network settings (You could use the default security group if you’ve already added ssh as an inbound rule) 123Select &quot;Create Security Group&quot;Select &quot;Allow SSH traffic from&quot;Select &quot;Anywhere&quot; Storage （Bigger SSD storage set-up are better for avoiding unexpected and difficult debugging bugs on the following process of creating EKS cluster and its nodes-group） 1SSD:30GB, EBS:gp3 volumes After setting up, review and launch your EC2 instance! Connect and access your EC2 instance!There are three different ways to do that The first one is pretty simple and easy.Just press the connect button on the EC2 dashboard, after navigate to launch page, press the launch button directly if you are fine with the default setting. Using ssh command (if you save the pair-key format as .pem, or you could use PuTTYgen to convert your pair-key from .ppk to .pem format. And there also is a tutorial about how to implement it! ) 123# open your Linux env bash terminal # assume pwd is the directory you run ssh command fromssh -i &lt;pair-key.pem&gt; ubuntu@ec2-&lt;your-ec2-public-ipv4-DNS&gt; Using PuTTY 12345678# open your PuTTy dashboard├── Session/ │ └── Logging/ # fill out &lt;hostname(ip-address): ubuntu@ec2-&lt;public-ipv4-DNS&gt; &lt;port:22&gt; &lt;connection-type: SSH&gt;...└── Connection/ └── SSH/ └── Auth/ # press 'browse' button to add and configure your private key file with .ppk format for auth... Install basic tools (apt, conda, kubeflow-manifests repo etc)Firstly, we need to stay the installation and other basic cmd updated 12sudo apt updatesudo apt install git curl unzip tar make sudo vim wget -y It would be better to install Conda for the following package needed installation efficiency, running-environment isolation and the reduction of dependency packages potential conflicts 12345# We choose miniconda for lightweight installation and efficiency (Anaconda is also a good choice for flexibilitymkdir -p ~/miniconda3wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.shbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3rm ~/miniconda3/miniconda.sh And we also need to change the system file ~/.bashrc 1234# edit the ~/.bashrc file using vim, nano etc# adding the command below and save export PATH=&quot;$HOME/miniconda3/bin:$PATH&quot; Back to the terminal, run the cmd below, and restart the terminal to make it work 1source ~/.bashrc It now should be able to make the MiniConda work and stay in the ‘base’ mode 12# your temninal be like:(base) [ubuntu:&lt;Your private Ipv4 DNS&gt; ~]$ We Could create and activate an env to set up the following packages needed 123# assume env-name is kubeflow_v1 or you could pick a name you happy with# python version 3.8 or above are both acceptable conda create --name kubeflow_v1 python=3.8 And the terminal should be like that after running 12(kubeflow_v1) [ubuntu:&lt;Your private Ipv4 DNS&gt; ~]$ and we use these commands ‘$python3.8$’, ‘which pip3’ and ‘which pip’ to check if they work simply 1234567891011$python3.8# and it should be like that# input 'exit()' to exit python terminalpython3.8.x ......&gt;&gt;&gt;&gt;&gt;&gt; exit()$$which pip/usr/bin/pip$which pip3/user/bin/pip3 Alright, time for installing the main part of kubeflow: the latest and compatible Kubeflow and AWS release versions are showed below, you could also replace the tag KUBEFLOW_RELEASE_VERSION and AWS_RELEASE_VERSION with one you happy with. There is also an instruction about how to choose the releases and versions 123456export KUBEFLOW_RELEASE_VERSION=v1.7.0export AWS_RELEASE_VERSION=v1.7.0-aws-b1.0.3git clone https://github.com/awslabs/kubeflow-manifests.git &amp;&amp; cd kubeflow-manifestsgit checkout ${AWS_RELEASE_VERSION}git clone --branch ${KUBEFLOW_RELEASE_VERSION} https://github.com/kubeflow/manifests.git upstream Make sure the terminal stay in the kubeflow-manifests directory and install tools needed from Makefile 12# it should be like:(kubeflow_v1) [ubuntu:&lt;Your private Ipv4 DNS&gt; kubeflow-manifests]$ 1$make install-tools After that, it might throw an exception about fail to install python3.8, but we could ignore it safely since we have get the python3.8 env configured and run the following command to continue to install the ones to be installed 1$ make install-python-packages For more info about why the error happened, we could dive into the Makefile to check it out 123456789# Makefile part of code snippets:...install-python: sudo apt install -q python3.8 -y sudo apt install -q python3-pip -y python3.8 -m pip install --upgrade pipinstall-tools: ...... install-python ......... Since it seems to be showing exception apt:python3.8 package not found sometimes, we have configured env python3.8 and pip package so could feel free to ignore it. Finally, ensure the packages below installed completely after run ‘make install-tools’ AWS CLI - A command line tool for interacting with AWS services. eksctl - A command line tool for working with EKS clusters. kubectl - A command line tool for working with Kubernetes clusters. yq - A command line tool for YAML processing. (For Linux environments, use the wget plain binary installation) jq - A command line tool for processing JSON. kustomize version 5.0.1 - A command line tool to customize Kubernetes objects through a kustomization file. python 3.8+ - A programming language used for automated installation scripts. pip - A package installer for python. terraform - An infrastructure as code tool that lets you develop cloud and on-prem resources. helm - A package manager for Kubernetes (referenced from awslabs) Configure AWS credentials, regions and deploy AWS EKS cluster, node-groupFor aws credentials config, you might need set up IAM credential to get your AWS account access key and secret key. Follow AWS CLI Configure Quickstart documentation to setup your IAM credentials. After getting the two keys, configure the AWS creds and regions for further EKS deployments 123456789aws configure --profile=kubeflow# AWS Access Key ID [None]: &lt;enter access key id&gt;# AWS Secret Access Key [None]: &lt;enter secret access key&gt;# Default region name [None]: &lt;AWS region&gt;# Default output format [None]: json# Set the AWS_PROFILE variable with the profile aboveexport AWS_PROFILE=kubeflow Once your configuration is complete, run ’aws sts get-caller-identity’ to verify that AWS CLI has access to your IAM credentials. And it should be fine if nothing error happened even though there is nothing print-out. Configure your EKS cluster_name, region: 1234# cluster_name 'kubeflow' is just used for exampleexport CLUSTER_NAME=kuebflow# us-east-1 is just used for example, please change that if it is not according to your account regionexport CLUSTER_REGION=us-east-1 Then we create EKS cluster and its node-group for kubeflow deployment. 1make create-eks-cluster If you want to set up your own EKS cluster and node-group (EKS version,Nodes_number etc), please use the eksctl command to finish the set-up for reference. 1234567891011eksctl create cluster \\ --name $(CLUSTER_NAME) \\ --version 1.25 \\ --region $(CLUSTER_REGION) \\ --nodegroup-name linux-nodes \\ --node-type m5.xlarge \\ --nodes 5 \\ --nodes-min 5 \\ --nodes-max 10 \\ --managed \\ --with-oidc Generally, it may take just a few minutes to finish up. But sometimes,unexpectedly,you might encounter the issue like still waiting for AWS ***cloudFormation*** creating cluser &lt;cluster_name&gt; still waiting for ***cloudFormation*** creating node-group &lt;node_group_name&gt; after waiting for a long time and even throw an TimeOut error sometimes. And the related blocks in AWS cloudFormation might show ROLL_BACK_Failed in status. One of the possible and simplest solutions is just accessing cloudFormation, deleting the block with the same name, and try it again. Lastly,after it finish up, we use awscli and kubectl to check if the cluster and its node-group status is active and all fine(And in fact, it is likely to be working normally once the installation done) 12aws eks describe-cluster --region &lt;your-region&gt; --name &lt;your-cluster-name&gt; -query &quot;cluster.status&quot; 1kubectl get nodes Install Kubeflow Pods requiredpreparationThere are two preparation work we need to do replace the old image file with new one in the **kubeflow-manifests/charts/common/oidc-authservice/templates/StatefulSet/authservice-istio-system-StatefulSet.yaml file** 1234# locate the following line in the filedocker pull gcr.io/arrikto/kubeflow/oidc-authservice:e236439# and replace it with the new docker file addrdocker pull docker.io/kubeflowmanifestswg/oidc-authservice:e236439 Otherwise it will result in oidc-authservice pod installation failed. We need to install AWS EBS CSI driver for the EKS cluster created from accessing the AWS EKS dashboard add-ons. Otherwise it will result in the following pods installation failed like my-sql,minio pods etc with kubeflow-pipeline namespaces. Please reference the tutorial to configure it. After that, let us go back to the kubeflow-manifests directory and install the Kubeflow Pods needed. 1make deploy-kubeflow INSTALLATION_OPTION=helm DEPLOYMENT_OPTION=vanilla It should take up just a few mins. If the installation process get stuck in some pods deployment like oidc-authservice, kubeflow-pipeline etc from observing the print-out for a long time (like 5mins or above) and throw the timeout error constantly, please use CTRL+C to interrupt the installation, go back and check if the preparation work is all-set above and try again. Finally, use the kubectl cmd below to check if all pods are all-set 1234567kubectl get pods -n cert-managerkubectl get pods -n istio-systemkubectl get pods -n authkubectl get pods -n knative-eventingkubectl get pods -n knative-servingkubectl get pods -n kubeflowkubectl get pods -n kubeflow-user-example-com And there also are some useful commands to help debug and config the pods fail to work 123456789101112# get all pods info, especially getting their names for debuggingkubectl get pods --all-namespaces# check the pod infokubectl describe pod &lt;pod_name&gt; -n &lt;namespace&gt;# check the pod logskubectl logs &lt;pod_name&gt; -n &lt;namespace&gt;# once your figure the bug out, change the StatefulSet(pod controller used) set-up yaml of the pod# and use the cmd below to get the StatefulSet name of the podkubectl get pod &lt;pod_name&gt; -n &lt;namespace&gt; -o jsonpath='{.metadata.ownerReferences[*].name}'# then edit (it'll open the vim ediot automatically if installed)kubectl edit statefulset &lt;statefulset_name&gt; -n &lt;namespace&gt;# after editing and saving, exit the vim editor, it'll apply the change automatically If it’s all going well,it’s time to connect the Kubeflow dashboard Connect the Kubeflow Dashboard123456make port-forward# or you could change the port number if port：8080 in your local machine get occupied by other services$(eval IP_ADDRESS:=127.0.0.1)$(eval PORT:=8080)kubectl port-forward svc/istio-ingressgateway --address $(IP_ADDRESS) -n istio-system $(PORT):80 and open another terminal to establish the connection 12#assume pwd is the directory you run ssh command fromssh -i &lt;pair-key.pem&gt; -L 8080:localhost:8080 -N ubuntu@ec2-&lt;your-ec2-public-ipv4-DNS&gt; go to the browser and input username: user@example.com and password: 12341234 It’s advised that change the plain text password as hash one for security 123#this command will convert your plain text password input to hash formation by using bcrypt packagespython3 -c 'from passlib.hash import bcrypt; import getpass; print(bcrypt.using(rounds=12, ident=&quot;2y&quot;).hash(getpass.getpass()))' then edit upstream/common/dex/base/config-map.yaml and fill the relevant field with the hash one you chose: 1234... staticPasswords: - email: user@example.com hash: &lt;enter the generated hash here&gt; Congrats!!!, You should be able to see the Kubeflow dashboard now! And we have finished the Kubeflow Config on AWS EC2 Connect the Kubeflow Notebooks ServerFirstly, we need to apply the yaml file below to access Kubeflow pipeline service from notebooks server 1234567891011121314151617181920212223242526# access-kfp-from-notebooks.yamlapiVersion: kubeflow.org/v1alpha1 # Specify the API version to interact with Kubeflowkind: PodDefault # This is a PodDefault object used to define default settingsmetadata: name: access-ml-pipeline # Give this PodDefault a friendly name namespace: kubeflow-user-example-com # kubeflow defalut namespacespec: desc: Allow access to Kubeflow Pipelines # Describe the purpose of this PodDefault selector: matchLabels: access-ml-pipeline: &quot;true&quot; # Select Pods with this label to apply these default settings volumes: - name: volume-kf-pipeline-token # Define a name for the volume projected: # Use a projected volume to include content from multiple sources sources: - serviceAccountToken: # Obtain a token from the service account path: token # Path where the token will be stored in the volume expirationSeconds: 7200 # Set the token's validity period to 2 hours, change that for longer period if u want audience: pipelines.kubeflow.org # Specify the audience for the token as Kubeflow Pipelines volumeMounts: - mountPath: /var/run/secrets/kubeflow/pipelines # Specify the path where the volume will be mounted in the Pod name: volume-kf-pipeline-token # Name of the volume being mounted readOnly: true # Set the volume to read-only to protect the data env: - name: KF_PIPELINES_SA_TOKEN_PATH # Set an environment variable to point to the token path value: /var/run/secrets/kubeflow/pipelines/token # The value of this environment variable and apply the change by using kubectl cmd 1kubectl apply -f access-kfp-from-notebooks.yaml then go to Kubeflow Notebooks dashboard and spin up a new notebook server for deploying our models on Kserve 1234567891011# config# or change them witgh set-ups you happy withName=kubeflow_v1# configure the docker_image you happy with for env and package dependenciesDocker_image=public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0 CPU=2, RAM=4GiBGPU=1， GPU Vendor=NVIDIAWorkspace_volume=default# please set up this configConfigurations=allow access to Kfp Pipelines after creating, we need to set up MinIO to manage our working data Setup MinIO for Object Storagewe need another two terminal to deal with that, one for forwarding the MinIO pod’s port to the local port and the other one for making connection with the local port on local machine to access MinIO service In the first one, using kubectl cmd to forward the port 123# you can also change the &lt;local-port: 9000&gt; as you want if it is occupiedkubectl port-forward -n kubeflow svc/minio-service &lt;local-port&gt;:&lt;pod-port&gt;kubectl port-forward -n kubeflow svc/minio-service 9000:9000 considering We need MinIO username and password to access MinIO dashboard for more info, which are minio and minio123 separately，and just for sure, We can also access them by using kubctl cmd: 1234# get accesskey (username)kubectl get secret mlpipeline-minio-artifact -n kubeflow -o jsonpath=&quot;{.data.accesskey}&quot; | base64 --decode# get secretkey (password)kubectl get secret mlpipeline-minio-artifact -n kubeflow -o jsonpath=&quot;{.data.secretkey}&quot; | base64 --decode and it’s advised to change the default username and password for security. One Tutorial for reference. Alright in the second one, using ssh cmd to connect 1ssh -i &lt;pair-key.pem&gt; -L 9000:localhost:9000 -N ubuntu@ec2-&lt;your-ipv4-DNS&gt; access ***localhost:9000*** in your local machine browser, enter the username and password. Now you should be able to see the MinIO dashboard like that: And then, we go ahead and start to deploy the kserve for inference service Setting up MinIO secret for Kserve for inference serviceWe need to apply this yaml file below so that the working data(train_dataset, models etc) which will be saved on minIO can be accessed by Kserve. Kserve could copy the model to be saved in the newly created inference container. 1234567891011121314151617181920212223# apply-minio-secret-to-kserve.yamlapiVersion: v1kind: Secretmetadata: name: minio-kserve-secret # Name of the secret for accessing MinIO. namespace: kubeflow-user-example-com # Namespace where this secret is located. annotations: serving.kserve.io/s3-endpoint: &quot;minio-service.kubeflow:9000&quot; # Specifies the S3 endpoint for MinIO service. serving.kserve.io/s3-usehttps: &quot;0&quot; # Indicates that HTTPS is not used (0 means false). serving.kserve.io/s3-useanoncredential: &quot;false&quot; # Denotes that anonymous credentials are not used (false means credentials are required).type: Opaque # Type of the secret, indicating it's in plain text format.stringData: AWS_ACCESS_KEY_ID: &quot;minio&quot; # AWS access key ID for authentication. AWS_SECRET_ACCESS_KEY: &quot;minio123&quot; # AWS secret access key for authentication.---apiVersion: v1kind: ServiceAccountmetadata: name: sa-minio-kserve # Name of the service account for MinIO access. namespace: kubeflow-user-example-com # Namespace where this service account is created.secrets:- name: minio-kserve-secret # Associates the service account with the MinIO secret created earlier. then we apply the yaml file for changes 1kubectl apply -f apply-minio-secret-to-kserve.yaml After that, we start to deploy our models to Kserve from MinIO to check if the changes above work and get the inference service started. Deploy models on Kserve inference servicesThere are five ways to deal with that, first and second one would be a good choice for quick-start, and the third one have enough advantages on developing and debugging by using the most common component of Kubeflow, which is Kubeflow pipelines(Kfp). The fourth and fifth one are using argo workflow and tekton separately. Argo workflow is famous by its DAG, flexible execution flow and task reusability. Tekton is known by its structured pipeline and strong CI/CD integration. And We will use one of my LSTM models for the demo. For more info about the model, please access the project:Time Series Forecasting(LSTM) Using GitHub In the first method, We will be using the model uploaded on GitHub mainly and a few funcs from kfp components packages to deploy kserve inference services Since we have configured the connection to Kubeflow Jupyter notebooks server before, let’s create one new ipynb file with python kernel. In the new file, clone the repo and take the model directory 1234import tensorflow as tf!git clone https://github.com/PaddyZz/Time_Series_Forecasting.git!mkdir lstm_model_dir &amp;&amp; cp .../repo_dir/models/* lstm_model_dirrm -rf repo_dir then upload the model directory to MinIO bucket for kserve inference service. Before that, we need to get the MinIO pod cluster IP 1234# get exact minio service namekubectl get svc -n kubeflow# check out the cluster IPkubectl describe svc &lt;svc-name&gt; -n kubeflow after that, upload the model directory with the model 12345678910111213141516171819202122232425262728from minio import Minioimport osimport globminio_client = Minio( &quot;&lt;MinIO clsuter-IP&gt;:9000&quot;, access_key=&quot;minio&quot;, secret_key=&quot;minio123&quot;, secure=False )minio_bucket = &quot;mlpipeline&quot; # default bucket namedef upload_local_directory_to_minio(local_path, bucket_name, minio_path): assert os.path.isdir(local_path) for local_file in glob.glob(local_path + '/**'): local_file = local_file.replace(os.sep, &quot;/&quot;) # Replace \\ with / on Windows if not os.path.isfile(local_file): upload_local_directory_to_minio( local_file, bucket_name, minio_path + &quot;/&quot; + os.path.basename(local_file)) else: remote_path = os.path.join( minio_path, local_file[1 + len(local_path):]) remote_path = remote_path.replace( os.sep, &quot;/&quot;) # Replace \\ with / on Windows minio_client.fput_object(bucket_name, remote_path, local_file) upload_local_directory_to_minio(&quot;/lstm_model_dir/&quot;,minio_bucket,&quot;/models/lstm_model_dir/&quot;) you could have a look to see if there is the model directory in the MinIO bucket from the browser After observing if there is no problem, deploy the inference service! 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import kfpimport kfp.components as componentsdef model_serving(): &quot;&quot;&quot; Create kserve instance &quot;&quot;&quot; from kubernetes import client from kserve import KServeClient from kserve import constants from kserve import utils from kserve import V1beta1InferenceService from kserve import V1beta1InferenceServiceSpec from kserve import V1beta1PredictorSpec from kserve import V1beta1TFServingSpec namespace = utils.get_default_target_namespace() name='weather-prediction-kserve-inference-service-v1' kserve_version='v1beta1' api_version = constants.KSERVE_GROUP + '/' + kserve_version isvc = V1beta1InferenceService(api_version=api_version, kind=constants.KSERVE_KIND, metadata=client.V1ObjectMeta( name=name, namespace=namespace, annotations={'sidecar.istio.io/inject':'false'}), spec=V1beta1InferenceServiceSpec( predictor=V1beta1PredictorSpec( service_account_name=&quot;sa-minio-kserve&quot;, #see apply-minio-secret-to-kserve.yaml tensorflow=(V1beta1TFServingSpec( storage_uri=&quot;s3://mlpipeline/models/lstm_model_dir&quot;)))) ) KServe = KServeClient() KServe.create(isvc) comp_model_serving = components.create_component_from_func(model_serving,base_image=&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;, packages_to_install=['kserve==0.8.0.1']) #define the pipelinefrom kfp import dsl@dsl.pipeline( name='weather-pred-pipeline', description='weather-prediction')def weather_pred(): comp_model_serving()if __name__ == &quot;__main__&quot;: #connect to kfp client import requests USERNAME=&quot;user@example.com&quot; PASSWORD=&quot;12341234&quot; NAMESPACE=&quot;kubeflow-user-example-com&quot; HOST='http://istio-ingressgateway.istio-system.svc.cluster.local:80' session=requests.Session() response=session.get(HOST) headers={&quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;,} data={&quot;login&quot;: USERNAME, &quot;password&quot;: PASSWORD} session.post(response.url, headers=headers, data=data) session_cookie=session.cookies.get_dict()[&quot;authservice_session&quot;] client=kfp.Client(host=f&quot;{HOST}/pipeline&quot;, cookies=f&quot;authservice_session={session_cookie}&quot;,) client.create_run_from_pipeline_func(weather_pred,arguments=None,experiment_name=&quot;weather-prediction-v1-exp&quot;) (access Run in Kubeflow central board menu panel and checkout the logs if the inference endpoint have not been set up correctly or there are other bugs) then make a request to test the inference service. Before that, We need some functions from my model project to get the inputs in tf.tensor for the inference input 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223import osimport pandas as pdimport zipfileimport tensorflow as tfdef getDataset(): &quot;&quot;&quot; Downloads and extracts a CSV dataset from a remote ZIP file, processes the data, and returns a DataFrame and a Series. The function performs the following steps: 1. Downloads a ZIP file containing the dataset from a specified URL. 2. Extracts the ZIP file into the current working directory. 3. Reads the CSV file from the extracted contents into a DataFrame. 4. Processes the DataFrame by slicing it to include every 6th row starting from the 5th row and converting the 'Date Time' column to datetime objects. 5. Cleans up by removing the ZIP file and extracted CSV file. Returns: df (pd.DataFrame): Processed DataFrame containing the dataset with every 6th row. date_time (pd.Series): Series containing datetime objects converted from the 'Date Time' column. Raises: KeyError: If the 'Date Time' column is not found in the CSV file. &quot;&quot;&quot; zip_path = tf.keras.utils.get_file( origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip', fname='jena_climate_2009_2016.csv.zip', extract=False) extract_dir = os.path.dirname(zip_path) with zipfile.ZipFile(zip_path, 'r') as zip_ref: zip_ref.extractall(extract_dir) extracted_files = zip_ref.namelist() csv_files = [f for f in extracted_files if f.endswith('.csv')] if csv_files: csv_path = os.path.join(extract_dir, csv_files[0]) df = pd.read_csv(csv_path) if 'Date Time' in df.columns: # sliceData df = df[5::6] date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S') else: raise KeyError(&quot;'Date Time' column not found in the CSV file.&quot;) def splitDataAndNormalization(df): n = len(df) train_df = df[0:int(n*0.7)] val_df = df[int(n*0.7):int(n*0.9)] test_df = df[int(n*0.9):] num_features = df.shape[1] train_mean = train_df.mean() train_std = train_df.std() train_df = (train_df - train_mean) / train_std val_df = (val_df - train_mean) / train_std #validation_df test_df = (test_df - train_mean) / train_std return train_df,val_df,test_df,num_featuresdef cleanUpOutlier(df): wv = df['wv (m/s)'] bad_wv = wv == -9999.0 wv[bad_wv] = 0.0 max_wv = df['max. wv (m/s)'] bad_max_wv = max_wv == -9999.0 max_wv[bad_max_wv] = 0.0 import numpy as npimport matplotlib.pyplot as pltclass WindowGenerator(): def __init__(self, input_width, label_width, shift, train_df, val_df, test_df, label_columns=None): # Store the raw data. self.train_df = train_df self.val_df = val_df self.test_df = test_df # Work out the label column indices. self.label_columns = label_columns if label_columns is not None: self.label_columns_indices = {name: i for i, name in enumerate(label_columns)} self.column_indices = {name: i for i, name in enumerate(train_df.columns)} # Work out the window parameters. self.input_width = input_width self.label_width = label_width self.shift = shift self.total_window_size = input_width + shift self.input_slice = slice(0, input_width) self.input_indices = np.arange(self.total_window_size)[self.input_slice] self.label_start = self.total_window_size - self.label_width self.labels_slice = slice(self.label_start, None) self.label_indices = np.arange(self.total_window_size)[self.labels_slice] def __repr__(self): return '\\n'.join([ f'Total window size: {self.total_window_size}', f'Input indices: {self.input_indices}', f'Label indices: {self.label_indices}', f'Label column name(s): {self.label_columns}']) @property def train(self): return self.make_dataset(self.train_df) @property def val(self): return self.make_dataset(self.val_df) @property def test(self): return self.make_dataset(self.test_df) @property def example(self): &quot;&quot;&quot;Get and cache an example batch of `inputs, labels` for plotting.&quot;&quot;&quot; result = getattr(self, '_example', None) if result is None: # No example batch was found, so get one from the `.train` dataset result = next(iter(self.train)) # And cache it for next time self._example = result return result def plot(self, plot_col='T (degC)', max_subplots=1, pred_tensor): inputs, labels = self.example plt.figure(figsize=(12, 8)) plot_col_index = self.column_indices[plot_col] max_n = min(max_subplots, len(inputs)) for n in range(max_n): plt.subplot(max_n, 1, n+1) plt.ylabel(f'{plot_col} [normed]') plt.plot(self.input_indices, inputs[n, :, plot_col_index], label='Inputs', marker='.', zorder=-10) if self.label_columns: label_col_index = self.label_columns_indices.get(plot_col, None) else: label_col_index = plot_col_index if label_col_index is None: continue plt.scatter(self.label_indices, pred_tensor[n, :, label_col_index], marker='X', edgecolors='k', label='Predictions', c='#ff7f0e', s=64) if n == 0: plt.legend() plt.xlabel('Time [h]') plt.show() def split_window(self, features): inputs = features[:, self.input_slice, :] labels = features[:, self.labels_slice, :] if self.label_columns is not None: labels = tf.stack( [labels[:, :, self.column_indices[name]] for name in self.label_columns], axis=-1) # Slicing doesn't preserve static shape information, so set the shapes # manually. This way the `tf.data.Datasets` are easier to inspect. inputs.set_shape([None, self.input_width, None]) labels.set_shape([None, self.label_width, None]) return inputs, labels def make_dataset(self, data): data = np.array(data, dtype=np.float32) ds = tf.keras.utils.timeseries_dataset_from_array( data=data, targets=None, sequence_length=self.total_window_size, sequence_stride=1, shuffle=True, batch_size=32,) ds = ds.map(self.split_window) return ds if __name__ == &quot;__main__&quot;: from kserve import KServeClient import requests df, date_time = getDataset() cleanUpOutlier(df) train_df,val_df,test_df,_ = splitDataAndNormalization(df) wide_window = WindowGenerator( input_width=24, label_width=24, shift=24, train_df=train_df,val_df=val_df,test_df=test_df, label_columns=None) inputs, _=wide_window.example KServe = KServeClient() isvc_resp = KServe.get(&quot;weather-prediction-kserve-inference-service-v1&quot;, namespace=&quot;kubeflow-user-example-com&quot;) isvc_url = isvc_resp['status']['address']['url'] inference_input = { 'instances': inputs.numpy().tolist() } response = requests.post(isvc_url, json=inference_input) predictions = response.json()['predictions'] pred_tensor = tf.convert_to_tensor(predictions) wide_window.plot(pred_tensor=pred_tensor) after getting inputs tensor, We change the tensor format as list for inference input and make an request to the endpoint deployed with the list. And we use the plot function to plot the response data got back from the endpoint. And the pic is like: Using Docker In the second method, we use docker to implement it will be similar to the first one open a new Jupyter file and pull the docker image 12345678910111213141516171819202122232425import docker# Pull the imageclient = docker.from_env()image = client.images.pull(&quot;&lt;docker_image_address&gt;&quot;) # Launch the containercontainer = client.containers.run( image=image.tags[0], name=&quot;my_container&quot;, detach=True, command=&quot;tail -f /dev/null&quot;)# Exec the container and check out the model dirresult = container.exec_run(&quot;ls /path/to/your/model&quot;)print(result.output.decode())# Copy the model dir to the expected dir in the Jupyter servercontainer.copy(&quot;my_container:/path/to/your/model&quot;, &quot;/local/path/to/save/model&quot;)# Stop and delete containercontainer.stop()container.remove() and then repeat the steps in the first method to deploy the kserve inference service Using Kubeflow pipeline(kfp) In the third method, we use kfp component fully to finish the most of MLOps including data_ingestion, pretrain_model, model_fit_train and the kserve inference service deployment，these 4 phases. And the implementing code will be similar to method one about data_ingestion and pretrain_model phases. Here is the code showing complete process of the phases and testing on Kfp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399import osimport pandas as pdimport tensorflow as tfimport zipfileimport numpy as npimport minio minio_client = minio( &quot;&lt;your-minio-cluster-ip&gt;:9000&quot;, access_key=&quot;minio&quot;, secret_key=&quot;minio123&quot;, secure=False )minio_bucket = &quot;mlpipeline&quot;def getDataset(): &quot;&quot;&quot; Downloads and extracts a CSV dataset from a remote ZIP file, processes the data, and returns a DataFrame and a Series. The function performs the following steps: 1. Downloads a ZIP file containing the dataset from a specified URL. 2. Extracts the ZIP file into the current working directory. 3. Reads the CSV file from the extracted contents into a DataFrame. 4. Processes the DataFrame by slicing it to include every 6th row starting from the 5th row and converting the 'Date Time' column to datetime objects. 5. Cleans up by removing the ZIP file and extracted CSV file. Returns: df (pd.DataFrame): Processed DataFrame containing the dataset with every 6th row. date_time (pd.Series): Series containing datetime objects converted from the 'Date Time' column. Raises: KeyError: If the 'Date Time' column is not found in the CSV file. &quot;&quot;&quot; zip_path = tf.keras.utils.get_file( origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip', fname='jena_climate_2009_2016.csv.zip', extract=False) extract_dir = os.path.dirname(zip_path) with zipfile.ZipFile(zip_path, 'r') as zip_ref: zip_ref.extractall(extract_dir) extracted_files = zip_ref.namelist() csv_files = [f for f in extracted_files if f.endswith('.csv')] if csv_files: csv_path = os.path.join(extract_dir, csv_files[0]) df = pd.read_csv(csv_path) if 'Date Time' in df.columns: # sliceData df = df[5::6] date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S') else: raise KeyError(&quot;'Date Time' column not found in the CSV file.&quot;) if os.path.exists(zip_path): os.remove(zip_path) for file_name in extracted_files: file_path = os.path.join(extract_dir, file_name) if os.path.exists(file_path): os.remove(file_path) df_npy = df.to_numpy() np.save(&quot;dataframes/df.npy&quot;,df_npy) minio_client.fput_object(minio_bucket,&quot;models/lstm/df&quot;,&quot;dataframes/df.npy&quot;) def splitDataAndNormalization(): minio_client.fget_object(minio_bucket,&quot;models/lstm/df&quot;,&quot;dataframes/df.npy&quot;) df_npy = np.load('dataframes/df.npy') df = pd.DataFrame(df_npy) wv = df['wv (m/s)'] bad_wv = wv == -9999.0 wv[bad_wv] = 0.0 max_wv = df['max. wv (m/s)'] bad_max_wv = max_wv == -9999.0 max_wv[bad_max_wv] = 0.0 n = len(df) train_df = df[0:int(n*0.7)] val_df = df[int(n*0.7):int(n*0.9)] test_df = df[int(n*0.9):] num_features = df.shape[1] train_mean = train_df.mean() train_std = train_df.std() train_df = (train_df - train_mean) / train_std val_df = (val_df - train_mean) / train_std #validation_df test_df = (test_df - train_mean) / train_std train_npy = train_df.to_numpy() test_npy = test_df.to_numpy() val_npy = val_df.to_numpy() np.save(&quot;dataframes/train.npy&quot;,train_npy) np.save(&quot;dataframes/test.npy&quot;,test_npy) np.save(&quot;dataframes/val.npy&quot;,val_npy) minio_client.fput_object(minio_bucket,&quot;models/lstm/train&quot;,&quot;dataframes/train.npy&quot;) minio_client.fput_object(minio_bucket,&quot;models/lstm/test&quot;,&quot;dataframes/test.npy&quot;) minio_client.fput_object(minio_bucket,&quot;models/lstm/val&quot;,&quot;dataframes/val.npy&quot;) def compile_and_fit(model, window, patience=2): early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min') model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.MeanAbsoluteError()]) history = model.fit(window.train, epochs=20, validation_data=window.val, callbacks=[early_stopping]) return history import numpy as npimport matplotlib.pyplot as pltclass WindowGenerator(): def __init__(self, input_width, label_width, shift, train_df, val_df, test_df, label_columns=None): # Store the raw data. self.train_df = train_df self.val_df = val_df self.test_df = test_df # Work out the label column indices. self.label_columns = label_columns if label_columns is not None: self.label_columns_indices = {name: i for i, name in enumerate(label_columns)} self.column_indices = {name: i for i, name in enumerate(train_df.columns)} # Work out the window parameters. self.input_width = input_width self.label_width = label_width self.shift = shift self.total_window_size = input_width + shift self.input_slice = slice(0, input_width) self.input_indices = np.arange(self.total_window_size)[self.input_slice] self.label_start = self.total_window_size - self.label_width self.labels_slice = slice(self.label_start, None) self.label_indices = np.arange(self.total_window_size)[self.labels_slice] def __repr__(self): return '\\n'.join([ f'Total window size: {self.total_window_size}', f'Input indices: {self.input_indices}', f'Label indices: {self.label_indices}', f'Label column name(s): {self.label_columns}']) @property def train(self): return self.make_dataset(self.train_df) @property def val(self): return self.make_dataset(self.val_df) @property def test(self): return self.make_dataset(self.test_df) @property def example(self): &quot;&quot;&quot;Get and cache an example batch of `inputs, labels` for plotting.&quot;&quot;&quot; result = getattr(self, '_example', None) if result is None: # No example batch was found, so get one from the `.train` dataset result = next(iter(self.train)) # And cache it for next time self._example = result return result def plot(self, plot_col='T (degC)', max_subplots=1, pred_tensor=None): inputs, labels = self.example plt.figure(figsize=(12, 8)) plot_col_index = self.column_indices[plot_col] max_n = min(max_subplots, len(inputs)) for n in range(max_n): plt.subplot(max_n, 1, n+1) plt.ylabel(f'{plot_col} [normed]') plt.plot(self.input_indices, inputs[n, :, plot_col_index], label='Inputs', marker='.', zorder=-10) if self.label_columns: label_col_index = self.label_columns_indices.get(plot_col, None) else: label_col_index = plot_col_index if label_col_index is None: continue if not pred_tensor is None: plt.scatter(self.label_indices, pred_tensor[n, :, label_col_index], marker='X', edgecolors='k', label='Predictions', c='#ff7f0e', s=64) if n == 0: plt.legend() plt.xlabel('Time [h]') plt.show() def split_window(self, features): inputs = features[:, self.input_slice, :] labels = features[:, self.labels_slice, :] if self.label_columns is not None: labels = tf.stack( [labels[:, :, self.column_indices[name]] for name in self.label_columns], axis=-1) # Slicing doesn't preserve static shape information, so set the shapes # manually. This way the `tf.data.Datasets` are easier to inspect. inputs.set_shape([None, self.input_width, None]) labels.set_shape([None, self.label_width, None]) return inputs, labels def make_dataset(self, data): if not isinstance(data, np.ndarray): data = np.array(data, dtype=np.float32) ds = tf.keras.utils.timeseries_dataset_from_array( data=data, targets=None, sequence_length=self.total_window_size, sequence_stride=1, shuffle=True, batch_size=32,) ds = ds.map(self.split_window) return ds def upload_local_directory_to_minio(local_path, bucket_name, minio_path): import glob assert os.path.isdir(local_path) for local_file in glob.glob(local_path + '/**'): local_file = local_file.replace(os.sep, &quot;/&quot;) # Replace \\ with / on Windows if not os.path.isfile(local_file): upload_local_directory_to_minio( local_file, bucket_name, minio_path + &quot;/&quot; + os.path.basename(local_file)) else: remote_path = os.path.join( minio_path, local_file[1 + len(local_path):]) remote_path = remote_path.replace( os.sep, &quot;/&quot;) # Replace \\ with / on Windows minio_client.fput_object(bucket_name, remote_path, local_file) def train_model() minio_client.fget_object(minio_bucket,&quot;models/lstm/train&quot;,&quot;dataframes/train.npy&quot;) minio_client.fget_object(minio_bucket,&quot;models/lstm/test&quot;,&quot;dataframes/test.npy&quot;) minio_client.fget_object(minio_bucket,&quot;models/lstm/val&quot;,&quot;dataframes/val.npy&quot;) train_npy = np.load('dataframes/train.npy') test_npy = np.load('dataframes/test.npy') val_npy = np.load('dataframes/val.npy') multi_window = WindowGenerator( input_width=24, label_width=24, shift=24, train_df=train_npy,val_df=val_npy,test_df=test_npy, label_columns=None) multi_lstm_model = tf.keras.Sequential([ # Shape [batch, time, features] =&gt; [batch, lstm_units]. # Adding more `lstm_units` just overfits more quickly. tf.keras.layers.LSTM(32, return_sequences=False), # Shape =&gt; [batch, 24*features]. tf.keras.layers.Dense(24*14, kernel_initializer=tf.initializers.zeros()), # Shape =&gt; [batch, out_steps, features]. tf.keras.layers.Reshape([24, 14]) ]) _ = compile_and_fit(multi_lstm_model, multi_window) tf.saved_model.save(multi_lstm_model,'models/lstm/model_dir') upload_local_directory_to_minio(&quot;models/lstm/model_dir&quot;,minio_bucket,&quot;/models/lstm/model_dir/&quot;) import kfpimport kfp.components as componentsdef model_serving(): &quot;&quot;&quot; Create kserve instance &quot;&quot;&quot; from kubernetes import client from kserve import KServeClient from kserve import constants from kserve import utils from kserve import V1beta1InferenceService from kserve import V1beta1InferenceServiceSpec from kserve import V1beta1PredictorSpec from kserve import V1beta1TFServingSpec namespace = utils.get_default_target_namespace() name='weather-prediction-kserve-inference-service-v1' kserve_version='v1beta1' api_version = constants.KSERVE_GROUP + '/' + kserve_version isvc = V1beta1InferenceService(api_version=api_version, kind=constants.KSERVE_KIND, metadata=client.V1ObjectMeta( name=name, namespace=namespace, annotations={'sidecar.istio.io/inject':'false'}), spec=V1beta1InferenceServiceSpec( predictor=V1beta1PredictorSpec( service_account_name=&quot;sa-minio-kserve&quot;, #see apply-minio-secret-to-kserve.yaml tensorflow=(V1beta1TFServingSpec( storage_uri=&quot;s3://mlpipeline/models/lstm/model_dir/&quot;)))) ) KServe = KServeClient() KServe.create(isvc)comp_getting_df = components.create_component_from_func(getDataset,base_image=&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;, packages_to_install=['kserve==0.8.0.1']) comp_splitData_norm = components.create_component_from_func(splitDataAndNormalization,base_image=&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;, packages_to_install=['kserve==0.8.0.1']) comp_model_training = components.create_component_from_func(train_model,base_image=&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;, packages_to_install=['kserve==0.8.0.1']) comp_model_serving = components.create_component_from_func(model_serving,base_image=&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;, packages_to_install=['kserve==0.8.0.1']) #define the pipelinefrom kfp import dsl@dsl.pipeline( name='weather-pred-pipeline', description='weather-prediction')def weather_pred_pipeline(): step1 = comp_getting_df() step2 = comp_splitData_norm() step2.after(step1) step3 = comp_model_training() step3.after(step2) step4 = comp_model_serving() step4.after(step3) if __name__ == &quot;__main__&quot;: #connect to kfp client import requests from kserve import KServeClient USERNAME=&quot;user@example.com&quot; PASSWORD=&quot;12341234&quot; NAMESPACE=&quot;kubeflow-user-example-com&quot; HOST='http://istio-ingressgateway.istio-system.svc.cluster.local:80' session=requests.Session() response=session.get(HOST) headers={&quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;,} data={&quot;login&quot;: USERNAME, &quot;password&quot;: PASSWORD} session.post(response.url, headers=headers, data=data) session_cookie=session.cookies.get_dict()[&quot;authservice_session&quot;] client=kfp.Client(host=f&quot;{HOST}/pipeline&quot;, cookies=f&quot;authservice_session={session_cookie}&quot;,) client.create_run_from_pipeline_func(weather_pred_pipeline,arguments=None,experiment_name=&quot;weather-prediction-v1-exp&quot;) _, _ = getDataset() train_df,val_df,test_df,_ = splitDataAndNormalization() wide_window = WindowGenerator( input_width=24, label_width=24, shift=24, train_df=train_df,val_df=val_df,test_df=test_df, label_columns=None) inputs, _=wide_window.example KServe = KServeClient() isvc_resp = KServe.get(&quot;weather-prediction-kserve-inference-service-v1&quot;, namespace=&quot;kubeflow-user-example-com&quot;) isvc_url = isvc_resp['status']['address']['url'] inference_input = { 'instances': inputs.numpy().tolist() } response = requests.post(isvc_url, json=inference_input) predictions = response.json()['predictions'] pred_tensor = tf.convert_to_tensor(predictions) wide_window.plot(pred_tensor=pred_tensor) Using argo workflowIn the fourth method, We will be using argo workflows to spin up the kserve inferenece service and evaluate the model from the response after requesting to the endpoint deployed. Reference the tutorial for more info on argo installation 1234#install argo-workflowskubectl create namespace argokubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo/v2.12.2/manifests/namespace-install.yaml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667!git clone https://github.com/PaddyZz/Time_Series_Forecasting.git!cd my-lstm-repo-dir/.../argo #build a docker container for env and dependencies required#dockerfileFROM python:3.10.2RUN pip install virtualenvRUN virtualenv /envENV VIRTUAL_ENV=/envENV PATH=&quot;$VIRTUAL_ENV/bin:$PATH&quot;WORKDIR ['/argo','/models/lstm'] # set it up for model_save path COPY . /argoRUN python -m pip install --no-cache-dir -r requirements.txtCMD [&quot;python&quot;, &quot;main.py&quot;]#requirements.txt includes all the dependencies we need to build the other conatiners in argo workflowIPython==7.34.0matplotlib==3.7.1numpy==1.26.4pandas==2.1.4seaborn==0.13.1tensorflow==2.17.0pickleminioglobkserve=0.8.0.1kfp#build and push to docker repo for following deploymentimport dockerdef build_and_push_image(repo, image_name, tag): &quot;&quot;&quot; Builds and pushes a Docker image to a registry. Args: repo: The registry where the image will be pushed. image_name: The name of the image. tag: The tag for the image. &quot;&quot;&quot; client = docker.from_env() # Create a Docker client # Build the image try: client.images.build(path='.', tag=f&quot;{repo}/{image_name}:{tag}&quot;) except docker.errors.BuildError as e: print(f&quot;Build error: {str(e)}&quot;) # Log in to the registry (if necessary) try: client.login(username=&quot;&lt;your-username&gt;&quot;, password=&quot;&lt;your-password&gt;&quot;) except docker.errors.APIError as e: print(f&quot;Login error: {str(e)}&quot;) # Push the image to the registry try: for line in client.images.push(f&quot;{repo}/{image_name}:{tag}&quot;, stream=True): print(line.decode('utf-8').strip()) except docker.errors.APIError as e: print(f&quot;Push error: {str(e)}&quot;)# Example usagerepo = &quot;your_repo&quot;image_name = &quot;your_image&quot;tag = &quot;latest&quot;build_and_push_image(lstm_kserve_env, lstm_kserve_env, v1) after that we need to deal with data_ingestion, pretain_model, model_training, model_serving, these four phases for argo workflow deployment 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270#data_ingestion.pyimport osimport pandas as pdimport tensorflow as tfimport zipfileimport pickledef getDataset(inputs=False): &quot;&quot;&quot; Downloads and extracts a CSV dataset from a remote ZIP file, processes the data, and returns a DataFrame and a Series. The function performs the following steps: 1. Downloads a ZIP file containing the dataset from a specified URL. 2. Extracts the ZIP file into the current working directory. 3. Reads the CSV file from the extracted contents into a DataFrame. 4. Processes the DataFrame by slicing it to include every 6th row starting from the 5th row and converting the 'Date Time' column to datetime objects. 5. Cleans up by removing the ZIP file and extracted CSV file. Returns: df (pd.DataFrame): Processed DataFrame containing the dataset with every 6th row. date_time (pd.Series): Series containing datetime objects converted from the 'Date Time' column. Raises: KeyError: If the 'Date Time' column is not found in the CSV file. &quot;&quot;&quot; zip_path = tf.keras.utils.get_file( origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip', fname='jena_climate_2009_2016.csv.zip', extract=False) extract_dir = os.path.dirname(zip_path) with zipfile.ZipFile(zip_path, 'r') as zip_ref: zip_ref.extractall(extract_dir) extracted_files = zip_ref.namelist() csv_files = [f for f in extracted_files if f.endswith('.csv')] if csv_files: csv_path = os.path.join(extract_dir, csv_files[0]) df = pd.read_csv(csv_path) if 'Date Time' in df.columns: # sliceData df = df[5::6] date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S') else: raise KeyError(&quot;'Date Time' column not found in the CSV file.&quot;) if os.path.exists(zip_path): os.remove(zip_path) for file_name in extracted_files: file_path = os.path.join(extract_dir, file_name) if os.path.exists(file_path): os.remove(file_path) if inputs: return df #we use pickle to sequentilize our data for sharing with other funcs with open('/models/lstm/df.pkl', 'wb') as f: pickle.dump(df, f) return Noneif __name__ == &quot;__main__&quot;: getDataset()#pretrain_model.pyimport pickledef splitDataAndNormalization(inputs=False,df=None): if inputs is True and df is not None: pass else: with open('/models/lstm/df.pkl', 'rb') as f: df = pickle.load(f) wv = df['wv (m/s)'] bad_wv = wv == -9999.0 wv[bad_wv] = 0.0 max_wv = df['max. wv (m/s)'] bad_max_wv = max_wv == -9999.0 max_wv[bad_max_wv] = 0.0 n = len(df) train_df = df[0:int(n*0.7)] val_df = df[int(n*0.7):int(n*0.9)] test_df = df[int(n*0.9):] num_features = df.shape[1] train_mean = train_df.mean() train_std = train_df.std() train_df = (train_df - train_mean) / train_std val_df = (val_df - train_mean) / train_std #validation_df test_df = (test_df - train_mean) / train_std if input is True: return train_df, val_df, test_df with open('/models/lstm/train.pkl', 'wb') as f: pickle.dump(train_df, f) with open('/models/lstm/val.pkl', 'wb') as f: pickle.dump(val_df, f) with open('/models/lstm/test.pkl', 'wb') as f: pickle.dump(test_df, f) return Noneif __name__ == &quot;__main__&quot;: splitDataAndNormalization()#model_trainingimport tensorflow as tfimport osimport globimport pickleimport miniofrom argo.compile_and_fit import compile_and_fitfrom argo.data_windowing import WindowGenerator minio_client = minio( &quot;&lt;your-minio-cluster-ip&gt;:9000&quot;, access_key=&quot;minio&quot;, secret_key=&quot;minio123&quot;, secure=False )minio_bucket = &quot;mlpipeline&quot;def upload_local_directory_to_minio(local_path, bucket_name, minio_path): assert os.path.isdir(local_path) for local_file in glob.glob(local_path + '/**'): local_file = local_file.replace(os.sep, &quot;/&quot;) # Replace \\ with / on Windows if not os.path.isfile(local_file): upload_local_directory_to_minio( local_file, bucket_name, minio_path + &quot;/&quot; + os.path.basename(local_file)) else: remote_path = os.path.join( minio_path, local_file[1 + len(local_path):]) remote_path = remote_path.replace( os.sep, &quot;/&quot;) # Replace \\ with / on Windows minio_client.fput_object(bucket_name, remote_path, local_file)def model_train(): with open('/models/lstm/train.pkl', 'rb') as f: train_df = pickle.load(f) with open('/models/lstm/val.pkl', 'rb') as f: val_df = pickle.load(f) with open('/models/lstm/test.pkl', 'rb') as f: test_df = pickle.load(f) multi_window = WindowGenerator( input_width=24, label_width=24, shift=24, train_df=train_df,val_df=val_df,test_df=test_df, label_columns=None) multi_lstm_model = tf.keras.Sequential([ # Shape [batch, time, features] =&gt; [batch, lstm_units]. # Adding more `lstm_units` just overfits more quickly. tf.keras.layers.LSTM(32, return_sequences=False), # Shape =&gt; [batch, 24*features]. tf.keras.layers.Dense(24*14, kernel_initializer=tf.initializers.zeros()), # Shape =&gt; [batch, out_steps, features]. tf.keras.layers.Reshape([24, 14]) ]) _ = compile_and_fit(multi_lstm_model, multi_window) tf.saved_model.save(multi_lstm_model,'/models/lstm/model_dir') upload_local_directory_to_minio(&quot;/models/lstm/model_dir&quot;,minio_bucket,&quot;/models/lstm/model_dir/&quot;) if __name__==&quot;__main__&quot;: model_train() #model_servingimport kfpimport kfp.components as componentsfrom kubernetes import client from kserve import KServeClientfrom kserve import constantsfrom kserve import utilsfrom kserve import V1beta1InferenceServicefrom kserve import V1beta1InferenceServiceSpecfrom kserve import V1beta1PredictorSpecfrom kserve import V1beta1TFServingSpecfrom kfp import dslimport requestsdef model_serving(): &quot;&quot;&quot; Create kserve instance &quot;&quot;&quot; namespace = utils.get_default_target_namespace() name='weather-prediction-kserve-inference-service-v1' kserve_version='v1beta1' api_version = constants.KSERVE_GROUP + '/' + kserve_version isvc = V1beta1InferenceService(api_version=api_version, kind=constants.KSERVE_KIND, metadata=client.V1ObjectMeta( name=name, namespace=namespace, annotations={'sidecar.istio.io/inject':'false'}), spec=V1beta1InferenceServiceSpec( predictor=V1beta1PredictorSpec( service_account_name=&quot;sa-minio-kserve&quot;, #see apply-minio-secret-to-kserve.yaml tensorflow=(V1beta1TFServingSpec( storage_uri=&quot;s3://mlpipeline/models/lstm/model_dir/&quot;)))) ) KServe = KServeClient() KServe.create(isvc)comp_model_serving = components.create_component_from_func(model_serving,base_image=&quot;public.ecr.aws/j1r0q0g6/notebooks/notebook-servers/jupyter-tensorflow-full:v1.5.0&quot;, packages_to_install=['kserve==0.8.0.1']) @dsl.pipeline( name='weather-pred-pipeline', description='weather-prediction')def weather_pred_pipeline(): comp_model_serving()if __name__ == &quot;__main__&quot;: USERNAME=&quot;user@example.com&quot; PASSWORD=&quot;12341234&quot; NAMESPACE=&quot;kubeflow-user-example-com&quot; HOST='http://istio-ingressgateway.istio-system.svc.cluster.local:80' session=requests.Session() response=session.get(HOST) headers={&quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;,} data={&quot;login&quot;: USERNAME, &quot;password&quot;: PASSWORD} session.post(response.url, headers=headers, data=data) session_cookie=session.cookies.get_dict()[&quot;authservice_session&quot;] client=kfp.Client(host=f&quot;{HOST}/pipeline&quot;, cookies=f&quot;authservice_session={session_cookie}&quot;,) client.create_run_from_pipeline_func(weather_pred_pipeline,arguments=None,experiment_name=&quot;weather-prediction-v1-exp&quot;) #model_evaluatingfrom kserve import KServeClientimport requestsimport tensorflow as tf from argo.data_ingestion import getDatasetfrom argo.pretrian_model import splitDataAndNormalizationfrom argo.data_windowing import WindowGeneratordef model_evaluating(): df = getDataset(inputs=True) train_df,val_df,test_df,_ = splitDataAndNormalization(inputs=True,df=df) wide_window = WindowGenerator( input_width=24, label_width=24, shift=24, train_df=train_df,val_df=val_df,test_df=test_df, label_columns=None) inputs, _=wide_window.example KServe = KServeClient() isvc_resp = KServe.get(&quot;weather-prediction-kserve-inference-service-v1&quot;, namespace=&quot;kubeflow-user-example-com&quot;) isvc_url = isvc_resp['status']['address']['url'] inference_input = { 'instances': inputs.numpy().tolist() } response = requests.post(isvc_url, json=inference_input) predictions = response.json()['predictions'] pred_tensor = tf.convert_to_tensor(predictions) wide_window.plot(pred_tensor=pred_tensor)if __name__ == &quot;__main__&quot;: model_evaluating() and then we will set up the argo workflows yaml file to deploy it simply 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136#deploy-kserve-with-argo-workflow.yamlapiVersion: argoproj.io/v1alpha1kind: Workflowmetadata: namespace: argo generateName: deploy kserve annotations: {pipelines.kubeflow.org/kserve_sdk_version: 0.8.0.1 labels: {pipelines.kubeflow.org/kserve_sdk_version: 0.8.0.1}spec: entrypoint: data_ingestion dag: tasks: - name: data_ingestion template: data_ingestion outputs: parameters: - name: df - name: pretrain_model template: pretrain_model dependsOn: - data_ingestion inputs: parameters: - name: df valueFrom: from: &quot;{{tasks.data_ingestion.outputs.parameters.df}}&quot; outputs: parameters: - name: train_df - name: test_df - name: val_df - name: model_training template: model_training dependsOn: - pretrain_model inputs: parameters: - name: train_df valueFrom: from: &quot;{{tasks.pretrain_model.outputs.parameters.train_df}}&quot; - name: test_df valueFrom: from: &quot;{{tasks.pretrain_model.outputs.parameters.test_df}}&quot; - name: val_df valueFrom: from: &quot;{{tasks.pretrain_model.outputs.parameters.val_df}}&quot; outputs: parameters: - name: model_trained - name: model_serving template: model_serving dependsOn: - model_training - name: model_evaluating template: model_evaluating dependsOn: - model_serving templates: - name: data_ingestion outputs: parameters: - name: df volumes: - name: data-volume persistentVolumeClaim: claimName: {{inputs.parameters.pvc-name}} container: image: (lstm_kserve_env/lstm_kserve_env:v1 volumeMounts: - name: data-volume mountPath: /models/lstm command: [&quot;python&quot;, &quot;data_ingestion.py&quot;] - name: pretrain_model inputs: parameters: - name: df outputs: parameters: - name: train_df - name: val_df - name: test_df volumes: - name: data-volume persistentVolumeClaim: claimName: {{inputs.parameters.pvc-name}} container: image: (lstm_kserve_env/lstm_kserve_env:v1 volumeMounts: - name: data-volume mountPath: /models/lstm command: [&quot;python&quot;, &quot;pretrain_model.py&quot;] - name: model_training inputs: parameters: - name: train_df - name: test_df - name: val_df outputs: parameters: - name: models_traine volumes: - name: data-volume persistentVolumeClaim: claimName: {{inputs.parameters.pvc-name}} container: image: (lstm_kserve_env/lstm_kserve_env:v1 volumeMounts: - name: data-volume mountPath: /models/lstm command: [&quot;python&quot;, &quot;model_training.py&quot;] - name: model-serving volumes: - name: data-volume persistentVolumeClaim: claimName: {{inputs.parameters.pvc-name}} container: image: (lstm_kserve_env/lstm_kserve_env:v1 volumeMounts: - name: data-volume mountPath: /models/lstm command: [&quot;python&quot;, &quot;model_serving.py&quot;] - name: model_evaluating volumes: - name: data-volume persistentVolumeClaim: claimName: {{inputs.parameters.pvc-name}} container: image: (lstm_kserve_env/lstm_kserve_env:v1 volumeMounts: - name: data-volume mountPath: /models/lstm command: [&quot;python&quot;, &quot;model_evaluating.py&quot;] 1kubectl apply -f deploy-kserve-with-argo-workflow.yaml Using TektonIn the final method, we will deploy Tekton simply with yaml file simply and Tekton ‘s deployment method is similar to argo workflow deployment one’s with some additional fine-tunes in yaml file. Reference the tutorial for more info on Tekton installation 1234#install kfp-Tektonkubectl create namespace tektonkubectl apply -k https://github.com/kubeflow/kfp-tekton//manifests/kustomize/env/platform-agnostic-tekton?ref=v2.0.5 -n tekton 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187#deploy-kserve-with-tekton.yamlapiVersion: tekton.dev/v1beta1kind: Pipelinemetadata: namespace: tekton generateName: deploy-kserve- annotations: pipelines.kubeflow.org/kserve_sdk_version: &quot;0.8.0.1&quot; labels: pipelines.kubeflow.org/kserve_sdk_version: &quot;0.8.0.1&quot;spec: params: - name: pvc-name type: string tasks: - name: data-ingestion taskRef: name: data-ingestion-task outputs: results: - name: df - name: pretrain-model taskRef: name: pretrain-model-task runAfter: - data-ingestion params: - name: df value: &quot;$(tasks.data-ingestion.results.df)&quot; outputs: results: - name: train_df - name: test_df - name: val_df - name: model-training taskRef: name: model-training-task runAfter: - pretrain-model params: - name: train_df value: &quot;$(tasks.pretrain-model.results.train_df)&quot; - name: test_df value: &quot;$(tasks.pretrain-model.results.test_df)&quot; - name: val_df value: &quot;$(tasks.pretrain-model.results.val_df)&quot; outputs: results: - name: model_trained - name: model-serving taskRef: name: model-serving-task runAfter: - model-training - name: model-evaluating taskRef: name: model-evaluating-task runAfter: - model-serving---apiVersion: tekton.dev/v1beta1kind: Taskmetadata: name: data-ingestion-taskspec: results: - name: df steps: - name: ingest-data image: lstm_kserve_env/lstm_kserve_env:v1 script: | #!/bin/sh python data_ingestion.py volumeMounts: - name: data-volume mountPath: /models/lstm volumes: - name: data-volume persistentVolumeClaim: claimName: $(params.pvc-name)---apiVersion: tekton.dev/v1beta1kind: Taskmetadata: name: pretrain-model-taskspec: params: - name: df type: dataframe results: - name: train_d - name: test_df - name: val_df steps: - name: pretrain image: lstm_kserve_env/lstm_kserve_env:v1 script: | #!/bin/sh python pretrain_model.py volumeMounts: - name: data-volume mountPath: /models/lstm volumes: - name: data-volume persistentVolumeClaim: claimName: $(params.pvc-name)---apiVersion: tekton.dev/v1beta1kind: Taskmetadata: name: model-training-taskspec: params: - name: pvc-name type: dataframe - name: train_df type: dataframe - name: test_df type: dataframe - name: val_df type: dataframe results: - name: model_trained steps: - name: train image: lstm_kserve_env/lstm_kserve_env:v1 script: | #!/bin/sh python model_training.py volumeMounts: - name: data-volume mountPath: /models/lstm volumes: - name: data-volume persistentVolumeClaim: claimName: $(params.pvc-name)---apiVersion: tekton.dev/v1beta1kind: Taskmetadata: name: model-serving-taskspec: steps: - name: serve image: lstm_kserve_env/lstm_kserve_env:v1 script: | #!/bin/sh python model_serving.py volumeMounts: - name: data-volume mountPath: /models/lstm volumes: - name: data-volume persistentVolumeClaim: claimName: $(params.pvc-name)---apiVersion: tekton.dev/v1beta1kind: Taskmetadata: name: model-evaluating-taskspec: steps: - name: evaluate image: lstm_kserve_env/lstm_kserve_env:v1 script: | #!/bin/sh python model_evaluating.py volumeMounts: - name: data-volume mountPath: /models/lstm volumes: - name: data-volume persistentVolumeClaim: claimName: $(params.pvc-name) 1kubectl apply -f deploy-kserve-with-tekton.yaml Potential Improvement Opportunitiesusing RabbitMQ or Kafka message queue suitable for high concurrency scenarios when deploying Kserve if needed Thanks for the watching! Hope the blog can help you improve your understanding of how to spin up Kubeflow on AWS EC2 and deploy the KServe inference service! ConclusionWe have finished:• Create and Configure EC2 instance in AWS console dashboard• Connect and access your EC2 instance• Install basic tools (apt, conda, kubeflow-manifests repo etc)• Configure AWS credentials, regions and deploy AWS EKS cluster, node-group• Install Kubeflow Pods required• Connect the Kubeflow Dashboard• Connect the Kubeflow Notebooks Server• Setup MinIO for Object Storage• Setting up MinIO secret for Kserve for inference service• Deploy models on Kserve inference services Referenceshow to configure kubeflow on AWS EC2 how to spin up Kserve on kubeflow","link":"/projects/Config_Kubeflow/"},{"title":"Configure and deploy models on Sagemaker","text":"IntroductionAWS SageMaker is an excellent ML platform for conducting MLOps, simplifying model deployment, seamlessly integrating with other AWS services, and enabling rapid iteration and experimentation. In this blog post, we’ll delve into the process of deploying a VGG19 model to AWS SageMaker, covering the steps involved in training the model, creating a SageMaker endpoint, and making real-time inferences. Get the modelthe model have been trained and saved on /home/sagemaker-user/model/vgg19/model_file, see the blog for more info Make the inference.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import jsonimport tensorflow as tffrom PIL import Imageimport numpy as npimport requestsimport ioimport base64def model_fn(model_dir): model = tf.saved_model.load(model_dir) return modeldef predict_fn(input_data, model): outputs = model(input_data) return outputsdef input_fn(request_body, request_content_type='application/json'): if request_content_type == 'application/json': # Parse the image URL or Base64 data from the request body data = json.loads(request_body) image_data = data['image'] # Assume the JSON contains an 'image' key # If it's a URL, download the image if 'http' in image_data: image = Image.open(requests.get(image_data, stream=True).raw) else: # If it's Base64 encoded, decode it image = Image.open(io.BytesIO(base64.b64decode(image_data))) # Convert to a format suitable for model input image = image.resize((224, 224)) # Assume VGG19 input size is 224x224 image = np.array(image) / 255.0 # Normalize to [0, 1] image = np.expand_dims(image, axis=0) # Add batch dimension return tf.convert_to_tensor(image, dtype=tf.float32) else: raise ValueError(&quot;Unsupported content type: {}&quot;.format(request_content_type))def output_fn(prediction, response_content_type='application/json'): if response_content_type == 'application/json': style_output = {k: v.numpy().tolist() for k, v in prediction['style'].items()} content_output = {k: v.numpy().tolist() for k, v in prediction['content'].items()} result = { 'style': style_output, 'content': content_output } return json.dumps(result) else: raise ValueError(&quot;Unsupported content type: {}&quot;.format(response_content_type)) 1tar -czvf model_package.tar.gz /home/sagemaker-user/model/vgg19/model_file inference.py Upload model to S312345678import boto3s3_client = boto3.client('s3')bucket_name = 'bucket-name's3_file_path = 'path/to/model_package.tar.gz'local_file_path = 'model_package.tar.gz' s3_client.upload_file(local_file_path, bucket_name, s3_file_path) Upload a custom Docker image to AWS ECRauthenticating to the AWS ECR repo12345678REGION=&lt;my_aws_region&gt;ACCOUNT=&lt;my_aws_account&gt; # Authenticate Docker to an AWS ECR registryaws ecr get-login-password --region $REGION | docker login --username AWS --password-stdin &lt;docker_registry_url&gt;.dkr.ecr.$REGION.amazonaws.com# Loging to your private AWS ECR registryaws ecr get-login-password --region $REGION | docker login --username AWS --password-stdin $ACCOUNT.dkr.ecr.$REGION.amazonaws.com Generate requirements.txt for model dependency1234567891011packages = &quot;&quot;&quot;IPythonnumpyPillowtensorflowmatplotlibrequests&quot;&quot;&quot;with open('/home/sagemaker-user/model/vgg19/requirements.txt', 'w') as f: f.write(packages.strip()) Make dockerfile1234567# Use the SageMaker Tensorflow image as the base image# 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.0.0-gpu-py310 # region: us-east-1 for referenceFROM &lt;docker_registry_url&gt;.dkr.ecr.&lt;my_aws_region&gt;.amazonaws.com/tensorflow-inference:2.0.0-gpu-py310# Install the additional dependencyRUN pip install /home/sagemaker-user/model/vgg19/requirements.txt Build and push image file12345678910docker build -t vgg19-image .# Create the AWS ECR repositoryaws ecr create-repository --repository-name vgg19-image# Tag the imagedocker tag vgg19-image:latest $ACCOUNT.dkr.ecr.$REGION.amazonaws.com/vgg19-image:latest# Push the tagged image to the AWS ECR repositorydocker push $ACCOUNT.dkr.ecr.$REGION.amazonaws.com/vgg19-image:latest Create a model in sagemaker1234567891011121314151617import boto3import sagemakersagemaker_client = boto3.client(service_name=&quot;sagemaker&quot;)role = sagemaker.get_execution_role()model_name = &quot;&lt;model-name&gt;&quot;primary_container = { &quot;Image&quot;: &quot;inference-image&quot; &quot;ModelDataUrl&quot;: &quot;s3://&lt;model-path&gt;.tar.gz&quot;}create_model_response = sagemaker_client.create_model( ModelName=model_name, ExecutionRoleArn=role, PrimaryContainer=primary_container) Create an Endpoint12345678910endpoint_config_name = &quot;endpoint-config-name&quot;sagemaker_client.create_endpoint_config( EndpointConfigName=endpoint_config_name, ProductionVariants=[{ &quot;InstanceType&quot;: &quot;ml.g5.xlarge&quot;, &quot;InitialVariantWeight&quot;: 1, &quot;InitialInstanceCount&quot;: 1, &quot;ModelName&quot;: model_name, &quot;VariantName&quot;: &quot;AllTraffic&quot;}]) Check the endpoint status if it is in-servicewe can start to invoke the endpoint to test it once the endpoint status is in-service 123456789import timewhile True: response = sagemaker_client.describe_endpoint(EndpointName='endpoint-name') status = response['EndpointStatus'] print(f'Endpoint status: {status}') if status in ['InService', 'Failed']: break time.sleep(30) Invoke the endpoint12345678910111213141516import boto3from PIL import Imageimport iowith open(file_name, &quot;rb&quot;) as f: payload = f.read()sagemaker_runtime = boto3.client(&quot;runtime.sagemaker&quot;)response = sagemaker_runtime.invoke_endpoint( EndpointName=endpoint_name, ContentType=&quot;image/x-image&quot;, Body=payload)image_data = response[&quot;Body&quot;].read()image = Image.open(io.BytesIO(image_data))image.show() Review and potential improvements:on making inference.py part, the ways of defining model_fn and predict_fn are a little bit simple and lack of flexibility. Here is an good template of model_fn about setting up pretrain_model, loading configs, model_weights，joblib storage banks and transforms on enhancing performance, efficiency, and usability in machine learning workflows. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def model_fn(model_dir): &quot;&quot;&quot; This function is the first to get executed upon a prediction request, it loads the model from the disk and returns the model object which will be used later for inference. &quot;&quot;&quot; # Load the config file config = OmegaConf.load(os.path.join(model_dir, &quot;ai_vad_config.yaml&quot;)) config_model = config.model # Load the model model = AiVadModel( box_score_thresh=config_model.box_score_thresh, persons_only=config_model.persons_only, min_bbox_area=config_model.min_bbox_area, max_bbox_overlap=config_model.max_bbox_overlap, enable_foreground_detections=config_model.enable_foreground_detections, foreground_kernel_size=config_model.foreground_kernel_size, foreground_binary_threshold=config_model.foreground_binary_threshold, n_velocity_bins=config_model.n_velocity_bins, use_velocity_features=config_model.use_velocity_features, use_pose_features=config_model.use_pose_features, use_deep_features=config_model.use_deep_features, n_components_velocity=config_model.n_components_velocity, n_neighbors_pose=config_model.n_neighbors_pose, n_neighbors_deep=config_model.n_neighbors_deep, ) # Load the model weights model.load_state_dict(torch.load(os.path.join(model_dir, &quot;ai_vad_weights.pth&quot;), map_location=device), strict=False) # Load the memory banks velocity_estimator_memory_bank, pose_estimator_memory_bank, appearance_estimator_memory_bank = joblib.load(os.path.join(model_dir, &quot;ai_vad_banks.joblib&quot;)) if velocity_estimator_memory_bank is not None: model.density_estimator.velocity_estimator.memory_bank = velocity_estimator_memory_bank if pose_estimator_memory_bank is not None: model.density_estimator.pose_estimator.memory_bank = pose_estimator_memory_bank if appearance_estimator_memory_bank is not None: model.density_estimator.appearance_estimator.memory_bank = appearance_estimator_memory_bank model.density_estimator.fit() # Move the entire model to device model = model.to(device) # get the transforms transform_config = config.dataset.transform_config.eval if &quot;transform_config&quot; in config.dataset.keys() else None image_size = (config.dataset.image_size[0], config.dataset.image_size[1]) center_crop = config.dataset.get(&quot;center_crop&quot;) center_crop = tuple(center_crop) if center_crop is not None else None normalization = InputNormalizationMethod(config.dataset.normalization) transform = get_transforms(config=transform_config, image_size=image_size, center_crop=center_crop, normalization=normalization) return model, transform ConclusionWe have finished: • Write the Sagemaker model serving script(inference.py)• Upload the Model to S3• Upload a custom Docker image to AWS ECR• Create a Model in SageMaker• Create an Endpoint Configuration• Create an Endpoint• Invoke the Endpoint ReferencesDeploy a custom ml model on AWS sagemaker","link":"/projects/Config_Sagemaker/"},{"title":"Neural machine translation","text":"IntroductionIn this blog, we will create and train a sequence-to-sequence Transformer model to translate Portuguese into English. Transformers are deep neural networks that replace CNNs and RNNs with self-attention. Self-attention allows Transformers to easily transmit information across the input sequences. As suggested in the Google AI Blog post: Neural networks for machine translation typically contain an encoder reading the input sentence and generating a representation of it. A decoder then generates the output sentence word by word while consulting the representation generated by the encoder. The Transformer starts by generating initial representations, or embeddings, for each word… Then, using self-attention, it aggregates information from all of the other words, generating a new representation per word informed by the entire context, represented by the filled balls. This step is then repeated multiple times in parallel for all words, successively generating new representations. let’s dive into it! Set upBegin by installing TensorFlow Datasets for loading the dataset and TensorFlow Text for text preprocessing: 12345678910111213141516171819# google colab# Install the most re version of TensorFlow to use the improved# masking support for `tf.keras.layers.MultiHeadAttention`.!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text!pip install protobuf~=3.20.3!pip install -q tensorflow_datasets!pip install -q -U tensorflow-text tensorflowimport loggingimport timeimport numpy as npimport matplotlib.pyplot as pltimport tensorflow_datasets as tfdsimport tensorflow as tfimport tensorflow_text!pip install datasets Data handlingDownload the datasetUse TensorFlow Datasets to load the Portuguese-English translation datasetD Talks Open Translation Project. This dataset contains approximately 52,000 training, 1,200 validation and 1,800 test examples. 12345examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True)train_examples, val_examples = examples['train'], examples['validation'] after we have loaded the dataset, we will tokenize the text, so that each element is represented as a token or token ID (a numeric representation). Set up the tokenizerownload, extract, and import the saved_model: 1234567model_name = 'ted_hrlr_translate_pt_en_converter'tf.keras.utils.get_file( f'{model_name}.zip', f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip', cache_dir='.', cache_subdir='', extract=True)tokenizers = tf.saved_model.load(f'{model_name}_extracted/{model_name}') Set up a data pipeline with tf.dataThe following function takes batches of text as input, and converts them to a format suitable for training. It tokenizes them into ragged batches. It trims each to be no longer than MAX_TOKENS. It splits the target (English) tokens into inputs and labels. These are shifted by one step so that at each input location the label is the id of the next token. It converts the RaggedTensors to padded dense Tensors. It returns an (inputs, labels) pair. 123456789101112MAX_TOKENS=128def prepare_batch(pt, en): pt = tokenizers.pt.tokenize(pt) # Output is ragged. pt = pt[:, :MAX_TOKENS] # Trim to MAX_TOKENS. pt = pt.to_tensor() # Convert to 0-padded dense Tensor en = tokenizers.en.tokenize(en) en = en[:, :(MAX_TOKENS+1)] en_inputs = en[:, :-1].to_tensor() # Drop the [END] tokens en_labels = en[:, 1:].to_tensor() # Drop the [START] tokens return (pt, en_inputs), en_labels The function below converts a dataset of text examples into data of batches for training. It tokenizes the text, and filters out the sequences that are too long. (The batch/unbatch is included because the tokenizer is much more efficient on large batches). The cache method ensures that that work is only executed once. Then shuffle and, dense_to_ragged_batch randomize the order and assemble batches of examples. Finally prefetch runs the dataset in parallel with the model to ensure that data is available when needed. 12345678910111213BUFFER_SIZE = 20000BATCH_SIZE = 64def make_batches(ds): return ( ds .shuffle(BUFFER_SIZE) .batch(BATCH_SIZE) .map(prepare_batch, tf.data.AUTOTUNE) .prefetch(buffer_size=tf.data.AUTOTUNE))# Create training and validation set batches.train_batches = make_batches(train_examples)val_batches = make_batches(val_examples) Define the componentswe will start to implement the components of a Transformer as a standard sequence-to-sequence model with an encoder and a decoder. Figure 1. The original transformer diagram. The embedding and positional encoding layerThe inputs to both the encoder and decoder use the same embedding and positional encoding logic. A Transformer adds a “Positional Encoding” to the embedding vectors. It uses a set of sines and cosines at different frequencies (across the sequence). By definition nearby elements will have similar position encodings. Using the following formula for calculating the positional encoding: $\\Large{PE_{(pos, 2i)} = \\sin(pos / 10000^{2i / d_{model}})}$$\\Large{PE_{(pos, 2i+1)} = \\cos(pos / 10000^{2i / d_{model}})}$ The function using the vectors of sines and cosines concatenated simply to implement it 1234567891011121314def positional_encoding(length, depth): depth = depth/2 positions = np.arange(length)[:, np.newaxis] # (seq, 1) depths = np.arange(depth)[np.newaxis, :]/depth # (1, depth) angle_rates = 1 / (10000**depths) # (1, depth) angle_rads = positions * angle_rates # (pos, depth) pos_encoding = np.concatenate( [np.sin(angle_rads), np.cos(angle_rads)], axis=-1) return tf.cast(pos_encoding, dtype=tf.float32) The position encoding function is a stack of sines and cosines that vibrate at different frequencies depending on their location along the depth of the embedding vector. They vibrate across the position axis. Creating a PositionEmbedding layer that looks-up a token’s embedding vector and adds the position vector: 123456789101112131415161718class PositionalEmbedding(tf.keras.layers.Layer): def __init__(self, vocab_size, d_model): super().__init__() self.d_model = d_model self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) self.pos_encoding = positional_encoding(length=2048, depth=d_model) def compute_mask(self, *args, **kwargs): return self.embedding.compute_mask(*args, **kwargs) def call(self, x): length = tf.shape(x)[1] x = self.embedding(x) # This factor sets the relative scale of the embedding and positonal_encoding. x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) x = x + self.pos_encoding[tf.newaxis, :length, :] return x Add and normalise These “Add &amp; Norm” blocks are scattered throughout the model. Each one joins a residual connection and runs the result through a LayerNormalization layer. The base attention layerAttention layers are used throughout the model. These are all identical except for how the attention is configured. Each one contains a layers.MultiHeadAttention, a layers.LayerNormalization and a layers.Add . And we will get started from a simple base class that just contains the component layers 123456class BaseAttention(tf.keras.layers.Layer): def __init__(self, **kwargs): super().__init__() self.mha = tf.keras.layers.MultiHeadAttention(**kwargs) self.layernorm = tf.keras.layers.LayerNormalization() self.add = tf.keras.layers.Add() The cross attention layerAt the literal center of the Transformer is the cross-attention layer. This layer connects the encoder and decoder. This layer is the most straight-forward use of attention in the model, it performs the same task as the attention block To implement this, we pass the target sequence x as the query and the context sequence as the key/value when calling the mha layer: 123456789101112131415class CrossAttention(BaseAttention): def call(self, x, context): attn_output, attn_scores = self.mha( query=x, key=context, value=context, return_attention_scores=True) # Cache the attention scores for plotting later. self.last_attn_scores = attn_scores x = self.add([x, attn_output]) x = self.layernorm(x) return x 12345678910111213# test out the layersample_ca = CrossAttention(num_heads=2, key_dim=512)print(pt_emb.shape)print(en_emb.shape)print(sample_ca(en_emb, pt_emb).shape)# result &quot;&quot;&quot;(64, 75, 512)(64, 53, 512)(64, 53, 512)&quot;&quot;&quot; The global self-attention layerThis layer is responsible for processing the context sequence, and propagating information along its length: To implement this layer we just need to pass the target sequence, x, as both the query, and value arguments to the mha layer: 123456789class GlobalSelfAttention(BaseAttention): def call(self, x): attn_output = self.mha( query=x, value=x, key=x) x = self.add([x, attn_output]) x = self.layernorm(x) return x 1234567891011# test out the layersample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)print(pt_emb.shape)print(sample_gsa(pt_emb).shape)# result &quot;&quot;&quot;(64, 75, 512)(64, 75, 512)&quot;&quot;&quot; The causal self-attention layerThis layer does a similar job as the global self-attention layer, for the output sequence: To build a causal self-attention layer, we need to use an appropriate mask when computing the attention scores and summing the attention values. And we can solve this pass use_causal_mask = True to the MultiHeadAttention layer 12345678910class CausalSelfAttention(BaseAttention): def call(self, x): attn_output = self.mha( query=x, value=x, key=x, use_causal_mask = True) x = self.add([x, attn_output]) x = self.layernorm(x) return x 1234567891011# test out the layersample_csa = CausalSelfAttention(num_heads=2, key_dim=512)print(en_emb.shape)print(sample_csa(en_emb).shape)# result &quot;&quot;&quot;(64, 53, 512)(64, 53, 512)&quot;&quot;&quot; The feed forward networkThe transformer also includes this point-wise feed-forward network in both the encoder and decoder: The network consists of two linear layers (tf.keras.layers.Dense) with a ReLU activation in-between, and a dropout layer. As with the attention layers the code here also includes the residual connection and normalization: 12345678910111213141516class FeedForward(tf.keras.layers.Layer): def __init__(self, d_model, dff, dropout_rate=0.1): super().__init__() self.seq = tf.keras.Sequential([ tf.keras.layers.Dense(dff, activation='relu'), tf.keras.layers.Dense(d_model), tf.keras.layers.Dropout(dropout_rate) ]) self.add = tf.keras.layers.Add() self.layer_norm = tf.keras.layers.LayerNormalization() def call(self, x): x = self.add([x, self.seq(x)]) x = self.layer_norm(x) return x 1234567891011# test out the layersample_ffn = FeedForward(512, 2048)print(en_emb.shape)print(sample_ffn(en_emb).shape)# result &quot;&quot;&quot;(64, 53, 512)(64, 53, 512)&quot;&quot;&quot; The encoder layerThe encoder contains a stack of N encoder layers. Where each EncoderLayer contains a GlobalSelfAttention and FeedForward layer: Here is the definition of the EncoderLayer: 123456789101112131415class EncoderLayer(tf.keras.layers.Layer): def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1): super().__init__() self.self_attention = GlobalSelfAttention( num_heads=num_heads, key_dim=d_model, dropout=dropout_rate) self.ffn = FeedForward(d_model, dff) def call(self, x): x = self.self_attention(x) x = self.ffn(x) return x And a quick test again, the output will have the same shape as the input 1234567891011# test out the layersample_encoder_layer = EncoderLayer(d_model=512, num_heads=8, dff=2048)print(pt_emb.shape)print(sample_encoder_layer(pt_emb).shape)# result &quot;&quot;&quot;(64, 75, 512)(64, 75, 512)&quot;&quot;&quot; The encoder The encoder consists of: A PositionalEmbedding layer at the input. A stack of EncoderLayer layers. 123456789101112131415161718192021222324252627282930class Encoder(tf.keras.layers.Layer): def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1): super().__init__() self.d_model = d_model self.num_layers = num_layers self.pos_embedding = PositionalEmbedding( vocab_size=vocab_size, d_model=d_model) self.enc_layers = [ EncoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate) for _ in range(num_layers)] self.dropout = tf.keras.layers.Dropout(dropout_rate) def call(self, x): # `x` is token-IDs shape: (batch, seq_len) x = self.pos_embedding(x) # Shape `(batch_size, seq_len, d_model)`. # Add dropout. x = self.dropout(x) for i in range(self.num_layers): x = self.enc_layers[i](x) return x # Shape `(batch_size, seq_len, d_model)`. And test the encoder: 12345678910111213141516# test out the layer# Instantiate the encoder.sample_encoder = Encoder(num_layers=4, d_model=512, num_heads=8, dff=2048, vocab_size=8500)sample_encoder_output = sample_encoder(pt, training=False)print(pt.shape)print(sample_encoder_output.shape) # Shape `(batch_size, input_seq_len, d_model)`.# result &quot;&quot;&quot;(64, 75)(64, 75, 512)&quot;&quot;&quot; The decoder layerThe decoder’s stack is slightly more complex, with each DecoderLayer containing a CausalSelfAttention, a CrossAttention, and a FeedForward layer: Implement it: 123456789101112131415161718192021222324252627282930class DecoderLayer(tf.keras.layers.Layer): def __init__(self, *, d_model, num_heads, dff, dropout_rate=0.1): super(DecoderLayer, self).__init__() self.causal_self_attention = CausalSelfAttention( num_heads=num_heads, key_dim=d_model, dropout=dropout_rate) self.cross_attention = CrossAttention( num_heads=num_heads, key_dim=d_model, dropout=dropout_rate) self.ffn = FeedForward(d_model, dff) def call(self, x, context): x = self.causal_self_attention(x=x) x = self.cross_attention(x=x, context=context) # Cache the last attention scores for plotting later self.last_attn_scores = self.cross_attention.last_attn_scores x = self.ffn(x) # Shape `(batch_size, seq_len, d_model)`. return x Test the layer: 123456789101112131415sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)sample_decoder_layer_output = sample_decoder_layer( x=en_emb, context=pt_emb)print(en_emb.shape)print(pt_emb.shape)print(sample_decoder_layer_output.shape) # `(batch_size, seq_len, d_model)`# result&quot;&quot;&quot;(64, 53, 512)(64, 75, 512)(64, 53, 512)&quot;&quot;&quot; The decoderSimilar to the Encoder, the Decoder consists of a PositionalEmbedding, and a stack of DecoderLayer Define the decoder by extending tf.keras.layers.Layer: 12345678910111213141516171819202122232425262728293031class Decoder(tf.keras.layers.Layer): def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1): super(Decoder, self).__init__() self.d_model = d_model self.num_layers = num_layers self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model) self.dropout = tf.keras.layers.Dropout(dropout_rate) self.dec_layers = [ DecoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, dropout_rate=dropout_rate) for _ in range(num_layers)] self.last_attn_scores = None def call(self, x, context): # `x` is token-IDs shape (batch, target_seq_len) x = self.pos_embedding(x) # (batch_size, target_seq_len, d_model) x = self.dropout(x) for i in range(self.num_layers): x = self.dec_layers[i](x, context) self.last_attn_scores = self.dec_layers[-1].last_attn_scores # The shape of x is (batch_size, target_seq_len, d_model). return x Test the decoder: 12345678910111213141516171819202122# Instantiate the decoder.sample_decoder = Decoder(num_layers=4, d_model=512, num_heads=8, dff=2048, vocab_size=8000)output = sample_decoder( x=en, context=pt_emb)# Print the shapes.print(en.shape)print(pt_emb.shape)print(output.shape)# result&quot;&quot;&quot;(64, 53)(64, 75, 512)(64, 53, 512)&quot;&quot;&quot; The TransformerNow we need to put Encoder and Decoder together and add a final linear (Dense) layer which converts the resulting vector at each location into output token probabilities to finish the transformer model to be created. Create the Transformer by extending tf.keras.Model: 12345678910111213141516171819202122232425262728293031323334353637class Transformer(tf.keras.Model): def __init__(self, *, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, dropout_rate=0.1): super().__init__() self.encoder = Encoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, vocab_size=input_vocab_size, dropout_rate=dropout_rate) self.decoder = Decoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, vocab_size=target_vocab_size, dropout_rate=dropout_rate) self.final_layer = tf.keras.layers.Dense(target_vocab_size) def call(self, inputs): # To use a Keras model with `.fit` you must pass all your inputs in the # first argument. context, x = inputs context = self.encoder(context) # (batch_size, context_len, d_model) x = self.decoder(x, context) # (batch_size, target_len, d_model) # Final linear layer output. logits = self.final_layer(x) # (batch_size, target_len, target_vocab_size) try: # Drop the keras mask, so it doesn't scale the losses/metrics. # b/250038731 del logits._keras_mask except AttributeError: pass # Return the final output and the attention weights. return logits define the hyperparameters, instantiate the model and test it out: 12345num_layers = 4d_model = 128dff = 512num_heads = 8dropout_rate = 0.1 1234567891011121314151617181920212223# instantiate the modeltransformer = Transformer( num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, input_vocab_size=tokenizers.pt.get_vocab_size().numpy(), target_vocab_size=tokenizers.en.get_vocab_size().numpy(), dropout_rate=dropout_rate) # testoutput = transformer((pt, en))print(en.shape)print(pt.shape)print(output.shape)# result&quot;&quot;&quot;(64, 53)(64, 75)(64, 53, 7010)&quot;&quot;&quot; TrainingSet up the optimiserUse the Adam optimiser with a custom learning rate scheduler according to the formula in the original Transformer paper. $\\Large{lrate = d_{model}^{-0.5} * \\min(step{_}num^{-0.5}, step{_}num \\cdot warmup{_}steps^{-1.5})}$ 123456789101112131415class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule): def __init__(self, d_model, warmup_steps=4000): super().__init__() self.d_model = d_model self.d_model = tf.cast(self.d_model, tf.float32) self.warmup_steps = warmup_steps def __call__(self, step): step = tf.cast(step, dtype=tf.float32) arg1 = tf.math.rsqrt(step) arg2 = step * (self.warmup_steps ** -1.5) return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2) Set up the loss and metricsWe will use the cross-entropy loss function (tf.keras.losses.SparseCategoricalCrossentropy) 123456789101112131415161718192021222324def masked_loss(label, pred): mask = label != 0 loss_object = tf.keras.losses.SparseCategoricalCrossentropy( from_logits=True, reduction='none') loss = loss_object(label, pred) mask = tf.cast(mask, dtype=loss.dtype) loss *= mask loss = tf.reduce_sum(loss)/tf.reduce_sum(mask) return lossdef masked_accuracy(label, pred): pred = tf.argmax(pred, axis=2) label = tf.cast(label, pred.dtype) match = label == pred mask = label != 0 match = match &amp; mask match = tf.cast(match, dtype=tf.float32) mask = tf.cast(mask, dtype=tf.float32) return tf.reduce_sum(match)/tf.reduce_sum(mask) Training the model123456789# compile and fittransformer.compile( loss=masked_loss, optimizer=optimizer, metrics=[masked_accuracy]) transformer.fit(train_batches, epochs=20, validation_data=val_batches) Run inferenceDefine the Translator class by subclassing tf.Module: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Translator(tf.Module): def __init__(self, tokenizers, transformer): self.tokenizers = tokenizers self.transformer = transformer def __call__(self, sentence, max_length=MAX_TOKENS): # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens. assert isinstance(sentence, tf.Tensor) if len(sentence.shape) == 0: sentence = sentence[tf.newaxis] sentence = self.tokenizers.pt.tokenize(sentence).to_tensor() encoder_input = sentence # As the output language is English, initialize the output with the # English `[START]` token. start_end = self.tokenizers.en.tokenize([''])[0] start = start_end[0][tf.newaxis] end = start_end[1][tf.newaxis] # `tf.TensorArray` is required here (instead of a Python list), so that the # dynamic-loop can be traced by `tf.function`. output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True) output_array = output_array.write(0, start) for i in tf.range(max_length): output = tf.transpose(output_array.stack()) predictions = self.transformer([encoder_input, output], training=False) # Select the last token from the `seq_len` dimension. predictions = predictions[:, -1:, :] # Shape `(batch_size, 1, vocab_size)`. predicted_id = tf.argmax(predictions, axis=-1) # Concatenate the `predicted_id` to the output which is given to the # decoder as its input. output_array = output_array.write(i+1, predicted_id[0]) if predicted_id == end: break output = tf.transpose(output_array.stack()) # The output shape is `(1, tokens)`. text = tokenizers.en.detokenize(output)[0] # Shape: `()`. tokens = tokenizers.en.lookup(output)[0] # `tf.function` prevents us from using the attention_weights that were # calculated on the last iteration of the loop. # So, recalculate them outside the loop. self.transformer([encoder_input, output[:,:-1]], training=False) attention_weights = self.transformer.decoder.last_attn_scores return text, tokens, attention_weights Create an instance of this Translator class, and try it out a few times: 123456translator = Translator(tokenizers, transformer)def print_translation(sentence, tokens, ground_truth): print(f'{&quot;Input:&quot;:15s}: {sentence}') print(f'{&quot;Prediction&quot;:15s}: {tokens.numpy().decode(&quot;utf-8&quot;)}') print(f'{&quot;Ground truth&quot;:15s}: {ground_truth}') 1234567891011121314# example onesentence = 'este é um problema que temos que resolver.'ground_truth = 'this is a problem we have to solve .'translated_text, translated_tokens, attention_weights = translator( tf.constant(sentence))print_translation(sentence, translated_text, ground_truth)#result&quot;&quot;&quot;Input: : este é um problema que temos que resolver.Prediction : this is a problem we have to solve .Ground truth : this is a problem we have to solve .&quot;&quot;&quot; 1234567891011121314# example twosentence = 'os meus vizinhos ouviram sobre esta ideia.'ground_truth = 'and my neighboring homes heard about this idea .'translated_text, translated_tokens, attention_weights = translator( tf.constant(sentence))print_translation(sentence, translated_text, ground_truth)#result&quot;&quot;&quot;Input: : os meus vizinhos ouviram sobre esta ideia .Prediction : and my neighboring homes heard about this idea .Ground truth : and my neighboring homes heard about this idea .&quot;&quot;&quot; 1234567891011121314# example threesentence = 'vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.'ground_truth = &quot;so i'll just share with you some stories very quickly of some magical things that have happened.&quot;translated_text, translated_tokens, attention_weights = translator( tf.constant(sentence))print_translation(sentence, translated_text, ground_truth)#result&quot;&quot;&quot;Input: : vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram .Prediction : so i'll just share with you some stories very quickly of some magical things that have happened .Ground truth : so i'll just share with you some stories very quickly of some magical things that have happened .&quot;&quot;&quot; Export the modelCreate a class called ExportTranslator by subclassing the tf.Module subclass with a tf.function on the __call__ method: 1234567891011class ExportTranslator(tf.Module): def __init__(self, translator): self.translator = translator @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)]) def __call__(self, sentence): (result, tokens, attention_weights) = self.translator(sentence, max_length=MAX_TOKENS) return result 12345translator = ExportTranslator(translator)tf.saved_model.save(translator, export_dir='translator')reloaded = tf.saved_model.load('translator')print(reloaded(tf.constant('este é o primeiro livro que eu fiz.')).numpy().decode(&quot;utf-8&quot;))# result: this is the first book I made. GitHubhttps://github.com/PaddyZz/neural_machine_translation ConclusionWe have finised: • Enviroment and Dependencies set up• Data Handling (Datasets, Tokenizer, Data Pipeline)• Define the components (encoder,decoder, attention layers and etc)• Train the Model• Run the inference• Export the model Referencespaper ted_hrlr_translate Neural machine learning with attention Neural machine translation with a Transformer and Keras","link":"/projects/neural_machine_translation/"},{"title":"Neural style transfer","text":"IntroductionNeural style transfer is an optimisation technique used to take two images—a content image and a style reference image (such as an artwork by a famous painter)—and blend them together so the output image looks like the content image, but “painted” in the style of the style reference image. This is implemented by using tensorflow pretrained model VGG19, accessing and changing the intermediate layers of the model, extracting style and content, running gradient descent to minimise the loss function: total variation loss with explicit regularisation to reduce high-frequency artifacts and preserve edge details, and optimising the output image to match the statistics of the content and the style reference image. These statistics are extracted from the images using a convolutional network. Configuration1234567jupyter notebookPython 3.10.12matplotlib==3.7.1Pillow==10.4.0numpy==1.26.4requests==2.32.3tensorflow==2.17.0 Setup1234567891011121314import osimport tensorflow as tfimport IPython.display as displayimport matplotlib.pyplot as pltimport matplotlib as mplmpl.rcParams['figure.figsize'] = (12, 12)mpl.rcParams['axes.grid'] = Falseimport numpy as npimport PIL.Imageimport timeimport functools 123456789#tensor_to_imagedef tensor_to_image(tensor): #convert pixel values from the range [0,1] to [0,255] tensor = tensor*255 tensor = np.array(tensor, dtype=np.uint8) if np.ndim(tensor)&gt;3: assert tensor.shape[0] == 1 tensor = tensor[0] return PIL.Image.fromarray(tensor) Download content and style image12content_path = tf.keras.utils.get_file('lighthouse.jpg', 'https://unsplash.com/photos/l5b_Jd8Ttfg/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNzI5NTI3OTk1fA&amp;force=true&amp;w=2400')style_path = tf.keras.utils.get_file('starrynight.png','https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg') Visualise the inputDefine a function to load an image and limit its maximum dimension to 512 pixels. 123456789101112131415def load_img(path_to_img): max_dim = 512 img = tf.io.read_file(path_to_img) img = tf.image.decode_image(img, channels=3) img = tf.image.convert_image_dtype(img, tf.float32) shape = tf.cast(tf.shape(img)[:-1], tf.float32) long_dim = max(shape) scale = max_dim / long_dim new_shape = tf.cast(shape * scale, tf.int32) img = tf.image.resize(img, new_shape) img = img[tf.newaxis, :] return img Create a simple function to display an image: 1234567def imshow(image, title=None): if len(image.shape) &gt; 3: image = tf.squeeze(image, axis=0) plt.imshow(image) if title: plt.title(title) 12345678content_image = load_img(content_path)style_image = load_img(style_path)plt.subplot(1, 2, 1)imshow(content_image, 'Content Image')plt.subplot(1, 2, 2)imshow(style_image, 'Style Image') Define content and style representationsWe will be using the VGG19 network architecture, a pretrained image classification network to implement it and use the intermediate layers of the model to get the content and style representations of the image. Starting from the network’s input layer, the first few layer activations represent low-level features like edges and textures. With stepping through the network, the final few layers represent higher-level features. Load a VGG19 and test run it on our image to ensure it’s used correctly: 1234567x = tf.keras.applications.vgg19.preprocess_input(content_image*255)x = tf.image.resize(x, (224, 224))vgg = tf.keras.applications.VGG19(include_top=True, weights='imagenet')prediction_probabilities = vgg(x)prediction_probabilities.shape#TensorShape([1, 1000]) 1234567891011predicted_top_5 = tf.keras.applications.vgg19.decode_predictions(prediction_probabilities.numpy())[0][(class_name, prob) for (number, class_name, prob) in predicted_top_5]#class_name, prob\"\"\"[('beacon', 0.5217742), ('promontory', 0.3035163), ('cliff', 0.09787675), ('breakwater', 0.04300915), ('seashore', 0.014805787)]\"\"\" load a VGG19 without the classification head, and list the layer names 123456789101112131415161718192021222324252627282930vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')print()for layer in vgg.layers: print(layer.name)#layer.name\"\"\"input_layer_1block1_conv1block1_conv2block1_poolblock2_conv1block2_conv2block2_poolblock3_conv1block3_conv2block3_conv3block3_conv4block3_poolblock4_conv1block4_conv2block4_conv3block4_conv4block4_poolblock5_conv1block5_conv2block5_conv3block5_conv4block5_pool\"\"\" Choose intermediate layers from the network to represent the style and content of the image: 12345678910content_layers = ['block5_conv2'] style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']num_content_layers = len(content_layers)num_style_layers = len(style_layers) Intermediate layers for style and contentSo why do these intermediate outputs within our pretrained image classification network allow us to define style and content representations? Here is a paragraph for the explains reference from Tensorflow Docs: At a high level, in order for a network to perform image classification (which this network has been trained to do), it must understand the image. This requires taking the raw image as input pixels and building an internal representation that converts the raw image pixels into a complex understanding of the features present within the image. This is also a reason why convolutional neural networks are able to generalize well: they’re able to capture the invariances and defining features within classes (e.g. cats vs. dogs) that are agnostic to background artifacts and other nuisances. Thus, somewhere between where the raw image is fed into the model and the output classification label, the model serves as a complex feature extractor. By accessing intermediate layers of the model, we’re able to describe the content and style of input images. Build the modelbuilds a VGG19 model that returns a list of intermediate layer outputs through specifying the inputs and outputs 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556def vgg_layers(layer_names): \"\"\" Creates a VGG model that returns a list of intermediate output values.\"\"\" # Load our model. Load pretrained VGG, trained on ImageNet data vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet') vgg.trainable = False outputs = [vgg.get_layer(name).output for name in layer_names] model = tf.keras.Model([vgg.input], outputs) return model #create the modelstyle_extractor = vgg_layers(style_layers)style_outputs = style_extractor(style_image*255)#Look at the statistics of each layer's outputfor name, output in zip(style_layers, style_outputs): print(name) print(\" shape: \", output.numpy().shape) print(\" min: \", output.numpy().min()) print(\" max: \", output.numpy().max()) print(\" mean: \", output.numpy().mean()) print()#each layer's outputs\"\"\"block1_conv1 shape: (1, 405, 512, 64) min: 0.0 max: 660.528 mean: 23.849983block2_conv1 shape: (1, 202, 256, 128) min: 0.0 max: 2981.8281 mean: 147.914block3_conv1 shape: (1, 101, 128, 256) min: 0.0 max: 7421.774 mean: 144.3642block4_conv1 shape: (1, 50, 64, 512) min: 0.0 max: 16733.793 mean: 560.6592block5_conv1 shape: (1, 25, 32, 512) min: 0.0 max: 3804.7947 mean: 48.127247\"\"\" Calculate styleThe content of an image is represented by the values of the intermediate feature maps. It turns out, the style of an image can be described by the means and correlations across the different feature maps. Calculate a Gram matrix that includes this information by taking the outer product of the feature vector with itself at each location, and averaging that outer product over all locations. This Gram matrix can be calculated for a particular layer as: represents the Gram matrix element for feature map and feature map at layer . It quantifies the correlation between feature maps and and are the activation values of feature map and feature map at position. By calculating their outer product, We can capture the joint information of these two feature maps at that position. By summing the outer products over all positions and the dividing by (the spatial dimensions of the feature maps), and then we can obtain the average correlation between the feature maps. And it could be implemented by using the tf.linalg.einsum function 12345def gram_matrix(input_tensor): result = tf.linalg.einsum('bijc,bijd-&gt;bcd', input_tensor, input_tensor) input_shape = tf.shape(input_tensor) num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32) return result/(num_locations) Extract style and contentBuild a model that returns the style and content tensors. 1234567891011121314151617181920212223242526272829class StyleContentModel(tf.keras.models.Model): def __init__(self, style_layers, content_layers): super(StyleContentModel, self).__init__() self.vgg = vgg_layers(style_layers + content_layers) self.style_layers = style_layers self.content_layers = content_layers self.num_style_layers = len(style_layers) self.vgg.trainable = False def call(self, inputs): \"Expects float input in [0,1]\" inputs = inputs*255.0 preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs) outputs = self.vgg(preprocessed_input) style_outputs, content_outputs = (outputs[:self.num_style_layers], outputs[self.num_style_layers:]) style_outputs = [gram_matrix(style_output) for style_output in style_outputs] content_dict = {content_name: value for content_name, value in zip(self.content_layers, content_outputs)} style_dict = {style_name: value for style_name, value in zip(self.style_layers, style_outputs)} return {'content': content_dict, 'style': style_dict} When called on an image, this model returns the gram matrix (style) of the style_layers and content of the content_layers: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061extractor = StyleContentModel(style_layers, content_layers)results = extractor(tf.constant(content_image))print('Styles:')for name, output in sorted(results['style'].items()): print(\" \", name) print(\" shape: \", output.numpy().shape) print(\" min: \", output.numpy().min()) print(\" max: \", output.numpy().max()) print(\" mean: \", output.numpy().mean()) print()print(\"Contents:\")for name, output in sorted(results['content'].items()): print(\" \", name) print(\" shape: \", output.numpy().shape) print(\" min: \", output.numpy().min()) print(\" max: \", output.numpy().max()) print(\" mean: \", output.numpy().mean()) #outputs\"\"\"Styles: block1_conv1 shape: (1, 64, 64) min: 0.15344943 max: 63351.805 mean: 709.7667 block2_conv1 shape: (1, 128, 128) min: 0.0 max: 143030.39 mean: 17212.434 block3_conv1 shape: (1, 256, 256) min: 0.0 max: 535053.25 mean: 13304.491 block4_conv1 shape: (1, 512, 512) min: 0.0 max: 4746262.0 mean: 204897.52 block5_conv1 shape: (1, 512, 512) min: 0.0 max: 155404.47 mean: 1599.2406Contents: block5_conv2 shape: (1, 18, 32, 512) min: 0.0 max: 2180.7375 mean: 13.492043\"\"\" Run gradient descentGradient descent is an optimisation algorithm used to minimise a loss function. During the training of deep learning models, gradient descent proceeds through the following steps: Calculate Loss: First, compute the loss based on the difference between the model’s output and the true labels. Compute Gradients: Then, use the backpropagation algorithm to calculate the gradients of the loss function with respect to the model parameters. Update Parameters: Finally, use these gradients to update the model parameters, thus reducing the loss. In tasks using VGG19 (like feature extraction), we may leverage a pre-trained model and fine-tune it to optimize performance for a specific task. Set the style and content target values: 1234567891011121314151617181920212223242526272829303132333435363738style_targets = extractor(style_image)['style']content_targets = extractor(content_image)['content']#Define a tf.Variable to contain the image to optimize. image = tf.Variable(content_image)#Since this is a float image, define a function to keep the pixel values between 0 and 1:def clip_0_1(image): return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0) # create an optimizer, both LBFGS and Adam are acceptableopt = tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)# To optimize this, we will use a weighted combination of the two losses to get the total loss:style_weight=1e-2content_weight=1e4def style_content_loss(outputs): style_outputs = outputs['style'] content_outputs = outputs['content'] style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) for name in style_outputs.keys()]) style_loss *= style_weight / num_style_layers content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2) for name in content_outputs.keys()]) content_loss *= content_weight / num_content_layers loss = style_loss + content_loss return loss# And finally use tf.GradientTape to update the image.@tf.function()def train_step(image): with tf.GradientTape() as tape: outputs = extractor(image) loss = style_content_loss(outputs) grad = tape.gradient(loss, image) opt.apply_gradients([(grad, image)]) image.assign(clip_0_1(image)) Now run a few steps to test: 1234train_step(image)train_step(image)train_step(image)tensor_to_image(image) performing a longer optimisation 123456789101112131415161718import timestart = time.time()epochs = 10steps_per_epoch = 100step = 0for n in range(epochs): for m in range(steps_per_epoch): step += 1 train_step(image) print(\".\", end='', flush=True) display.clear_output(wait=True) display.display(tensor_to_image(image)) print(\"Train step: {}\".format(step)) end = time.time()print(\"Total time: {:.1f}\".format(end-start)) Train step: 1000Total time: 5952.3 Total variation lossVariation loss is often used in image generation tasks, particularly in style transfer. Its primary aim is to maintain the smoothness and structure of the image while preventing excessive smoothing that could result in loss of detail. Variation loss is typically calculated based on the differences between pixel values, encouraging small changes between adjacent pixels. The formula can be expressed as: Here, is the generated image, and and are the pixel coordinates of the image. This loss penalises large variations to maintain the natural smoothness of the image. One downside to this basic implementation is that it produces a lot of high frequency artifacts. Decrease these using an explicit regularisation term on the high frequency components of the image. 12345def high_pass_x_y(image): x_var = image[:, :, 1:, :] - image[:, :, :-1, :] y_var = image[:, 1:, :, :] - image[:, :-1, :, :] return x_var, y_var 12345678910111213141516x_deltas, y_deltas = high_pass_x_y(content_image)plt.figure(figsize=(14, 10))plt.subplot(2, 2, 1)imshow(clip_0_1(2*y_deltas+0.5), \"Horizontal Deltas: Original\")plt.subplot(2, 2, 2)imshow(clip_0_1(2*x_deltas+0.5), \"Vertical Deltas: Original\")x_deltas, y_deltas = high_pass_x_y(image)plt.subplot(2, 2, 3)imshow(clip_0_1(2*y_deltas+0.5), \"Horizontal Deltas: Styled\")plt.subplot(2, 2, 4)imshow(clip_0_1(2*x_deltas+0.5), \"Vertical Deltas: Styled\") This shows how the high frequency components have increased. Re-run the optimisationBy minimizing the loss function incorporating total variation regularisation using gradient descent, we can effectively reduce high-frequency artifacts in images while preserving edge details. 12345678910111213141516171819202122232425262728293031323334353637# Choose a weight for the total_variation_losstotal_variation_weight=30@tf.function()def train_step(image): with tf.GradientTape() as tape: outputs = extractor(image) loss = style_content_loss(outputs) loss += total_variation_weight*tf.image.total_variation(image) grad = tape.gradient(loss, image) opt.apply_gradients([(grad, image)]) image.assign(clip_0_1(image)) # Reinitialize the image-variable and the optimizer:opt = tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)image = tf.Variable(content_image)# Run the optimisationimport timestart = time.time()epochs = 10steps_per_epoch = 100step = 0for n in range(epochs): for m in range(steps_per_epoch): step += 1 train_step(image) print(\".\", end='', flush=True) display.clear_output(wait=True) display.display(tensor_to_image(image)) print(\"Train step: {}\".format(step))end = time.time()print(\"Total time: {:.1f}\".format(end-start)) Train step: 1000Total time: 6952.3 Save the model1tf.saved_model.save(extractor, '/home/sagemaker-user/model/vgg19/model_file') GitHub Checking out the GitHub repo below for complete implementing VGG19 model with the configs above on the neural style transfer tasks and the blog: Deploy the model on AWS Sagemaker https://github.com/PaddyZz/Neural-style-transfer ConclusionWe have finished: • Enviroment and dependencies set up• Visualise the input images• Define content and style image representations• Configure the VGG19 intermediate layers• Build the VGG19 model• Calculate and extract style and content• Run gradient descent• Total variation loss• Re-run the optimisation• Save the model on AWS sagemaker jupyter notebook server directory Referencesneural style transfer","link":"/projects/neural_style_transfer/"},{"title":"Time Series Forecasting","text":"IntroductionWeather forecasting has always been a critical aspect of our daily lives, influencing various sectors such as agriculture, transportation, and disaster management. Accurate predictions of weather parameters, particularly temperature and humidity, play a vital role in planning and decision-making processes. As climate change continues to introduce variability and uncertainty in weather patterns, the need for reliable forecasting methods becomes increasingly important. In recent years, advancements in machine learning and data analytics have opened new avenues for improving prediction models. Traditional statistical methods, while useful, often fall short in capturing complex non-linear relationships within the data. By leveraging time series analysis and modern computational techniques, we can enhance the accuracy of forecasts and provide more timely insights into atmospheric conditions. This project focuses on developing a time series forecasting model for predicting temperature, humidity levels and other factors based on historical weather data from the dataset. We aim to explore various machine learning algorithms, including regression models, neural networks like CNN and RNN etc, to identify the most effective approach for our prediction task. Configuration12345678jupyter notebookPython 3.10.2IPython==7.34.0matplotlib==3.7.1numpy==1.26.4pandas==2.1.4seaborn==0.13.1tensorflow==2.17.0 Exploratory Data AnalysisSet up123456789101112import osimport datetimeimport IPythonimport IPython.displayimport matplotlib as mplimport matplotlib.pyplot as pltimport numpy as npimport pandas as pdimport seaborn as snsimport tensorflow as tf DatasetWe will use a weather dataset containing 14 features such as air temperature, atmospheric pressure, and humidity to make predictions hourly. These were collected every 10 minutes, beginning in 2003. 12345zip_path = tf.keras.utils.get_file( origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip', fname='jena_climate_2009_2016.csv.zip', extract=True)csv_path, _ = os.path.splitext(zip_path) 12345df = pd.read_csv(csv_path)# Slice [start:stop:step], starting from index 5 take every 6th record.df = df[5::6]date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S') use df.head() to take a glance Inspect and clean up1df.describe().transpose() One thing that should stand out is the min value of the wind velocity (wv (m/s)) and the maximum value (max. wv (m/s)) columns. This -9999 is likely erroneous. There’s a separate wind direction column, so the velocity should be greater than zero (&gt;=0). Replace it with zeros: 12345678910wv = df['wv (m/s)']bad_wv = wv == -9999.0wv[bad_wv] = 0.0max_wv = df['max. wv (m/s)']bad_max_wv = max_wv == -9999.0max_wv[bad_max_wv] = 0.0# The above inplace edits are reflected in the DataFrame.df['wv (m/s)'].min() Feature engineeringThe last column of the data, wd (deg)—gives the wind direction in units of degrees. Angles do not make good model inputs: 360° and 0° should be close to each other and wrap around smoothly. Direction shouldn’t matter if the wind is not blowing. Right now the distribution of wind data looks like this: 1234plt.hist2d(df['wd (deg)'], df['wv (m/s)'], bins=(50, 50), vmax=400)plt.colorbar()plt.xlabel('Wind Direction [deg]')plt.ylabel('Wind Velocity [m/s]') But this will be easier for the model to interpret if converting the wind direction and velocity columns to a wind vector: 12345678910111213wv = df.pop('wv (m/s)')max_wv = df.pop('max. wv (m/s)')# Convert to radians.wd_rad = df.pop('wd (deg)')*np.pi / 180# Calculate the wind x and y components.df['Wx'] = wv*np.cos(wd_rad)df['Wy'] = wv*np.sin(wd_rad)# Calculate the max wind x and y components.df['max Wx'] = max_wv*np.cos(wd_rad)df['max Wy'] = max_wv*np.sin(wd_rad) The distribution of wind vectors is much simpler for the model to correctly interpret: 123456plt.hist2d(df['Wx'], df['Wy'], bins=(50, 50), vmax=400)plt.colorbar()plt.xlabel('Wind X [m/s]')plt.ylabel('Wind Y [m/s]')ax = plt.gca()ax.axis('tight') Similarly, the Date Time column is very useful, but not in this string form. Start by converting it to seconds: 1timestamp_s = date_time.map(pd.Timestamp.timestamp) the time in seconds is not a useful model input. Being weather data, it has clear daily and yearly periodicity. And getting usable signals by using sine and cosine transforms to clear “Time of day” and “Time of year” signals: 1234567891011day = 24*60*60year = (365.2425)*daydf['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))plt.plot(np.array(df['Day sin'])[:25])plt.plot(np.array(df['Day cos'])[:25])plt.xlabel('Time [h]')plt.title('Time of day signal') Spilt the dataWe will be using a (70%, 20%, 10%) split for the training, validation, and test sets. And the data is not being randomly shuffled before splitting. This is for two reasons I think: It ensures that chopping the data into windows of consecutive samples is still possible. It ensures that the validation/test results are more realistic, being evaluated on the data collected after the model was trained. 12345678column_indices = {name: i for i, name in enumerate(df.columns)}n = len(df)train_df = df[0:int(n*0.7)]val_df = df[int(n*0.7):int(n*0.9)]test_df = df[int(n*0.9):]num_features = df.shape[1] Normalise the data Normalisation is a common way of doing this scaling: subtract the mean and divide by the standard deviation of each feature. 123456train_mean = train_df.mean()train_std = train_df.std()train_df = (train_df - train_mean) / train_stdval_df = (val_df - train_mean) / train_stdtest_df = (test_df - train_mean) / train_std Now, peek at the distribution of the features. Some features do have long tails, but there are no obvious errors like the -9999 wind velocity value. ## Data windowing The main features of the input windows are: The width (number of time steps) of the input and label windows. The time offset between them. Which features are used as inputs, labels, or both. This section focuses on implementing the data windowing so that it can be reused for all of those models. Here are two examples about data windowing: 1.For example, to make a single prediction 24 hours into the future, given 24 hours of history, we might define a window like this: 2.A model that makes a prediction one hour into the future, given six hours of history, would need a window like this: WindowGenerator class. This class can: Handle the indexes and offsets as shown in the diagrams above. Split windows of features into (features, labels) pairs. Plot the content of the resulting windows. Efficiently generate batches of these windows from the training, evaluation, and test data, using tf.data.Datasets. Indexes and offsetsStart by creating the WindowGenerator class. The __init__ method includes all the necessary logic for the input and label indices. It also takes the training, evaluation, and test DataFrames as input. These will be converted to tf.data.Datasets of windows later. 12345678910111213141516171819202122232425262728293031323334353637class WindowGenerator(): def __init__(self, input_width, label_width, shift, train_df=train_df, val_df=val_df, test_df=test_df, label_columns=None): # Store the raw data. self.train_df = train_df self.val_df = val_df self.test_df = test_df # Work out the label column indices. self.label_columns = label_columns if label_columns is not None: self.label_columns_indices = {name: i for i, name in enumerate(label_columns)} self.column_indices = {name: i for i, name in enumerate(train_df.columns)} # Work out the window parameters. self.input_width = input_width self.label_width = label_width self.shift = shift self.total_window_size = input_width + shift self.input_slice = slice(0, input_width) self.input_indices = np.arange(self.total_window_size)[self.input_slice] self.label_start = self.total_window_size - self.label_width self.labels_slice = slice(self.label_start, None) self.label_indices = np.arange(self.total_window_size)[self.labels_slice] def __repr__(self): return '\\n'.join([ f'Total window size: {self.total_window_size}', f'Input indices: {self.input_indices}', f'Label indices: {self.label_indices}', f'Label column name(s): {self.label_columns}']) Here is code to create the 2 windows shown in the diagrams at the start of this section: 123w1 = WindowGenerator(input_width=24, label_width=1, shift=24, label_columns=['T (degC)'])w1 12345#w1Total window size: 48Input indices: [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]Label indices: [47]Label column name(s): ['T (degC)'] 123w2 = WindowGenerator(input_width=6, label_width=1, shift=1, label_columns=['T (degC)'])w2 12345#w2Total window size: 7Input indices: [0 1 2 3 4 5]Label indices: [6]Label column name(s): ['T (degC)'] Spilt windowGiven a list of consecutive inputs, the split_window method will convert them to a window of inputs and a window of labels. The example w2 you define earlier will be split like this: 1234567891011121314151617def split_window(self, features): inputs = features[:, self.input_slice, :] labels = features[:, self.labels_slice, :] if self.label_columns is not None: labels = tf.stack( [labels[:, :, self.column_indices[name]] for name in self.label_columns], axis=-1) # Slicing doesn't preserve static shape information, so set the shapes # manually. This way the `tf.data.Datasets` are easier to inspect. inputs.set_shape([None, self.input_width, None]) labels.set_shape([None, self.label_width, None]) return inputs, labelsWindowGenerator.split_window = split_window Test it out: 1234567891011# Stack three slices, the length of the total window.example_window = tf.stack([np.array(train_df[:w2.total_window_size]), np.array(train_df[100:100+w2.total_window_size]), np.array(train_df[200:200+w2.total_window_size])])example_inputs, example_labels = w2.split_window(example_window)print('All shapes are: (batch, time, features)')print(f'Window shape: {example_window.shape}')print(f'Inputs shape: {example_inputs.shape}')print(f'Labels shape: {example_labels.shape}') 1234All shapes are: (batch, time, features)Window shape: (3, 7, 19)Inputs shape: (3, 6, 19)Labels shape: (3, 1, 1) The code above took a batch of three 7-time step windows with 19 features at each time step. It splits them into a batch of 6-time step 19-feature inputs, and a 1-time step 1-feature label. The label only has one feature because the WindowGenerator was initialized with label_columns=['T (degC)']. PlotHere is a plot method that allows a simple visualization of the split window: 123456789101112131415161718192021222324252627282930313233def plot(self, model=None, plot_col='T (degC)', max_subplots=3): inputs, labels = self.example plt.figure(figsize=(12, 8)) plot_col_index = self.column_indices[plot_col] max_n = min(max_subplots, len(inputs)) for n in range(max_n): plt.subplot(max_n, 1, n+1) plt.ylabel(f'{plot_col} [normed]') plt.plot(self.input_indices, inputs[n, :, plot_col_index], label='Inputs', marker='.', zorder=-10) if self.label_columns: label_col_index = self.label_columns_indices.get(plot_col, None) else: label_col_index = plot_col_index if label_col_index is None: continue plt.scatter(self.label_indices, labels[n, :, label_col_index], edgecolors='k', label='Labels', c='#2ca02c', s=64) if model is not None: predictions = model(inputs) plt.scatter(self.label_indices, predictions[n, :, label_col_index], marker='X', edgecolors='k', label='Predictions', c='#ff7f0e', s=64) if n == 0: plt.legend() plt.xlabel('Time [h]')WindowGenerator.plot = plot test it out: 1w2.plot() 1w2.plot(plot_col='p (mbar)') Create tf.data.DatasetsFinally, this make_dataset method will take a time series DataFrame and convert it to a tf.data.Dataset of (input_window, label_window) pairs using the tf.keras.utils.timeseries_dataset_from_array function: 123456789101112131415def make_dataset(self, data): data = np.array(data, dtype=np.float32) ds = tf.keras.utils.timeseries_dataset_from_array( data=data, targets=None, sequence_length=self.total_window_size, sequence_stride=1, shuffle=True, batch_size=32,) ds = ds.map(self.split_window) return dsWindowGenerator.make_dataset = make_dataset The WindowGenerator object holds training, validation, and test data. Also, we add a standard example batch for easy access and plotting: 123456789101112131415161718192021222324252627@propertydef train(self): return self.make_dataset(self.train_df)@propertydef val(self): return self.make_dataset(self.val_df)@propertydef test(self): return self.make_dataset(self.test_df)@propertydef example(self): &quot;&quot;&quot;Get and cache an example batch of `inputs, labels` for plotting.&quot;&quot;&quot; result = getattr(self, '_example', None) if result is None: # No example batch was found, so get one from the `.train` dataset result = next(iter(self.train)) # And cache it for next time self._example = result return resultWindowGenerator.train = trainWindowGenerator.val = valWindowGenerator.test = testWindowGenerator.example = example Now, the WindowGenerator object gives you access to the tf.data.Dataset objects, so we can easily iterate over the data. 12# Each element is an (inputs, label) pair.w2.train.element_spec 12(TensorSpec(shape=(None, 6, 19), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None)) 123for example_inputs, example_labels in w2.train.take(1): print(f'Inputs shape (batch, time, features): {example_inputs.shape}') print(f'Labels shape (batch, time, features): {example_labels.shape}') 12Inputs shape (batch, time, features): (32, 6, 19)Labels shape (batch, time, features): (32, 1, 1) MLFLOWbefore diving into next section, we will set up MLflow(open source MLOps platform) for tracking and logging the parameters and metrics for the models to be implemented and find out the potential model with best performance lining with the time series data Install mlflow and pyngrok1!pip install mlflow pyngrok --quiet Config pyngrok port and set up mlflow UI123456789101112131415from pyngrok import ngrokfrom getpass import getpassimport mlflow# Terminate open tunnels if existngrok.kill()#sign up a new pyngrok account for the AUTH token if not have NGROK_AUTH_TOKEN = getpass('Your_AUTH_TOKEN:')ngrok.set_auth_token(NGROK_AUTH_TOKEN)# Open an HTTPs tunnel on port 5000 for http://localhost:5000ngrok_tunnel = ngrok.connect(addr=&quot;5000&quot;, proto=&quot;http&quot;, bind_tls=True)print(&quot;MLflow Tracking UI:&quot;, ngrok_tunnel.public_url)get_ipython().system_raw(&quot;mlflow ui --port 5000 &amp;&quot;)mlflow.set_experiment(&quot;mlflow_[weather_tsf]_exp_[v1]&quot;) access MLFLOW UI to test it out, the MLFLOW Track UI: like https://17fe-34-70-201-166.ngrok-free.app/ Config model params and metrics123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# collect params and metrics for mlflowdef mlflow_metrics_eval_model(model_used, model_type, window_used, model_name, metric_result, metric_type): from mlflow.models import infer_signature params = { 'model_used': model_used, 'window_used': window_used, 'model_name': model_name, 'max_epochs': 20, 'batch_size': 32, 'loss': 'mean_squared_error', 'optimizer': 'adam', 'patience' : 2, 'input_width': window_used.input_width, 'label_width': window_used.label_width, 'shift': window_used.shift, 'label_columns': ['T (degC)'] } metrics = {} metrics_key_mapping = { 'mean_absolute_error': 'mae', 'mean_absolute_percentage_error': 'mape', 'root_mean_squared_error': 'rmsr', 'loss' : 'mse' } for key, value in metric_result.items(): if key == 'mean_absolute_percentage_error' and value &gt; 1: value = value / 100 metrics_short_key = metrics_key_mapping.get(key, key) metrics_short_key = f&quot;{metrics_short_key}{metric_type}&quot; metrics[metrics_short_key] = value with mlflow.start_run(): mlflow.log_params(params) mlflow.log_metrics(metrics) mlflow.set_tag(model_type, model_name) signature = infer_signature(window_used.example[0].numpy(), model_used(window_used.example[0]).numpy()) model_info = mlflow.sklearn.log_model( sk_model=model_used, artifact_path=f&quot;models/{model_type}/{model_name}&quot;, signature=signature, input_example=window_used.example[0].numpy(), registered_model_name=model_name, conda_env={ 'name': f&quot;{model_type}_{model_name}&quot;, 'dependencies': [ 'python=3.10.3', 'IPython==7.34.0', 'matplotlib==3.7.1', 'numpy==1.26.4', 'pandas==2.1.4', 'seaborn==0.13.1', 'tensorflow==2.17.0', 'mlflow', 'pyngrok', 'scikit-learn' ] } ) Config mlfow plot function for plotting model metrics1234567891011121314151617181920212223242526272829# plot mlflow metrics for modelsdef plot_mlflow_metrics(model_type): runs = mlflow.search_runs() metrics_list = [] for index, row in runs.iterrows(): run_id = row['run_id'] metrics = mlflow.get_run(run_id).data.metrics tags = mlflow.get_run(run_id).data.tags tag_value = tags.get(model_type, run_id) metrics_list.append({'tag': tag_value, **metrics}) metrics_df = pd.DataFrame(metrics_list) metrics_df_melted = metrics_df.melt(id_vars='tag', var_name='Metric', value_name='Value') plt.figure(figsize=(12, 6)) ax = sns.barplot(data=metrics_df_melted, x='Metric', y='Value', hue='tag') plt.title(f'Metrics with Val_df and Test_df for {model_type} Models') plt.xlabel('Metrics') plt.ylabel('Values') plt.legend(title=model_type) plt.tight_layout() plt.show() Single step modelsThis blog will introduce two sorts of models, one for single step models with predicting one hour and the other for multi step models with predicting one day. single step models predicts a single feature’s value—1 time step (one hour) into the future based only on the current conditions. So, start by building models to predict the T (degC) value one hour into the future Configure a WindowGenerator object to produce these single-step (input, label) pairs: 123single_step_window = WindowGenerator( input_width=1, label_width=1, shift=1, label_columns=['T (degC)']) And we will create 6 different models in time series forecasting to evaluate their performance BaselineBefore building a trainable model it would be good to have a performance baseline as a point for comparison with the later more complicated models. 12345678910class Baseline(tf.keras.Model): def __init__(self, label_index=None): super().__init__() self.label_index = label_index def call(self, inputs): if self.label_index is None: return inputs result = inputs[:, :, self.label_index] return result[:, :, tf.newaxis] Instantiate and evaluate this model: 123456789101112131415161718baseline = Baseline(label_index=column_indices['T (degC)'])baseline.compile(loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanAbsoluteError()])val_performance = {}performance = {}single_step_performance_key = ['loss','mean_absolute_error']def handle_performance(model_used,model_type, model_name, window_used, val_perf, perf, perf_key_list ): metrics_val = model_used.evaluate(window_used.val, return_dict=True) metrics_test = model_used.evaluate(window_used.test, verbose=0, return_dict=True) mlflow_metrics_eval_model(model_used, model_type, window_used, model_name, metrics_val,'_val') mlflow_metrics_eval_model(model_used, model_type, window_used, model_name, metrics_test,'_test') val_perf[model_name] = {key: metrics_val[key] for key in perf_key_list if key in metrics_val} perf[model_name] = {key: metrics_test[key] for key in perf_key_list if key in metrics_test }handle_performance(baseline,'single_step','Baseline',single_step_window,val_performance,performance,single_step_performance_key) 1234567891/439 ━━━━━━━━━━━━━━━━━━━━ 2:27 337ms/step - loss: 0.0075 - mean_absolute_error: 0.0657WARNING: All log messages before absl::InitializeLog() is called are written to STDERRI0000 00:00:1723775844.435380 80829 service.cc:146] XLA service 0x7eff1c004a90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:I0000 00:00:1723775844.435411 80829 service.cc:154] StreamExecutor device (0): Tesla T4, Compute Capability 7.5I0000 00:00:1723775844.435416 80829 service.cc:154] StreamExecutor device (1): Tesla T4, Compute Capability 7.5I0000 00:00:1723775844.435419 80829 service.cc:154] StreamExecutor device (2): Tesla T4, Compute Capability 7.5I0000 00:00:1723775844.435422 80829 service.cc:154] StreamExecutor device (3): Tesla T4, Compute Capability 7.5I0000 00:00:1723775844.614710 80829 device_compiler.h:188] Compiled cluster using XLA! This line is logged at most once for the lifetime of the process.439/439 ━━━━━━━━━━━━━━━━━━━━ 1s 1ms/step - loss: 0.0121 - mean_absolute_error: 0.0769 That printed some performance metrics, but those don’t give you a feeling for how well the model is doing. The WindowGenerator has a plot method, but the plots won’t be very interesting with only a single sample. So, create a wider WindowGenerator that generates windows 24 hours of consecutive inputs and labels at a time. The new wide_window variable doesn’t change the way the model operates. The model still makes predictions one hour into the future based on a single input time step. Here, the time axis acts like the batch axis: each prediction is made independently with no interaction between time steps: 123wide_window = WindowGenerator( input_width=24, label_width=24, shift=1, label_columns=['T (degC)']) This expanded window can be passed directly to the same baseline model without any code changes. This is possible because the inputs and labels have the same number of time steps, and the baseline just forwards the input to the output: 1wide_window.plot(baseline) In the above plots of three examples the single step model is run over the course of 24 hours. This deserves some explanation: The blue Inputs line shows the input temperature at each time step. The model receives all features, this plot only shows the temperature. The green Labels dots show the target prediction value. These dots are shown at the prediction time, not the input time. That is why the range of labels is shifted 1 step relative to the inputs. The orange Predictions crosses are the model’s prediction’s for each output time step. If the model were predicting perfectly the predictions would land directly on the Labels. Linear modelA tf.keras.layers.Dense layer with no activation set is a linear model. The layer only transforms the last axis of the data from (batch, time, inputs) to (batch, time, units); it is applied independently to every item across the batch and time axes. 123linear = tf.keras.Sequential([ tf.keras.layers.Dense(units=1)]) compile and fit function: 123456789101112131415MAX_EPOCHS = 20def compile_and_fit(model, window, patience=2): early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min') model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.MeanAbsoluteError()]) history = model.fit(window.train, epochs=MAX_EPOCHS, validation_data=window.val, callbacks=[early_stopping]) return history Train the model and evaluate its performance: 123history = compile_and_fit(linear, single_step_window)handle_performance(linear,'single_step','linear',single_step_window,val_performance,performance,single_step_performance_key) Here is the plot of its example predictions on the wide_window, and how in many cases the prediction is clearly better than just returning the input temperature, but in a few cases it’s worse: 1wide_window.plot(linear) One advantage to linear models is that they’re relatively simple to interpret. We can pull out the layer’s weights and visualise the weight assigned to each input: 12345plt.bar(x = range(len(train_df.columns)), height=linear.layers[0].kernel[:,0].numpy())axis = plt.gca()axis.set_xticks(range(len(train_df.columns)))_ = axis.set_xticklabels(train_df.columns, rotation=90) Sometimes the model doesn’t even place the most weight on the input T (degC). This is one of the risks of random initialisation. DenseHere’s a model similar to the linear model for checking the performance of deeper, more powerful, single input step models, except it stacks several a few Dense layers between the input and the output: 123456789dense = tf.keras.Sequential([ tf.keras.layers.Dense(units=64, activation='relu'), tf.keras.layers.Dense(units=64, activation='relu'), tf.keras.layers.Dense(units=1)])history = compile_and_fit(dense, single_step_window)handle_performance(dense,'single_step','Dense',single_step_window,val_performance,performance,single_step_performance_key) Multi dense modelA single-time-step model has no context for the current values of its inputs. It can’t see how the input features are changing over time. To address this issue the model needs access to multiple time steps when making predictions: The baseline, linear and dense models handled each time step independently. Here the model will take multiple time steps as input to produce a single output. Create a WindowGenerator that will produce batches of three-hour inputs and one-hour labels: training a dense model on a multiple-input-step window by adding a tf.keras.layers.Flatten as the first layer of the model: 12345678910multi_step_dense = tf.keras.Sequential([ # Shape: (time, features) =&gt; (time*features) tf.keras.layers.Flatten(), tf.keras.layers.Dense(units=32, activation='relu'), tf.keras.layers.Dense(units=32, activation='relu'), tf.keras.layers.Dense(units=1), # Add back the time dimension. # Shape: (outputs) =&gt; (1, outputs) tf.keras.layers.Reshape([1, -1]),]) 123history = compile_and_fit(multi_step_dense, conv_window)handle_performance(multi_step_dense,'single_step','Multi step dense',conv_window,val_performance,performance,single_step_performance_key) 12print('Input shape:', conv_window.example[0].shape)print('Output shape:', multi_step_dense(conv_window.example[0]).shape) 12Input shape: (32, 3, 19)Output shape: (32, 1, 1) 1conv_window.plot(multi_step_dense) The main down-side of this approach is that the resulting model can only be executed on input windows of exactly this shape. 12345print('Input shape:', wide_window.example[0].shape)try: print('Output shape:', multi_step_dense(wide_window.example[0]).shape)except Exception as e: print(f'\\n{type(e).__name__}:{e}') 12345678910Input shape: (32, 24, 19)ValueError:Exception encountered when calling Sequential.call().Input 0 of layer &quot;dense_4&quot; is incompatible with the layer: expected axis -1 of input shape to have value 57, but received input with shape (32, 456)Arguments received by Sequential.call(): • inputs=tf.Tensor(shape=(32, 24, 19), dtype=float32) • training=None • mask=None The convolution models in the next section fix this problem. Convolution neural networkA convolution layer (tf.keras.layers.Conv1D) also takes multiple time steps as input to each prediction. Below is the same model as multi_step_dense, re-written with a convolution. 1234567conv_model = tf.keras.Sequential([ tf.keras.layers.Conv1D(filters=32, kernel_size=(CONV_WIDTH,), activation='relu'), tf.keras.layers.Dense(units=32, activation='relu'), tf.keras.layers.Dense(units=1),]) Compile and fit the model, handle the performance 12345history = compile_and_fit(conv_model, conv_window)IPython.display.clear_output()handle_performance(conv_model,'Conv','Multi step dense',conv_window,val_performance,performance,single_step_performance_key) check out the input and output tensor shape 123print(&quot;Conv model on `conv_window`&quot;)print('Input shape:', conv_window.example[0].shape)print('Output shape:', conv_model(conv_window.example[0]).shape) 123Conv model on `conv_window`Input shape: (32, 3, 19)Output shape: (32, 1, 1) check out the input and output tensor shape of wide_window 1234print(&quot;Wide window&quot;)print('Input shape:', wide_window.example[0].shape)print('Labels shape:', wide_window.example[1].shape)print('Output shape:', conv_model(wide_window.example[0]).shape) 123456789Wide windowInput shape: (32, 24, 19)Labels shape: (32, 24, 1)Output shape: (32, 22, 1)W0000 00:00:1723775965.411205 80658 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reducedW0000 00:00:1723775965.430143 80658 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reducedW0000 00:00:1723775965.431321 80658 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reducedW0000 00:00:1723775965.432466 80658 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced... We could find out that the output is shorter than the input. To make training or plotting work, we need the labels, and prediction to have the same length. So build a WindowGenerator to produce wide windows with a few extra input time steps so the label and prediction lengths match: 123456789LABEL_WIDTH = 24INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)wide_conv_window = WindowGenerator( input_width=INPUT_WIDTH, label_width=LABEL_WIDTH, shift=1, label_columns=['T (degC)'])wide_conv_window 12345Total window size: 27Input indices: [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25]Label indices: [ 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26]Label column name(s): ['T (degC)'] 1234print(&quot;Wide conv window&quot;)print('Input shape:', wide_conv_window.example[0].shape)print('Labels shape:', wide_conv_window.example[1].shape)print('Output shape:', conv_model(wide_conv_window.example[0]).shape) 12345678Wide conv windowInput shape: (32, 26, 19)Labels shape: (32, 24, 1)Output shape: (32, 24, 1)W0000 00:00:1723775965.630979 80658 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reducedW0000 00:00:1723775965.632244 80658 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reducedW0000 00:00:1723775965.633402 80658 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced... Every prediction here is based on the 3 preceding time steps: 1wide_conv_window.plot(conv_model) Recurrent neural networkA Recurrent Neural Network (RNN) is a type of neural network well-suited to time series data. RNNs process a time series step-by-step, maintaining an internal state from time-step to time-step. And we will use an RNN layer called Long Short-Term Memory (tf.keras.layers.LSTM). n important constructor argument for all Keras RNN layers, such as tf.keras.layers.LSTM, is the return_sequences argument. This setting can configure the layer in one of two ways: If False, the default, the layer only returns the output of the final time step, giving the model time to warm up its internal state before making a single prediction: If True, the layer returns an output for each input. This is useful for: Stacking RNN layers. Training a model on multiple time steps simultaneously. 123456lstm_model = tf.keras.models.Sequential([ # Shape [batch, time, features] =&gt; [batch, time, lstm_units] tf.keras.layers.LSTM(32, return_sequences=True), # Shape =&gt; [batch, time, features] tf.keras.layers.Dense(units=1)]) 12345history = compile_and_fit(lstm_model, wide_window)IPython.display.clear_output()handle_performance(lstm_model,'single_step','LSTM',wide_window,val_performance,performance,single_step_performance_key) 12print('Input shape:', wide_window.example[0].shape)print('Output shape:', lstm_model(wide_window.example[0]).shape) 12Input shape: (32, 24, 19)Output shape: (32, 24, 1) 1wide_window.plot(lstm_model) Performancelog in MLFLOW UI and check out the metrics use MLFLOW plot func to present and analyse the metrics 1plot_mlflow_metrics('single_step') from the picture and we could find out the LSTM model metrics are better than other models’ based on the test and validation dataset according to the four different common used metrics in time series data prediction, which are mean_absolute_error, mean_square_error, mean_absolute_percentage_error, symmetric_mean_absolute_percentage_error and root_mean_square_error Diving into deeper on comparison of the mae metric for the models 123cm = lstm_model.metrics[1]cm.metrics 1[&lt;MeanAbsoluteError name=mean_absolute_error&gt;] 1val_performance 123456789101112{'Baseline': {'loss': 0.012845644727349281, 'mean_absolute_error': 0.07846628874540329}, 'Linear': {'loss': 0.008695926517248154, 'mean_absolute_error': 0.06866316497325897}, 'Dense': {'loss': 0.006793886888772249, 'mean_absolute_error': 0.05716359242796898}, 'Multi step dense': {'loss': 0.007616413291543722, 'mean_absolute_error': 0.06059327721595764}, 'Conv': {'loss': 0.006222909316420555, 'mean_absolute_error': 0.05451442673802376}, 'LSTM': {'loss': 0.0056776562705636024, 'mean_absolute_error': 0.05233458802103996} } 123456789101112x = np.arange(len(performance))width = 0.3metric_name = 'mean_absolute_error'val_mae = [v[metric_name] for v in val_performance.values()]test_mae = [v[metric_name] for v in performance.values()]plt.ylabel('mean_absolute_error [T (degC), normalized]')plt.bar(x - 0.17, val_mae, width, label='Validation')plt.bar(x + 0.17, test_mae, width, label='Test')plt.xticks(ticks=x, labels=performance.keys(), rotation=45)_ = plt.legend() 12for name, value in performance.items(): print(f'{name:12s}: {value[metric_name]:0.4f}') 123456Baseline : 0.0852Linear : 0.0663Dense : 0.0584Multi step dense: 0.0633Conv : 0.0543LSTM : 0.0533 With this dataset typically each of the models does slightly better than the one before it and from the data, the performance of the model based on LSTM model is better than other’s, which is 0.0533, when predicting single time step. Multi-step modelsThis section looks at how to expand these models to make multiple time step predictions. In a multi-step prediction, the model needs to learn to predict a range of future values. Thus, unlike a single step model, where only a single future point is predicted, a multi-step model predicts a sequence of the future values. There are two rough approaches to this: Single shot predictions where the entire time series is predicted at once. Autoregressive predictions where the model only makes single step predictions and its output is fed back as its input. For the multi-step model, the training data again consists of hourly samples. However, here, the models will learn to predict 24 hours into the future, given 24 hours of the past. Here is a Window object that generates these slices from the dataset: 1234567OUT_STEPS = 24multi_window = WindowGenerator(input_width=24, label_width=OUT_STEPS, shift=OUT_STEPS)multi_window.plot()multi_window 1234Total window size: 48Input indices: [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]Label indices: [24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]Label column name(s): None BaselinesA simple baseline for this task is to repeat the last input time step for the required number of output time steps: 12345678910111213141516class MultiStepLastBaseline(tf.keras.Model): def call(self, inputs): return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])last_baseline = MultiStepLastBaseline()last_baseline.compile(loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanAbsoluteError()])multi_val_performance = {}multi_performance = {}multi_step_performance_key = ['loss', 'mean_absolute_error']handle_performance(last_baseline,'multi_step','Last',multi_window,multi_val_performance,multi_performance,multi_step_performance_key)multi_window.plot(last_baseline) Since this task is to predict 24 hours into the future, given 24 hours of the past, another simple approach is to repeat the previous day, assuming tomorrow will be similar: 1234567891011class RepeatBaseline(tf.keras.Model): def call(self, inputs): return inputsrepeat_baseline = RepeatBaseline()repeat_baseline.compile(loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanAbsoluteError()])handle_performance(repeat_baseline,'multi_step','Repeat', multi_window, multi_val_performance, multi_performance,multi_step_performance_key)multi_window.plot(repeat_baseline) LinearA simple linear model based on the last input time step does better than either baseline, but is underpowered. The model needs to predict OUTPUT_STEPS time steps, from a single input time step with a linear projection. It can only capture a low-dimensional slice of the behavior, likely based mainly on the time of day and time of year. 123456789101112131415161718multi_linear_model = tf.keras.Sequential([ # Take the last time-step. # Shape [batch, time, features] =&gt; [batch, 1, features] tf.keras.layers.Lambda(lambda x: x[:, -1:, :]), # Shape =&gt; [batch, 1, out_steps*features] tf.keras.layers.Dense(OUT_STEPS*num_features, kernel_initializer=tf.initializers.zeros()), # Shape =&gt; [batch, out_steps, features] tf.keras.layers.Reshape([OUT_STEPS, num_features])])history = compile_and_fit(multi_linear_model, multi_window)IPython.display.clear_output()handle_performance(multi_linear_model,'multi_step','Linear',multi_window,multi_val_performance,multi_performance,multi_step_performance_key)multi_window.plot(multi_linear_model) ### Dense Adding a tf.keras.layers.Dense between the input and output gives the linear model more power 123456789101112131415161718192021multi_dense_model = tf.keras.Sequential([ # Take the last time step. # Shape [batch, time, features] =&gt; [batch, 1, features] tf.keras.layers.Lambda(lambda x: x[:, -1:, :]), # Shape =&gt; [batch, 1, dense_units] tf.keras.layers.Dense(512, activation='relu'), # Shape =&gt; [batch, out_steps*features] tf.keras.layers.Dense(OUT_STEPS*num_features, kernel_initializer=tf.initializers.zeros()), # Shape =&gt; [batch, out_steps, features] tf.keras.layers.Reshape([OUT_STEPS, num_features])])history = compile_and_fit(multi_dense_model, multi_window)IPython.display.clear_output()handle_performance(multi_dense_model,'multi_step','Dense',multi_window,multi_val_performance,multi_performance,multi_step_performance_key)multi_window.plot(multi_dense_model) CNNA convolutional model makes predictions based on a fixed-width history, which may lead to better performance than the dense model since it can see how things are changing over time: 1234567891011121314151617181920CONV_WIDTH = 3multi_conv_model = tf.keras.Sequential([ # Shape [batch, time, features] =&gt; [batch, CONV_WIDTH, features] tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]), # Shape =&gt; [batch, 1, conv_units] tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)), # Shape =&gt; [batch, 1, out_steps*features] tf.keras.layers.Dense(OUT_STEPS*num_features, kernel_initializer=tf.initializers.zeros()), # Shape =&gt; [batch, out_steps, features] tf.keras.layers.Reshape([OUT_STEPS, num_features])])history = compile_and_fit(multi_conv_model, multi_window)IPython.display.clear_output()handle_performance(multi_conv_model,'multi_step','Conv',multi_window,multi_val_performance,multi_performance,multi_step_performance_key)multi_window.plot(multi_conv_model) RNNA recurrent model can learn to use a long history of inputs, if it’s relevant to the predictions the model is making. Here the model will accumulate internal state for 24 hours, before making a single prediction for the next 24 hours. In this single-shot format, the LSTM only needs to produce an output at the last time step, so set return_sequences=False in tf.keras.layers.LSTM. In this multi-step format, the LSTM only needs to produce an output at the last time step, so set return_sequences=False in tf.keras.layers.LSTM. 123456789101112131415161718multi_lstm_model = tf.keras.Sequential([ # Shape [batch, time, features] =&gt; [batch, lstm_units]. # Adding more `lstm_units` just overfits more quickly. tf.keras.layers.LSTM(32, return_sequences=False), # Shape =&gt; [batch, out_steps*features]. tf.keras.layers.Dense(OUT_STEPS*num_features, kernel_initializer=tf.initializers.zeros()), # Shape =&gt; [batch, out_steps, features]. tf.keras.layers.Reshape([OUT_STEPS, num_features])])history = compile_and_fit(multi_lstm_model, multi_window)IPython.display.clear_output()handle_performance(multi_lstm_model,'multi_step','LSTM',multi_window,multi_val_performance,multi_performance,multi_step_performance_key)multi_window.plot(multi_lstm_model) Autoregressive RNN modelThe above models all predict the entire output sequence in a single step. In some cases it may be helpful for the model to decompose this prediction into individual time steps. Then, each model’s output can be fed back into itself at each step and predictions can be made conditioned on the previous one. The model will have the same basic form as the single-step LSTM models from earlier: a tf.keras.layers.LSTM layer followed by a tf.keras.layers.Dense layer that converts the LSTM layer’s outputs to model predictions. A tf.keras.layers.LSTM is a tf.keras.layers.LSTMCell wrapped in the higher level tf.keras.layers.RNN that manages the state and sequence results for you (Check out the Recurrent Neural Networks (RNN) with Keras guide for details). In this case, the model has to manually manage the inputs for each step, so it uses tf.keras.layers.LSTMCell directly for the lower level, single time step interface. 12345678910class FeedBack(tf.keras.Model): def __init__(self, units, out_steps): super().__init__() self.out_steps = out_steps self.units = units self.lstm_cell = tf.keras.layers.LSTMCell(units) # Also wrap the LSTMCell in an RNN to simplify the `warmup` method. self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True) self.dense = tf.keras.layers.Dense(num_features)feedback_model = FeedBack(units=32, out_steps=OUT_STEPS) The first method this model needs is a warmup method to initialize its internal state based on the inputs. Once trained, this state will capture the relevant parts of the input history. This is equivalent to the single-step LSTM model from earlier 12345678910def warmup(self, inputs): # inputs.shape =&gt; (batch, time, features) # x.shape =&gt; (batch, lstm_units) x, *state = self.lstm_rnn(inputs) # predictions.shape =&gt; (batch, features) prediction = self.dense(x) return prediction, stateFeedBack.warmup = warmup This method returns a single time-step prediction and the internal state of the LSTM: 12prediction, state = feedback_model.warmup(multi_window.example[0])prediction.shape 1TensorShape([32, 19]) With the RNN‘s state, and an initial prediction you can now continue iterating the model feeding the predictions at each step back as the input. One of the simplest approach for collecting the output predictions could be using a Python list and a tf.stack after the loop. 12345678910111213141516171819202122232425262728def call(self, inputs, training=None): # Use a TensorArray to capture dynamically unrolled outputs. predictions = [] # Initialize the LSTM state. prediction, state = self.warmup(inputs) # Insert the first prediction. predictions.append(prediction) # Run the rest of the prediction steps. for n in range(1, self.out_steps): # Use the last prediction as input. x = prediction # Execute one lstm step. x, state = self.lstm_cell(x, states=state, training=training) # Convert the lstm output to a prediction. prediction = self.dense(x) # Add the prediction to the output. predictions.append(prediction) # predictions.shape =&gt; (time, batch, features) predictions = tf.stack(predictions) # predictions.shape =&gt; (batch, time, features) predictions = tf.transpose(predictions, [1, 0, 2]) return predictionsFeedBack.call = call 1234567history = compile_and_fit(feedback_model, multi_window)IPython.display.clear_output()handle_performance(feedback_model,'multi_step','AR LSTM',multi_window,multi_val_performance,multi_performance,multi_step_performance_key)multi_window.plot(feedback_model) PerformanceMLFLOW metrics 1plot_mlflow_metrics('multi_step') LSTM model performs well generally except on mean_abosolute_percentage_error. 1234567891011121314x = np.arange(len(multi_performance))width = 0.3metric_name = 'mean_absolute_error'val_mae = [v[metric_name] for v in multi_val_performance.values()]test_mae = [v[metric_name] for v in multi_performance.values()]plt.bar(x - 0.17, val_mae, width, label='Validation')plt.bar(x + 0.17, test_mae, width, label='Test')plt.xticks(ticks=x, labels=multi_performance.keys(), rotation=45)plt.ylabel(f'MAE (average over all times and outputs)')_ = plt.legend() 12for name, value in multi_performance.items(): print(f'{name:8s}: {value[metric_name]:0.4f}') 1234567Last : 0.5157Repeat : 0.3774Linear : 0.2980Dense : 0.2765Conv : 0.2732LSTM : 0.2767AR LSTM : 0.2910 The gains achieved going from a dense model to convolutional and recurrent models are only a few percent (if any), and the autoregressive model performed clearly worse. So these more complex approaches may not be worth while on this problem, but there was no way to know without trying. Finally, we will use LSTM model to implement our time series data forecasting. Checking out the GitHub repo below for complete implementing LSTM model with the configs above on the prediction tasks and the blog: Deploy the model on Kubeflow GitHubhttps://github.com/PaddyZz/Time_Series_Forecasting ConclusionWe have finished: • Environment and dependencies set up• Exploratory Data Analysis• Configure MLflow for model evaluation and model metrics visualisation• Compile, fit, train and evaluate the models with single step type• Compile, fit, train and evaluate the models with multi step type• Compare the metrics for choosing best performance model among them Referencestime series forecasting","link":"/projects/time_series_forecasting/"}],"tags":[{"name":"Certificates","slug":"Certificates","link":"/tags/Certificates/"},{"name":"Word2Vec","slug":"Word2Vec","link":"/tags/Word2Vec/"},{"name":"Word Embedding","slug":"Word-Embedding","link":"/tags/Word-Embedding/"},{"name":"Convolution Layers","slug":"Convolution-Layers","link":"/tags/Convolution-Layers/"},{"name":"Max Pooling","slug":"Max-Pooling","link":"/tags/Max-Pooling/"},{"name":"DL","slug":"DL","link":"/tags/DL/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"CNN","slug":"CNN","link":"/tags/CNN/"},{"name":"Theory","slug":"Theory","link":"/tags/Theory/"},{"name":"NoCode","slug":"NoCode","link":"/tags/NoCode/"},{"name":"SoftMax","slug":"SoftMax","link":"/tags/SoftMax/"},{"name":"CNN Layers","slug":"CNN-Layers","link":"/tags/CNN-Layers/"},{"name":"Neural Networks","slug":"Neural-Networks","link":"/tags/Neural-Networks/"},{"name":"FC Layers","slug":"FC-Layers","link":"/tags/FC-Layers/"},{"name":"Pooling Layers","slug":"Pooling-Layers","link":"/tags/Pooling-Layers/"},{"name":"Math","slug":"Math","link":"/tags/Math/"},{"name":"Model Eval","slug":"Model-Eval","link":"/tags/Model-Eval/"},{"name":"ModelMetricsFunc","slug":"ModelMetricsFunc","link":"/tags/ModelMetricsFunc/"},{"name":"life","slug":"life","link":"/tags/life/"},{"name":"quotes","slug":"quotes","link":"/tags/quotes/"},{"name":"Scenic_Pics","slug":"Scenic-Pics","link":"/tags/Scenic-Pics/"},{"name":"PROJECTS","slug":"PROJECTS","link":"/tags/PROJECTS/"},{"name":"Conda","slug":"Conda","link":"/tags/Conda/"},{"name":"CICD","slug":"CICD","link":"/tags/CICD/"},{"name":"AWS","slug":"AWS","link":"/tags/AWS/"},{"name":"EC2","slug":"EC2","link":"/tags/EC2/"},{"name":"EKS","slug":"EKS","link":"/tags/EKS/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"K8s","slug":"K8s","link":"/tags/K8s/"},{"name":"End-to-End","slug":"End-to-End","link":"/tags/End-to-End/"},{"name":"MLOps","slug":"MLOps","link":"/tags/MLOps/"},{"name":"Kubeflow","slug":"Kubeflow","link":"/tags/Kubeflow/"},{"name":"Bash","slug":"Bash","link":"/tags/Bash/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"MinIO","slug":"MinIO","link":"/tags/MinIO/"},{"name":"Kserve","slug":"Kserve","link":"/tags/Kserve/"},{"name":"kfp","slug":"kfp","link":"/tags/kfp/"},{"name":"argo","slug":"argo","link":"/tags/argo/"},{"name":"Tekton","slug":"Tekton","link":"/tags/Tekton/"},{"name":"ECR","slug":"ECR","link":"/tags/ECR/"},{"name":"S3","slug":"S3","link":"/tags/S3/"},{"name":"Seq-to-Seq","slug":"Seq-to-Seq","link":"/tags/Seq-to-Seq/"},{"name":"Tensorflow","slug":"Tensorflow","link":"/tags/Tensorflow/"},{"name":"Keras","slug":"Keras","link":"/tags/Keras/"},{"name":"transformer","slug":"transformer","link":"/tags/transformer/"},{"name":"tokenizer","slug":"tokenizer","link":"/tags/tokenizer/"},{"name":"self-attention","slug":"self-attention","link":"/tags/self-attention/"},{"name":"translation","slug":"translation","link":"/tags/translation/"},{"name":"CV","slug":"CV","link":"/tags/CV/"},{"name":"VGG19","slug":"VGG19","link":"/tags/VGG19/"},{"name":"AIgenerative","slug":"AIgenerative","link":"/tags/AIgenerative/"},{"name":"GradientDescent","slug":"GradientDescent","link":"/tags/GradientDescent/"},{"name":"VariationLoss","slug":"VariationLoss","link":"/tags/VariationLoss/"},{"name":"prediction","slug":"prediction","link":"/tags/prediction/"},{"name":"TSF","slug":"TSF","link":"/tags/TSF/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"LSTM","slug":"LSTM","link":"/tags/LSTM/"},{"name":"MLflow","slug":"MLflow","link":"/tags/MLflow/"},{"name":"ModelEval","slug":"ModelEval","link":"/tags/ModelEval/"},{"name":"Visualistion","slug":"Visualistion","link":"/tags/Visualistion/"}],"categories":[{"name":"certificates","slug":"certificates","link":"/certificates/"},{"name":"curriculum","slug":"curriculum","link":"/curriculum/"},{"name":"faqs","slug":"faqs","link":"/faqs/"},{"name":"blogs","slug":"blogs","link":"/blogs/"},{"name":"life","slug":"life","link":"/life/"},{"name":"projects","slug":"projects","link":"/projects/"}],"pages":[{"title":"blogs","text":"","link":"/blogs/index.html"},{"title":"projects","text":"","link":"/projects/index.html"}]}